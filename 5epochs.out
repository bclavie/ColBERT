nohup: ignoring input
/usr/local/share/miniconda/envs/mcol/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  _torch_pytree._register_pytree_node(
/usr/local/share/miniconda/envs/mcol/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  _torch_pytree._register_pytree_node(
/usr/local/share/miniconda/envs/mcol/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  _torch_pytree._register_pytree_node(
#> Starting...
#> Starting...
/usr/local/share/miniconda/envs/mcol/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  _torch_pytree._register_pytree_node(
/usr/local/share/miniconda/envs/mcol/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  _torch_pytree._register_pytree_node(
/usr/local/share/miniconda/envs/mcol/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  _torch_pytree._register_pytree_node(
/usr/local/share/miniconda/envs/mcol/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  _torch_pytree._register_pytree_node(
/usr/local/share/miniconda/envs/mcol/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  _torch_pytree._register_pytree_node(
/usr/local/share/miniconda/envs/mcol/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  _torch_pytree._register_pytree_node(
nranks = 2 	 num_gpus = 2 	 device=0
{
    "query_token_id": "[unused0]",
    "doc_token_id": "[unused1]",
    "query_token": "[Q]",
    "doc_token": "[D]",
    "ncells": null,
    "centroid_score_threshold": null,
    "ndocs": null,
    "load_index_with_mmap": false,
    "index_path": null,
    "index_bsize": 64,
    "nbits": 1,
    "kmeans_niters": 4,
    "resume": false,
    "similarity": "cosine",
    "bsize": 64,
    "accumsteps": 1,
    "lr": 2e-5,
    "maxsteps": 500000,
    "save_every": null,
    "warmup": 100,
    "warmup_bert": null,
    "relu": false,
    "nway": 4,
    "use_ib_negatives": true,
    "reranker": false,
    "distillation_alpha": 1.0,
    "ignore_scores": false,
    "model_name": null,
    "query_maxlen": 32,
    "attend_to_mask_tokens": false,
    "interaction": "colbert",
    "dim": 128,
    "doc_maxlen": 220,
    "mask_punctuation": true,
    "checkpoint": "colbert-ir\/colbertv2.0",
    "triples": "shuftriplets.jsonl",
    "collection": "corpus.train.colbert.tsv",
    "queries": "queries.train.colbert.tsv",
    "index_name": null,
    "overwrite": false,
    "root": "\/home\/ubuntu\/colbert\/experiments",
    "experiment": "test",
    "index_root": null,
    "name": "2024-03\/29\/22.22.09",
    "rank": 0,
    "nranks": 2,
    "amp": true,
    "gpus": 2,
    "avoid_fork_if_possible": false
}
Using config.bsize = 32 (per process) and config.accumsteps = 1
[Mar 29, 22:22:18] #> Loading the queries from queries.train.colbert.tsv ...
[Mar 29, 22:22:18] #> Got 9906 queries. All QIDs are unique.

[Mar 29, 22:22:18] #> Loading collection...
0M nranks = 2 	 num_gpus = 2 	 device=1
Using config.bsize = 32 (per process) and config.accumsteps = 1
[Mar 29, 22:22:18] #> Loading the queries from queries.train.colbert.tsv ...
[Mar 29, 22:22:18] #> Got 9906 queries. All QIDs are unique.

[Mar 29, 22:22:18] #> Loading collection...
0M Some weights of HF_ColBERT were not initialized from the model checkpoint at colbert-ir/colbertv2.0 and are newly initialized: ['instruction_encoder.encoder.layer.17.attention.self.value.bias', 'instruction_encoder.encoder.layer.7.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.8.attention.self.key.weight', 'instruction_encoder.encoder.layer.20.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.1.attention.self.value.weight', 'instruction_encoder.encoder.layer.22.attention.output.dense.weight', 'instruction_encoder.encoder.layer.19.attention.self.key.bias', 'instruction_encoder.encoder.layer.15.attention.self.query.weight', 'instruction_encoder.encoder.layer.18.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.21.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.15.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.6.intermediate.dense.weight', 'instruction_encoder.encoder.layer.2.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.6.output.dense.bias', 'instruction_encoder.encoder.layer.22.attention.output.dense.bias', 'instruction_encoder.encoder.layer.13.attention.output.dense.bias', 'instruction_encoder.encoder.layer.21.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.12.intermediate.dense.weight', 'instruction_encoder.encoder.layer.3.output.dense.bias', 'instruction_encoder.encoder.layer.6.attention.self.query.weight', 'instruction_encoder.encoder.layer.8.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.5.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.0.attention.self.key.bias', 'instruction_encoder.encoder.layer.1.intermediate.dense.weight', 'instruction_encoder.encoder.layer.6.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.12.attention.self.key.bias', 'instruction_encoder.encoder.layer.4.attention.self.value.bias', 'instruction_encoder.encoder.layer.15.attention.self.key.bias', 'instruction_encoder.encoder.layer.3.intermediate.dense.weight', 'instruction_encoder.encoder.layer.3.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.19.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.5.attention.self.key.bias', 'instruction_encoder.encoder.layer.20.output.dense.bias', 'instruction_encoder.encoder.layer.20.attention.self.query.weight', 'instruction_encoder.encoder.layer.5.intermediate.dense.weight', 'instruction_encoder.encoder.layer.12.attention.self.value.weight', 'instruction_encoder.encoder.layer.19.attention.self.value.weight', 'instruction_encoder.encoder.layer.17.attention.self.key.bias', 'instruction_encoder.encoder.layer.21.attention.output.dense.weight', 'instruction_encoder.encoder.layer.10.attention.self.query.bias', 'instruction_encoder.encoder.layer.15.intermediate.dense.bias', 'instruction_encoder.encoder.layer.22.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.4.attention.self.query.bias', 'instruction_encoder.encoder.layer.11.attention.output.dense.bias', 'instruction_encoder.encoder.layer.19.attention.output.dense.weight', 'instruction_encoder.encoder.layer.15.attention.output.dense.weight', 'instruction_encoder.encoder.layer.10.output.dense.bias', 'instruction_encoder.encoder.layer.10.output.dense.weight', 'instruction_encoder.encoder.layer.15.attention.output.dense.bias', 'instruction_encoder.encoder.layer.17.attention.self.key.weight', 'instruction_encoder.encoder.layer.8.attention.self.key.bias', 'instruction_encoder.encoder.layer.22.intermediate.dense.bias', 'instruction_encoder.encoder.layer.12.attention.self.key.weight', 'instruction_encoder.encoder.layer.0.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.10.intermediate.dense.weight', 'instruction_encoder.encoder.layer.9.attention.output.dense.bias', 'instruction_encoder.encoder.layer.0.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.1.intermediate.dense.bias', 'instruction_encoder.encoder.layer.4.attention.self.value.weight', 'instruction_encoder.encoder.layer.2.output.dense.bias', 'instruction_encoder.encoder.layer.18.attention.self.query.weight', 'instruction_encoder.encoder.layer.15.attention.self.value.bias', 'instruction_encoder.encoder.layer.1.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.19.output.dense.weight', 'instruction_encoder.encoder.layer.1.output.dense.weight', 'instruction_encoder.encoder.layer.2.attention.self.key.bias', 'instruction_encoder.encoder.layer.2.attention.self.key.weight', 'instruction_encoder.encoder.layer.0.intermediate.dense.bias', 'instruction_encoder.encoder.layer.16.attention.self.key.weight', 'instruction_encoder.encoder.layer.15.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.21.attention.self.value.weight', 'instruction_encoder.encoder.layer.13.output.dense.weight', 'instruction_encoder.pooler.dense.bias', 'instruction_encoder.encoder.layer.14.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.20.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.12.output.dense.weight', 'instruction_encoder.encoder.layer.2.intermediate.dense.bias', 'instruction_encoder.encoder.layer.15.attention.self.query.bias', 'instruction_encoder.encoder.layer.16.attention.self.value.bias', 'instruction_encoder.encoder.layer.9.attention.self.query.weight', 'instruction_encoder.encoder.layer.13.intermediate.dense.weight', 'instruction_encoder.encoder.layer.6.attention.output.dense.bias', 'instruction_encoder.encoder.layer.8.attention.output.dense.weight', 'instruction_encoder.encoder.layer.12.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.0.attention.output.dense.bias', 'instruction_encoder.encoder.layer.3.attention.self.value.bias', 'instruction_encoder.encoder.layer.16.attention.output.dense.weight', 'instruction_encoder.encoder.layer.2.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.0.attention.output.dense.weight', 'instruction_encoder.encoder.layer.18.intermediate.dense.weight', 'instruction_encoder.encoder.layer.23.attention.self.key.bias', 'instruction_encoder.encoder.layer.9.attention.self.query.bias', 'instruction_encoder.encoder.layer.11.attention.self.query.weight', 'instruction_encoder.encoder.layer.17.intermediate.dense.weight', 'instruction_encoder.encoder.layer.12.attention.self.query.bias', 'instruction_encoder.encoder.layer.11.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.8.attention.self.value.weight', 'instruction_encoder.encoder.layer.21.output.dense.weight', 'instruction_encoder.encoder.layer.23.attention.self.key.weight', 'instruction_encoder.encoder.layer.6.attention.self.key.bias', 'instruction_encoder.encoder.layer.11.attention.output.dense.weight', 'instruction_encoder.encoder.layer.17.output.LayerNorm.weight', 'cross_attention.attention.in_proj_weight', 'instruction_encoder.encoder.layer.4.intermediate.dense.weight', 'instruction_encoder.encoder.layer.2.attention.self.query.weight', 'instruction_encoder.encoder.layer.1.attention.self.query.bias', 'instruction_encoder.encoder.layer.21.attention.self.query.bias', 'instruction_encoder.encoder.layer.18.output.dense.bias', 'cross_attention.instruction_projection.bias', 'instruction_encoder.encoder.layer.19.output.dense.bias', 'instruction_encoder.encoder.layer.4.attention.self.key.weight', 'instruction_encoder.encoder.layer.19.attention.self.key.weight', 'instruction_encoder.encoder.layer.9.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.7.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.3.output.dense.weight', 'instruction_encoder.encoder.layer.6.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.8.attention.self.query.weight', 'instruction_encoder.encoder.layer.14.intermediate.dense.bias', 'instruction_encoder.encoder.layer.18.intermediate.dense.bias', 'instruction_encoder.encoder.layer.8.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.9.intermediate.dense.bias', 'instruction_encoder.encoder.layer.0.attention.self.value.weight', 'instruction_encoder.encoder.layer.2.attention.self.value.weight', 'instruction_encoder.encoder.layer.6.attention.self.value.bias', 'instruction_encoder.encoder.layer.12.output.dense.bias', 'instruction_encoder.encoder.layer.14.attention.self.query.weight', 'instruction_encoder.encoder.layer.21.output.LayerNorm.weight', 'instruction_linear.weight', 'instruction_encoder.encoder.layer.12.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.22.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.3.intermediate.dense.bias', 'instruction_encoder.encoder.layer.13.attention.self.value.bias', 'instruction_encoder.encoder.layer.2.attention.output.dense.weight', 'instruction_encoder.encoder.layer.8.intermediate.dense.weight', 'instruction_encoder.encoder.layer.4.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.6.attention.self.value.weight', 'instruction_encoder.encoder.layer.12.attention.output.dense.bias', 'instruction_encoder.encoder.layer.15.output.dense.weight', 'instruction_encoder.encoder.layer.20.attention.self.value.weight', 'instruction_encoder.encoder.layer.20.attention.output.dense.weight', 'instruction_encoder.encoder.layer.13.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.20.attention.self.key.weight', 'instruction_encoder.encoder.layer.22.attention.self.key.weight', 'instruction_encoder.encoder.layer.21.output.dense.bias', 'instruction_encoder.encoder.layer.22.intermediate.dense.weight', 'instruction_encoder.encoder.layer.4.intermediate.dense.bias', 'instruction_encoder.encoder.layer.22.attention.self.key.bias', 'instruction_encoder.encoder.layer.19.intermediate.dense.weight', 'instruction_encoder.encoder.layer.5.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.14.attention.output.dense.bias', 'instruction_encoder.encoder.layer.1.attention.self.query.weight', 'instruction_encoder.encoder.layer.13.attention.output.LayerNorm.weight', 'cross_attention.attention.out_proj.bias', 'instruction_encoder.encoder.layer.8.attention.self.query.bias', 'instruction_encoder.encoder.layer.20.attention.output.dense.bias', 'instruction_encoder.encoder.layer.10.attention.self.value.bias', 'instruction_encoder.encoder.layer.21.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.4.attention.self.query.weight', 'instruction_encoder.encoder.layer.17.attention.output.dense.bias', 'instruction_encoder.encoder.layer.19.attention.self.value.bias', 'instruction_encoder.encoder.layer.11.attention.self.key.weight', 'instruction_encoder.encoder.layer.16.attention.self.key.bias', 'instruction_encoder.encoder.layer.13.attention.self.value.weight', 'cross_attention.attention.in_proj_bias', 'instruction_encoder.encoder.layer.22.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.7.attention.self.query.bias', 'instruction_encoder.encoder.layer.19.intermediate.dense.bias', 'instruction_encoder.encoder.layer.16.output.dense.weight', 'instruction_encoder.encoder.layer.5.output.dense.bias', 'instruction_encoder.encoder.layer.5.output.dense.weight', 'instruction_encoder.encoder.layer.19.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.3.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.3.attention.self.value.weight', 'instruction_encoder.encoder.layer.7.attention.output.dense.weight', 'instruction_encoder.encoder.layer.9.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.9.output.dense.weight', 'instruction_encoder.encoder.layer.13.attention.self.query.weight', 'instruction_encoder.encoder.layer.14.output.dense.weight', 'instruction_encoder.encoder.layer.10.intermediate.dense.bias', 'instruction_encoder.encoder.layer.17.output.dense.weight', 'instruction_encoder.encoder.layer.8.attention.self.value.bias', 'instruction_encoder.encoder.layer.3.attention.self.key.bias', 'instruction_encoder.encoder.layer.9.intermediate.dense.weight', 'instruction_encoder.encoder.layer.12.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.6.attention.self.query.bias', 'instruction_encoder.encoder.layer.20.attention.self.query.bias', 'instruction_encoder.encoder.layer.19.attention.self.query.bias', 'instruction_encoder.encoder.layer.15.output.dense.bias', 'instruction_encoder.encoder.layer.9.attention.self.value.weight', 'instruction_encoder.encoder.layer.7.attention.self.value.bias', 'instruction_encoder.encoder.layer.0.intermediate.dense.weight', 'instruction_encoder.encoder.layer.21.attention.self.key.bias', 'instruction_encoder.encoder.layer.8.output.dense.bias', 'instruction_encoder.encoder.layer.7.output.dense.bias', 'instruction_encoder.encoder.layer.11.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.5.attention.self.value.bias', 'instruction_encoder.encoder.layer.10.attention.output.dense.weight', 'instruction_encoder.encoder.layer.18.attention.output.dense.weight', 'instruction_encoder.encoder.layer.23.attention.self.value.bias', 'cross_attention.instruction_projection.weight', 'instruction_encoder.encoder.layer.16.intermediate.dense.weight', 'instruction_encoder.encoder.layer.1.attention.self.key.weight', 'instruction_encoder.encoder.layer.6.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.15.intermediate.dense.weight', 'instruction_encoder.encoder.layer.16.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.11.output.dense.bias', 'instruction_encoder.encoder.layer.21.intermediate.dense.bias', 'instruction_encoder.encoder.layer.0.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.6.output.dense.weight', 'instruction_encoder.pooler.dense.weight', 'instruction_encoder.encoder.layer.0.attention.self.query.bias', 'instruction_encoder.encoder.layer.1.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.15.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.23.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.4.output.dense.bias', 'instruction_encoder.encoder.layer.5.intermediate.dense.bias', 'instruction_encoder.encoder.layer.14.attention.self.value.bias', 'instruction_encoder.encoder.layer.11.output.dense.weight', 'instruction_encoder.encoder.layer.11.attention.self.key.bias', 'instruction_encoder.encoder.layer.18.attention.self.value.weight', 'instruction_encoder.encoder.layer.7.output.dense.weight', 'instruction_encoder.encoder.layer.10.attention.output.dense.bias', 'instruction_encoder.encoder.layer.12.attention.self.query.weight', 'instruction_encoder.encoder.layer.16.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.23.attention.self.query.weight', 'instruction_encoder.encoder.layer.14.attention.self.query.bias', 'instruction_encoder.encoder.layer.16.attention.self.query.bias', 'instruction_encoder.encoder.layer.4.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.0.output.dense.weight', 'instruction_encoder.encoder.layer.21.attention.output.dense.bias', 'instruction_encoder.encoder.layer.16.intermediate.dense.bias', 'instruction_encoder.encoder.layer.19.attention.output.dense.bias', 'instruction_encoder.encoder.layer.2.attention.output.dense.bias', 'instruction_encoder.encoder.layer.7.intermediate.dense.bias', 'instruction_encoder.encoder.layer.14.output.dense.bias', 'instruction_encoder.encoder.layer.10.attention.self.key.weight', 'instruction_encoder.encoder.layer.0.attention.self.query.weight', 'instruction_encoder.encoder.layer.14.intermediate.dense.weight', 'instruction_encoder.encoder.layer.7.attention.self.key.weight', 'instruction_encoder.encoder.layer.5.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.20.attention.self.key.bias', 'instruction_encoder.encoder.layer.4.attention.output.dense.bias', 'instruction_encoder.encoder.layer.10.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.9.attention.self.value.bias', 'instruction_encoder.encoder.layer.1.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.4.attention.output.dense.weight', 'instruction_encoder.encoder.layer.16.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.18.output.LayerNorm.bias', 'instruction_encoder.embeddings.LayerNorm.bias', 'instruction_encoder.encoder.layer.23.intermediate.dense.bias', 'instruction_encoder.encoder.layer.5.attention.self.query.weight', 'instruction_encoder.encoder.layer.14.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.1.attention.output.dense.weight', 'instruction_encoder.embeddings.LayerNorm.weight', 'instruction_encoder.embeddings.token_type_embeddings.weight', 'instruction_encoder.encoder.layer.0.output.dense.bias', 'instruction_encoder.encoder.layer.2.intermediate.dense.weight', 'instruction_encoder.encoder.layer.18.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.12.intermediate.dense.bias', 'instruction_encoder.encoder.layer.0.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.23.attention.output.dense.bias', 'instruction_encoder.encoder.layer.9.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.7.attention.self.value.weight', 'instruction_encoder.encoder.layer.3.attention.self.key.weight', 'instruction_encoder.encoder.layer.12.attention.output.dense.weight', 'instruction_encoder.encoder.layer.13.attention.self.query.bias', 'instruction_encoder.encoder.layer.10.attention.self.value.weight', 'instruction_encoder.encoder.layer.9.attention.output.dense.weight', 'instruction_encoder.encoder.layer.18.attention.output.dense.bias', 'instruction_encoder.encoder.layer.10.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.11.attention.self.value.weight', 'instruction_encoder.encoder.layer.5.attention.output.dense.bias', 'instruction_encoder.encoder.layer.13.intermediate.dense.bias', 'instruction_encoder.encoder.layer.23.attention.output.dense.weight', 'instruction_encoder.encoder.layer.19.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.15.attention.self.key.weight', 'instruction_encoder.encoder.layer.23.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.5.attention.self.value.weight', 'instruction_encoder.encoder.layer.5.attention.output.dense.weight', 'instruction_encoder.encoder.layer.13.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.3.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.11.intermediate.dense.bias', 'instruction_encoder.encoder.layer.15.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.21.attention.self.key.weight', 'instruction_encoder.encoder.layer.13.attention.output.dense.weight', 'instruction_encoder.encoder.layer.4.output.dense.weight', 'instruction_encoder.encoder.layer.23.output.dense.weight', 'instruction_encoder.encoder.layer.2.attention.self.value.bias', 'instruction_encoder.encoder.layer.10.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.18.attention.self.key.bias', 'instruction_encoder.encoder.layer.7.attention.output.dense.bias', 'instruction_encoder.encoder.layer.6.intermediate.dense.bias', 'instruction_linear.bias', 'instruction_encoder.encoder.layer.13.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.11.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.19.attention.self.query.weight', 'instruction_encoder.encoder.layer.14.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.2.attention.self.query.bias', 'instruction_encoder.encoder.layer.2.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.10.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.8.attention.output.dense.bias', 'instruction_encoder.encoder.layer.8.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.14.attention.self.key.weight', 'instruction_encoder.encoder.layer.9.attention.self.key.bias', 'instruction_encoder.encoder.layer.22.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.1.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.8.output.dense.weight', 'instruction_encoder.encoder.layer.18.attention.self.query.bias', 'instruction_encoder.encoder.layer.20.intermediate.dense.weight', 'instruction_encoder.encoder.layer.22.attention.self.value.weight', 'instruction_encoder.encoder.layer.17.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.17.attention.self.query.weight', 'instruction_encoder.encoder.layer.2.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.11.attention.self.query.bias', 'instruction_encoder.encoder.layer.18.attention.self.key.weight', 'instruction_encoder.encoder.layer.12.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.6.attention.output.dense.weight', 'instruction_encoder.encoder.layer.13.attention.self.key.weight', 'instruction_encoder.encoder.layer.14.attention.self.key.bias', 'instruction_encoder.encoder.layer.20.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.17.intermediate.dense.bias', 'instruction_encoder.encoder.layer.23.output.dense.bias', 'instruction_encoder.encoder.layer.3.attention.output.dense.weight', 'instruction_encoder.encoder.layer.16.attention.self.query.weight', 'instruction_encoder.encoder.layer.13.attention.self.key.bias', 'instruction_encoder.encoder.layer.5.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.16.output.dense.bias', 'instruction_encoder.encoder.layer.1.attention.self.key.bias', 'instruction_encoder.encoder.layer.4.attention.self.key.bias', 'instruction_encoder.encoder.layer.3.attention.self.query.bias', 'instruction_encoder.encoder.layer.8.intermediate.dense.bias', 'instruction_encoder.encoder.layer.20.output.dense.weight', 'instruction_encoder.encoder.layer.4.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.12.attention.self.value.bias', 'instruction_encoder.encoder.layer.21.intermediate.dense.weight', 'instruction_encoder.encoder.layer.8.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.23.attention.self.value.weight', 'instruction_encoder.encoder.layer.2.output.dense.weight', 'instruction_encoder.encoder.layer.5.attention.self.key.weight', 'instruction_encoder.encoder.layer.18.output.dense.weight', 'instruction_encoder.encoder.layer.15.attention.self.value.weight', 'instruction_encoder.encoder.layer.16.attention.self.value.weight', 'instruction_encoder.embeddings.word_embeddings.weight', 'instruction_encoder.encoder.layer.5.attention.self.query.bias', 'instruction_encoder.encoder.layer.17.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.17.output.dense.bias', 'instruction_encoder.encoder.layer.17.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.0.attention.self.key.weight', 'instruction_encoder.encoder.layer.6.attention.self.key.weight', 'instruction_encoder.encoder.layer.7.attention.self.key.bias', 'instruction_encoder.encoder.layer.9.output.dense.bias', 'instruction_encoder.encoder.layer.4.output.LayerNorm.bias', 'cross_attention.attention.out_proj.weight', 'instruction_encoder.encoder.layer.3.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.7.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.10.attention.self.key.bias', 'instruction_encoder.encoder.layer.23.output.LayerNorm.weight', 'instruction_encoder.embeddings.position_embeddings.weight', 'instruction_encoder.encoder.layer.20.intermediate.dense.bias', 'instruction_encoder.encoder.layer.23.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.23.intermediate.dense.weight', 'instruction_encoder.encoder.layer.22.output.dense.bias', 'instruction_encoder.encoder.layer.16.attention.output.dense.bias', 'instruction_encoder.encoder.layer.3.attention.output.dense.bias', 'instruction_encoder.encoder.layer.22.attention.self.query.bias', 'instruction_encoder.encoder.layer.9.attention.self.key.weight', 'instruction_encoder.encoder.layer.16.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.7.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.14.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.18.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.20.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.1.attention.self.value.bias', 'instruction_encoder.encoder.layer.17.attention.output.dense.weight', 'instruction_encoder.encoder.layer.13.output.dense.bias', 'instruction_encoder.encoder.layer.19.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.3.attention.self.query.weight', 'instruction_encoder.encoder.layer.1.output.dense.bias', 'instruction_encoder.encoder.layer.7.intermediate.dense.weight', 'instruction_encoder.encoder.layer.17.attention.self.query.bias', 'instruction_encoder.encoder.layer.7.attention.self.query.weight', 'instruction_encoder.encoder.layer.11.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.1.attention.output.dense.bias', 'instruction_encoder.encoder.layer.14.attention.output.dense.weight', 'instruction_encoder.encoder.layer.22.attention.self.value.bias', 'instruction_encoder.encoder.layer.14.attention.self.value.weight', 'instruction_encoder.encoder.layer.22.output.dense.weight', 'instruction_encoder.encoder.layer.23.attention.self.query.bias', 'instruction_encoder.encoder.layer.11.attention.self.value.bias', 'instruction_encoder.encoder.layer.21.attention.self.query.weight', 'instruction_encoder.encoder.layer.17.attention.self.value.weight', 'instruction_encoder.encoder.layer.22.attention.self.query.weight', 'instruction_encoder.encoder.layer.0.attention.self.value.bias', 'instruction_encoder.encoder.layer.10.attention.self.query.weight', 'instruction_encoder.encoder.layer.11.intermediate.dense.weight', 'instruction_encoder.encoder.layer.6.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.20.attention.self.value.bias', 'instruction_encoder.encoder.layer.21.attention.self.value.bias', 'instruction_encoder.encoder.layer.18.attention.self.value.bias', 'instruction_encoder.encoder.layer.9.attention.output.LayerNorm.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of HF_ColBERT were not initialized from the model checkpoint at colbert-ir/colbertv2.0 and are newly initialized: ['instruction_encoder.encoder.layer.20.attention.self.query.bias', 'instruction_encoder.encoder.layer.2.attention.self.query.weight', 'instruction_encoder.encoder.layer.20.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.7.attention.self.key.weight', 'instruction_encoder.encoder.layer.13.attention.self.value.weight', 'instruction_encoder.encoder.layer.9.attention.self.value.weight', 'instruction_encoder.encoder.layer.11.attention.self.query.weight', 'instruction_encoder.encoder.layer.17.attention.self.value.bias', 'instruction_encoder.encoder.layer.10.intermediate.dense.weight', 'instruction_encoder.encoder.layer.14.attention.self.key.weight', 'instruction_encoder.encoder.layer.23.attention.self.key.bias', 'instruction_encoder.encoder.layer.1.attention.self.query.weight', 'instruction_encoder.encoder.layer.1.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.0.attention.self.query.weight', 'instruction_encoder.encoder.layer.15.attention.output.dense.bias', 'instruction_encoder.encoder.layer.0.attention.self.value.bias', 'instruction_encoder.encoder.layer.23.attention.self.key.weight', 'instruction_encoder.encoder.layer.7.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.2.intermediate.dense.bias', 'instruction_encoder.encoder.layer.5.attention.self.value.bias', 'instruction_encoder.encoder.layer.0.attention.self.value.weight', 'instruction_encoder.encoder.layer.0.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.3.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.10.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.21.attention.self.key.bias', 'instruction_encoder.encoder.layer.23.attention.output.dense.weight', 'instruction_encoder.encoder.layer.1.attention.self.key.weight', 'instruction_encoder.encoder.layer.8.attention.self.value.bias', 'instruction_encoder.encoder.layer.5.attention.self.query.weight', 'instruction_encoder.encoder.layer.1.output.dense.weight', 'instruction_encoder.encoder.layer.7.output.dense.weight', 'instruction_encoder.encoder.layer.12.intermediate.dense.bias', 'instruction_encoder.encoder.layer.3.attention.self.query.bias', 'instruction_encoder.encoder.layer.16.attention.self.query.bias', 'instruction_encoder.encoder.layer.22.attention.self.value.weight', 'instruction_encoder.encoder.layer.19.intermediate.dense.weight', 'instruction_encoder.encoder.layer.19.attention.output.dense.bias', 'instruction_encoder.encoder.layer.15.output.dense.weight', 'instruction_encoder.encoder.layer.8.intermediate.dense.bias', 'instruction_encoder.encoder.layer.5.attention.self.value.weight', 'instruction_encoder.encoder.layer.16.attention.self.value.weight', 'instruction_encoder.encoder.layer.21.attention.output.dense.bias', 'instruction_encoder.encoder.layer.12.attention.output.dense.weight', 'cross_attention.attention.out_proj.bias', 'instruction_encoder.encoder.layer.0.output.dense.bias', 'instruction_encoder.encoder.layer.15.attention.self.value.weight', 'instruction_encoder.encoder.layer.7.attention.self.value.weight', 'instruction_encoder.encoder.layer.1.attention.self.value.weight', 'instruction_encoder.encoder.layer.12.attention.output.dense.bias', 'instruction_encoder.encoder.layer.17.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.10.attention.self.query.bias', 'instruction_encoder.encoder.layer.22.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.21.intermediate.dense.weight', 'instruction_encoder.encoder.layer.16.attention.self.query.weight', 'instruction_encoder.encoder.layer.7.attention.output.dense.bias', 'instruction_encoder.encoder.layer.10.attention.self.key.weight', 'instruction_encoder.pooler.dense.weight', 'instruction_encoder.encoder.layer.17.attention.self.key.bias', 'instruction_encoder.embeddings.LayerNorm.bias', 'instruction_encoder.encoder.layer.7.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.21.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.23.intermediate.dense.bias', 'instruction_encoder.encoder.layer.20.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.15.intermediate.dense.weight', 'instruction_encoder.encoder.layer.11.attention.output.dense.weight', 'instruction_encoder.encoder.layer.21.attention.self.query.bias', 'instruction_encoder.encoder.layer.22.attention.output.dense.weight', 'instruction_encoder.encoder.layer.0.attention.output.dense.bias', 'instruction_encoder.encoder.layer.4.attention.self.query.weight', 'instruction_encoder.encoder.layer.12.attention.self.query.bias', 'instruction_encoder.encoder.layer.15.intermediate.dense.bias', 'instruction_encoder.encoder.layer.13.attention.output.dense.weight', 'instruction_encoder.encoder.layer.14.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.11.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.23.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.21.attention.self.value.weight', 'instruction_encoder.encoder.layer.4.output.dense.weight', 'instruction_encoder.encoder.layer.20.attention.self.key.bias', 'instruction_encoder.encoder.layer.22.attention.self.key.bias', 'instruction_encoder.encoder.layer.10.attention.self.key.bias', 'instruction_encoder.encoder.layer.2.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.15.attention.self.query.weight', 'instruction_encoder.encoder.layer.21.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.11.attention.self.query.bias', 'instruction_encoder.encoder.layer.15.output.LayerNorm.weight', 'cross_attention.attention.out_proj.weight', 'instruction_encoder.encoder.layer.18.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.7.output.dense.bias', 'instruction_encoder.encoder.layer.18.attention.self.value.bias', 'instruction_encoder.encoder.layer.0.attention.output.dense.weight', 'instruction_encoder.encoder.layer.9.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.1.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.7.intermediate.dense.weight', 'instruction_encoder.encoder.layer.8.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.12.attention.self.query.weight', 'instruction_encoder.encoder.layer.14.output.dense.weight', 'instruction_encoder.encoder.layer.6.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.9.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.18.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.9.attention.self.value.bias', 'instruction_encoder.encoder.layer.23.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.3.attention.self.value.weight', 'instruction_encoder.encoder.layer.3.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.22.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.1.attention.output.dense.weight', 'instruction_encoder.encoder.layer.0.intermediate.dense.bias', 'instruction_encoder.encoder.layer.12.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.10.attention.output.dense.weight', 'instruction_encoder.encoder.layer.2.attention.output.dense.weight', 'instruction_encoder.encoder.layer.17.output.dense.weight', 'instruction_encoder.encoder.layer.6.attention.self.value.weight', 'instruction_encoder.encoder.layer.17.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.9.attention.self.query.bias', 'instruction_encoder.encoder.layer.22.intermediate.dense.weight', 'instruction_encoder.encoder.layer.16.attention.self.key.bias', 'cross_attention.instruction_projection.bias', 'instruction_encoder.encoder.layer.6.attention.output.dense.bias', 'instruction_encoder.encoder.layer.19.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.21.attention.output.dense.weight', 'instruction_encoder.encoder.layer.23.attention.self.query.weight', 'instruction_encoder.encoder.layer.1.attention.self.query.bias', 'instruction_encoder.encoder.layer.19.attention.output.dense.weight', 'instruction_encoder.encoder.layer.4.attention.self.value.bias', 'instruction_encoder.encoder.layer.4.attention.self.key.bias', 'instruction_encoder.encoder.layer.15.attention.self.value.bias', 'instruction_encoder.encoder.layer.3.intermediate.dense.weight', 'instruction_encoder.encoder.layer.11.attention.self.value.weight', 'instruction_encoder.encoder.layer.9.attention.output.dense.bias', 'instruction_encoder.encoder.layer.21.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.17.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.19.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.3.attention.output.dense.weight', 'instruction_encoder.encoder.layer.3.attention.self.value.bias', 'instruction_encoder.encoder.layer.23.output.dense.bias', 'instruction_encoder.encoder.layer.13.attention.self.key.bias', 'instruction_encoder.encoder.layer.13.attention.self.query.weight', 'instruction_encoder.encoder.layer.12.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.8.attention.self.query.bias', 'instruction_encoder.encoder.layer.11.attention.output.dense.bias', 'instruction_encoder.encoder.layer.2.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.14.intermediate.dense.weight', 'instruction_encoder.encoder.layer.4.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.16.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.13.output.dense.weight', 'instruction_encoder.encoder.layer.12.output.dense.weight', 'instruction_encoder.encoder.layer.19.attention.self.value.bias', 'instruction_encoder.encoder.layer.9.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.16.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.9.output.dense.weight', 'instruction_encoder.encoder.layer.9.attention.self.query.weight', 'instruction_encoder.encoder.layer.10.output.dense.bias', 'instruction_encoder.encoder.layer.13.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.4.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.11.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.9.attention.output.dense.weight', 'instruction_encoder.encoder.layer.11.output.dense.weight', 'instruction_encoder.encoder.layer.16.attention.output.dense.bias', 'instruction_encoder.encoder.layer.16.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.21.attention.self.query.weight', 'instruction_encoder.encoder.layer.18.attention.self.query.weight', 'instruction_encoder.encoder.layer.14.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.2.attention.self.query.bias', 'instruction_encoder.encoder.layer.6.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.14.attention.output.dense.bias', 'instruction_encoder.encoder.layer.4.attention.output.dense.weight', 'instruction_encoder.encoder.layer.1.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.17.intermediate.dense.weight', 'instruction_encoder.encoder.layer.6.attention.self.key.bias', 'instruction_encoder.encoder.layer.18.attention.self.key.weight', 'instruction_encoder.encoder.layer.6.attention.self.value.bias', 'instruction_encoder.encoder.layer.23.output.dense.weight', 'instruction_encoder.encoder.layer.10.intermediate.dense.bias', 'instruction_encoder.encoder.layer.2.output.dense.weight', 'instruction_encoder.encoder.layer.19.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.16.output.dense.weight', 'instruction_encoder.encoder.layer.3.attention.self.query.weight', 'instruction_encoder.encoder.layer.10.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.17.attention.self.key.weight', 'instruction_encoder.encoder.layer.22.output.dense.bias', 'instruction_encoder.encoder.layer.5.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.2.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.3.output.dense.bias', 'instruction_encoder.encoder.layer.17.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.4.output.dense.bias', 'instruction_encoder.encoder.layer.17.attention.output.dense.bias', 'instruction_encoder.encoder.layer.9.output.dense.bias', 'instruction_encoder.encoder.layer.16.intermediate.dense.bias', 'instruction_encoder.encoder.layer.15.attention.self.key.bias', 'instruction_encoder.encoder.layer.19.output.dense.weight', 'instruction_encoder.encoder.layer.15.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.7.attention.self.query.weight', 'instruction_encoder.encoder.layer.15.attention.self.query.bias', 'instruction_encoder.encoder.layer.21.attention.self.key.weight', 'instruction_encoder.encoder.layer.20.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.20.attention.output.dense.weight', 'instruction_encoder.encoder.layer.13.attention.self.value.bias', 'instruction_encoder.encoder.layer.17.attention.output.dense.weight', 'instruction_encoder.encoder.layer.18.attention.self.key.bias', 'instruction_encoder.encoder.layer.2.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.7.attention.self.key.bias', 'instruction_encoder.encoder.layer.11.attention.self.key.weight', 'instruction_encoder.encoder.layer.2.attention.self.key.weight', 'instruction_encoder.encoder.layer.2.attention.output.dense.bias', 'instruction_encoder.encoder.layer.22.attention.output.dense.bias', 'instruction_encoder.encoder.layer.20.intermediate.dense.bias', 'instruction_encoder.encoder.layer.4.attention.self.query.bias', 'instruction_encoder.encoder.layer.4.attention.output.dense.bias', 'instruction_encoder.encoder.layer.8.intermediate.dense.weight', 'instruction_encoder.encoder.layer.13.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.12.attention.self.key.weight', 'instruction_encoder.encoder.layer.20.attention.output.dense.bias', 'instruction_encoder.encoder.layer.16.intermediate.dense.weight', 'instruction_encoder.encoder.layer.6.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.23.attention.output.dense.bias', 'instruction_encoder.encoder.layer.0.attention.self.key.bias', 'instruction_encoder.encoder.layer.18.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.9.attention.self.key.bias', 'instruction_linear.weight', 'instruction_encoder.encoder.layer.11.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.20.attention.self.value.bias', 'instruction_encoder.encoder.layer.14.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.18.output.dense.bias', 'instruction_encoder.encoder.layer.3.intermediate.dense.bias', 'instruction_encoder.encoder.layer.16.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.20.attention.self.key.weight', 'instruction_encoder.encoder.layer.5.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.21.intermediate.dense.bias', 'instruction_encoder.encoder.layer.22.attention.self.value.bias', 'instruction_encoder.encoder.layer.0.attention.self.query.bias', 'instruction_encoder.encoder.layer.9.intermediate.dense.weight', 'instruction_encoder.encoder.layer.17.attention.self.query.bias', 'instruction_encoder.encoder.layer.11.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.0.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.13.attention.output.dense.bias', 'instruction_encoder.encoder.layer.15.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.0.output.dense.weight', 'instruction_encoder.encoder.layer.3.attention.self.key.weight', 'instruction_encoder.encoder.layer.20.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.6.intermediate.dense.bias', 'instruction_encoder.encoder.layer.13.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.23.attention.self.value.weight', 'instruction_encoder.encoder.layer.19.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.8.attention.output.dense.weight', 'instruction_encoder.encoder.layer.12.output.dense.bias', 'instruction_encoder.encoder.layer.13.intermediate.dense.bias', 'instruction_encoder.encoder.layer.22.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.11.intermediate.dense.bias', 'instruction_encoder.encoder.layer.7.attention.self.query.bias', 'instruction_encoder.encoder.layer.15.attention.output.dense.weight', 'instruction_encoder.encoder.layer.14.attention.self.query.bias', 'instruction_encoder.encoder.layer.16.attention.self.value.bias', 'instruction_encoder.embeddings.token_type_embeddings.weight', 'instruction_encoder.encoder.layer.6.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.6.intermediate.dense.weight', 'instruction_encoder.encoder.layer.10.attention.self.value.bias', 'instruction_encoder.encoder.layer.21.output.dense.bias', 'instruction_encoder.encoder.layer.7.intermediate.dense.bias', 'instruction_encoder.encoder.layer.9.intermediate.dense.bias', 'instruction_encoder.encoder.layer.11.output.dense.bias', 'instruction_encoder.encoder.layer.17.attention.self.value.weight', 'instruction_encoder.encoder.layer.4.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.9.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.4.attention.self.value.weight', 'instruction_encoder.encoder.layer.11.attention.self.key.bias', 'instruction_encoder.encoder.layer.1.intermediate.dense.weight', 'instruction_encoder.encoder.layer.20.intermediate.dense.weight', 'instruction_encoder.encoder.layer.10.output.dense.weight', 'instruction_encoder.encoder.layer.5.output.dense.bias', 'instruction_encoder.encoder.layer.9.attention.self.key.weight', 'instruction_encoder.encoder.layer.2.intermediate.dense.weight', 'instruction_encoder.encoder.layer.6.attention.self.query.bias', 'instruction_encoder.embeddings.position_embeddings.weight', 'instruction_encoder.encoder.layer.12.attention.self.value.weight', 'instruction_encoder.encoder.layer.4.intermediate.dense.weight', 'instruction_encoder.encoder.layer.20.output.dense.weight', 'instruction_encoder.encoder.layer.18.output.dense.weight', 'instruction_encoder.encoder.layer.6.attention.self.query.weight', 'instruction_encoder.encoder.layer.7.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.17.output.dense.bias', 'cross_attention.attention.in_proj_weight', 'instruction_encoder.encoder.layer.2.attention.self.value.weight', 'instruction_encoder.encoder.layer.18.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.1.output.dense.bias', 'instruction_encoder.encoder.layer.5.output.dense.weight', 'instruction_encoder.encoder.layer.19.attention.self.key.bias', 'instruction_encoder.encoder.layer.10.attention.self.query.weight', 'instruction_encoder.encoder.layer.8.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.14.attention.self.query.weight', 'instruction_encoder.embeddings.LayerNorm.weight', 'instruction_encoder.encoder.layer.22.intermediate.dense.bias', 'instruction_encoder.encoder.layer.10.attention.output.dense.bias', 'instruction_encoder.encoder.layer.19.attention.self.key.weight', 'cross_attention.attention.in_proj_bias', 'instruction_encoder.encoder.layer.13.output.dense.bias', 'instruction_encoder.encoder.layer.22.attention.self.query.bias', 'instruction_encoder.encoder.layer.13.attention.self.key.weight', 'instruction_encoder.encoder.layer.12.attention.self.value.bias', 'instruction_encoder.encoder.layer.7.attention.self.value.bias', 'instruction_encoder.encoder.layer.17.attention.self.query.weight', 'instruction_encoder.encoder.layer.15.attention.self.key.weight', 'instruction_encoder.encoder.layer.14.attention.self.value.weight', 'instruction_encoder.encoder.layer.14.attention.output.dense.weight', 'instruction_encoder.encoder.layer.18.attention.output.dense.weight', 'instruction_encoder.encoder.layer.22.output.dense.weight', 'instruction_encoder.encoder.layer.14.attention.self.key.bias', 'instruction_encoder.encoder.layer.10.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.12.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.3.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.8.attention.self.key.bias', 'cross_attention.instruction_projection.weight', 'instruction_encoder.encoder.layer.5.attention.self.query.bias', 'instruction_encoder.encoder.layer.12.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.18.intermediate.dense.weight', 'instruction_encoder.encoder.layer.5.intermediate.dense.bias', 'instruction_encoder.encoder.layer.18.attention.output.dense.bias', 'instruction_encoder.encoder.layer.19.attention.self.query.bias', 'instruction_encoder.encoder.layer.23.attention.self.query.bias', 'instruction_encoder.encoder.layer.5.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.1.intermediate.dense.bias', 'instruction_encoder.encoder.layer.3.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.12.intermediate.dense.weight', 'instruction_encoder.encoder.layer.6.output.dense.weight', 'instruction_encoder.encoder.layer.18.attention.self.query.bias', 'instruction_encoder.encoder.layer.15.output.dense.bias', 'instruction_encoder.encoder.layer.22.attention.self.query.weight', 'instruction_encoder.encoder.layer.10.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.2.output.dense.bias', 'instruction_encoder.encoder.layer.11.attention.self.value.bias', 'instruction_encoder.encoder.layer.8.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.2.attention.self.key.bias', 'instruction_encoder.encoder.layer.14.intermediate.dense.bias', 'instruction_encoder.encoder.layer.4.intermediate.dense.bias', 'instruction_encoder.encoder.layer.8.output.dense.bias', 'instruction_encoder.encoder.layer.21.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.6.output.dense.bias', 'instruction_encoder.encoder.layer.3.output.dense.weight', 'instruction_encoder.encoder.layer.19.attention.self.value.weight', 'instruction_encoder.encoder.layer.0.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.8.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.17.intermediate.dense.bias', 'instruction_encoder.encoder.layer.16.output.dense.bias', 'instruction_encoder.encoder.layer.22.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.18.attention.self.value.weight', 'instruction_linear.bias', 'instruction_encoder.encoder.layer.20.attention.self.query.weight', 'instruction_encoder.encoder.layer.19.intermediate.dense.bias', 'instruction_encoder.encoder.layer.8.attention.output.dense.bias', 'instruction_encoder.encoder.layer.21.output.dense.weight', 'instruction_encoder.encoder.layer.0.intermediate.dense.weight', 'instruction_encoder.encoder.layer.8.output.dense.weight', 'instruction_encoder.encoder.layer.22.attention.self.key.weight', 'instruction_encoder.encoder.layer.5.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.8.attention.self.key.weight', 'instruction_encoder.encoder.layer.3.attention.output.dense.bias', 'instruction_encoder.encoder.layer.8.attention.self.value.weight', 'instruction_encoder.encoder.layer.14.attention.self.value.bias', 'instruction_encoder.encoder.layer.1.attention.output.dense.bias', 'instruction_encoder.encoder.layer.3.attention.self.key.bias', 'instruction_encoder.encoder.layer.13.attention.self.query.bias', 'instruction_encoder.encoder.layer.11.intermediate.dense.weight', 'instruction_encoder.encoder.layer.13.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.13.intermediate.dense.weight', 'instruction_encoder.encoder.layer.1.attention.self.key.bias', 'instruction_encoder.encoder.layer.0.attention.self.key.weight', 'instruction_encoder.encoder.layer.20.output.dense.bias', 'instruction_encoder.encoder.layer.23.attention.self.value.bias', 'instruction_encoder.encoder.layer.2.attention.self.value.bias', 'instruction_encoder.encoder.layer.6.attention.self.key.weight', 'instruction_encoder.encoder.layer.14.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.8.attention.self.query.weight', 'instruction_encoder.encoder.layer.15.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.20.attention.self.value.weight', 'instruction_encoder.encoder.layer.23.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.10.attention.self.value.weight', 'instruction_encoder.encoder.layer.12.attention.self.key.bias', 'instruction_encoder.encoder.layer.0.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.5.attention.self.key.weight', 'instruction_encoder.encoder.layer.4.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.1.attention.self.value.bias', 'instruction_encoder.encoder.layer.5.intermediate.dense.weight', 'instruction_encoder.encoder.layer.4.attention.self.key.weight', 'instruction_encoder.embeddings.word_embeddings.weight', 'instruction_encoder.encoder.layer.5.attention.output.dense.weight', 'instruction_encoder.encoder.layer.5.attention.self.key.bias', 'instruction_encoder.encoder.layer.16.attention.self.key.weight', 'instruction_encoder.encoder.layer.1.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.21.attention.self.value.bias', 'instruction_encoder.encoder.layer.16.attention.output.dense.weight', 'instruction_encoder.encoder.layer.18.intermediate.dense.bias', 'instruction_encoder.encoder.layer.14.output.dense.bias', 'instruction_encoder.encoder.layer.23.intermediate.dense.weight', 'instruction_encoder.pooler.dense.bias', 'instruction_encoder.encoder.layer.19.attention.self.query.weight', 'instruction_encoder.encoder.layer.23.attention.output.LayerNorm.weight', 'instruction_encoder.encoder.layer.19.output.dense.bias', 'instruction_encoder.encoder.layer.6.attention.output.dense.weight', 'instruction_encoder.encoder.layer.7.attention.output.LayerNorm.bias', 'instruction_encoder.encoder.layer.7.attention.output.dense.weight', 'instruction_encoder.encoder.layer.5.attention.output.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/usr/local/share/miniconda/envs/mcol/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
/usr/local/share/miniconda/envs/mcol/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(

Qwen/Qwen1.5-1.8B-Chat
{'instruction_model': 'Qwen/Qwen1.5-1.8B-Chat'}
#> LR will use 100 warmup steps and linear decay over 500000 steps.
True

#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: . what is the science of mapmaking called, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2003,  1996,  2671,  1997,  4949, 12614,  2170,
          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')

				 0.5302426815032959 6.217868328094482
#>>>    4.23 4.0 		|		 0.23000000000000043
[Mar 29, 22:22:23] 0 6.748110771179199
True
				 0.5580023527145386 5.683130264282227
#>>>    4.18 4.01 		|		 0.16999999999999993
[Mar 29, 22:22:24] 1 6.7476037931442265
True
				 0.8265413045883179 6.289978504180908
#>>>    3.99 4.36 		|		 -0.3700000000000001
[Mar 29, 22:22:25] 2 6.747972709279061
True
				 0.525357186794281 5.679942607879639
#>>>    4.29 4.1 		|		 0.1900000000000004
[Mar 29, 22:22:25] 3 6.747430036424061
True
				 0.5834604501724243 6.342393398284912
#>>>    4.0 3.92 		|		 0.08000000000000007
[Mar 29, 22:22:26] 4 6.747608460116885
True
				 0.521706223487854 5.886639595031738
#>>>    4.58 4.53 		|		 0.04999999999999982
[Mar 29, 22:22:27] 5 6.747269197356078
True
				 0.4795704782009125 5.999866008758545
#>>>    4.57 4.47 		|		 0.10000000000000053
[Mar 29, 22:22:28] 6 6.747001364556275
True
				 0.513605535030365 5.956616401672363
#>>>    4.58 4.41 		|		 0.16999999999999993
[Mar 29, 22:22:28] 7 6.746724585188026
True
				 0.6153508424758911 6.6621174812316895
#>>>    4.29 4.34 		|		 -0.04999999999999982
[Mar 29, 22:22:29] 8 6.747255328807337
True
				 0.4118916392326355 5.561220645904541
#>>>    4.45 4.53 		|		 -0.08000000000000007
[Mar 29, 22:22:30] 9 6.7464811855848525
True
				 0.46645283699035645 5.895495891571045
#>>>    3.89 4.04 		|		 -0.1499999999999999
[Mar 29, 22:22:30] 10 6.746096653366247
True
				 0.48525047302246094 5.905421257019043
#>>>    4.01 4.1 		|		 -0.08999999999999986
[Mar 29, 22:22:31] 11 6.745741228442923
True
				 0.4280765652656555 5.641881942749023
#>>>    4.04 4.4 		|		 -0.3600000000000003
[Mar 29, 22:22:32] 12 6.745065445901309
True
				 0.5032367706298828 5.870759963989258
#>>>    4.0 4.21 		|		 -0.20999999999999996
[Mar 29, 22:22:33] 13 6.744694377190027
True
				 0.6282477378845215 5.575562000274658
#>>>    4.74 4.44 		|		 0.2999999999999998
[Mar 29, 22:22:33] 14 6.744153492550996
True
				 0.41520529985427856 5.8160080909729
#>>>    3.87 4.25 		|		 -0.3799999999999999
[Mar 29, 22:22:34] 15 6.743640552628086
True
				 0.3646036982536316 5.735701560974121
#>>>    4.48 4.6 		|		 -0.11999999999999922
[Mar 29, 22:22:35] 16 6.742997217155872
True
				 0.4221224784851074 5.777340412139893
#>>>    4.35 4.4 		|		 -0.05000000000000071
[Mar 29, 22:22:36] 17 6.742453682829341
True
				 0.6104676723480225 5.86918830871582
#>>>    4.92 4.54 		|		 0.3799999999999999
[Mar 29, 22:22:36] 18 6.742190885365994
True
				 0.4223070740699768 6.158771514892578
#>>>    4.15 4.63 		|		 -0.47999999999999954
[Mar 29, 22:22:37] 19 6.742029773009985
True
				 0.6440295577049255 5.928102493286133
#>>>    4.19 4.04 		|		 0.15000000000000036
[Mar 29, 22:22:38] 20 6.741859875347571
True
				 0.4720088541507721 5.707634449005127
#>>>    4.38 4.71 		|		 -0.33000000000000007
[Mar 29, 22:22:39] 21 6.741297658626368
True
				 0.36541062593460083 5.464066028594971
#>>>    4.88 4.74 		|		 0.13999999999999968
[Mar 29, 22:22:39] 22 6.740385837801085
True
				 0.41110727190971375 5.362590312957764
#>>>    4.54 4.2 		|		 0.33999999999999986
[Mar 29, 22:22:40] 23 6.739419149339535
True
				 0.4567134380340576 5.585366725921631
#>>>    4.41 4.7 		|		 -0.29000000000000004
[Mar 29, 22:22:41] 24 6.738721810115733
True
				 0.42648792266845703 5.700292587280273
#>>>    4.46 4.41 		|		 0.04999999999999982
[Mar 29, 22:22:42] 25 6.738109868815565
True
				 0.49442118406295776 5.761111259460449
#>>>    4.39 4.05 		|		 0.33999999999999986
[Mar 29, 22:22:42] 26 6.737627291211458
True
				 0.5228810906410217 5.98621940612793
#>>>    4.52 4.65 		|		 -0.13000000000000078
[Mar 29, 22:22:43] 27 6.737398764357412
True
				 0.35166260600090027 5.494774341583252
#>>>    5.02 4.88 		|		 0.13999999999999968
[Mar 29, 22:22:44] 28 6.736507802570441
True
				 0.33876341581344604 5.581374168395996
#>>>    4.62 4.67 		|		 -0.04999999999999982
[Mar 29, 22:22:44] 29 6.735691432173265
True
				 0.3552556037902832 5.382285118103027
#>>>    4.85 4.87 		|		 -0.020000000000000462
[Mar 29, 22:22:45] 30 6.7346932814629845
True
				 0.35438022017478943 5.384002208709717
#>>>    4.84 4.88 		|		 -0.040000000000000036
[Mar 29, 22:22:46] 31 6.733696970520999
True
				 0.4370447099208832 5.384244918823242
#>>>    5.13 5.03 		|		 0.09999999999999964
[Mar 29, 22:22:47] 32 6.732784563089815
True
				 0.4544776678085327 5.416796684265137
#>>>    4.98 4.77 		|		 0.21000000000000085
[Mar 29, 22:22:47] 33 6.731923052998009
True
				 0.31397292017936707 5.4390130043029785
#>>>    5.12 4.67 		|		 0.4500000000000002
[Mar 29, 22:22:48] 34 6.7309441158992955
True
				 0.4361380338668823 5.479814052581787
#>>>    4.8 4.91 		|		 -0.11000000000000032
[Mar 29, 22:22:49] 35 6.730129123989054
True
				 0.362883597612381 5.270014762878418
#>>>    5.76 6.11 		|		 -0.35000000000000053
[Mar 29, 22:22:50] 36 6.729031893195754
True
				 0.31893643736839294 5.541662216186523
#>>>    5.64 5.76 		|		 -0.1200000000000001
[Mar 29, 22:22:50] 37 6.728163459866706
True
				 0.36750590801239014 5.295298099517822
#>>>    5.39 5.19 		|		 0.1999999999999993
[Mar 29, 22:22:51] 38 6.727098100533579
True
				 0.39943841099739075 5.284040927886963
#>>>    5.6 5.29 		|		 0.3099999999999996
[Mar 29, 22:22:52] 39 6.726054481742127
True
				 0.3519640564918518 5.241296768188477
#>>>    5.87 5.67 		|		 0.20000000000000018
[Mar 29, 22:22:53] 40 6.72492168802546
True
				 0.3928023874759674 5.2909440994262695
#>>>    5.86 5.57 		|		 0.29000000000000004
[Mar 29, 22:22:53] 41 6.723880512675325
True
				 0.4083009958267212 5.4790849685668945
#>>>    5.57 5.53 		|		 0.040000000000000036
[Mar 29, 22:22:54] 42 6.723044018007834
True
				 0.38973191380500793 5.487048625946045
#>>>    5.5 5.47 		|		 0.03000000000000025
[Mar 29, 22:22:55] 43 6.722197754499775
True
				 0.3181678056716919 5.312963962554932
#>>>    5.94 5.88 		|		 0.0600000000000005
[Mar 29, 22:22:55] 44 6.7211066883942925
True
				 0.23563775420188904 5.099743843078613
#>>>    5.92 5.66 		|		 0.2599999999999998
[Mar 29, 22:22:56] 45 6.719720963213772
True
				 0.3272831439971924 5.31093692779541
#>>>    5.71 5.65 		|		 0.05999999999999961
[Mar 29, 22:22:57] 46 6.7186394620839325
True
				 0.239627867937088 5.252948760986328
#>>>    6.1 6.28 		|		 -0.1800000000000006
[Mar 29, 22:22:58] 47 6.71741339922097
True
				 0.3307797312736511 5.224320411682129
#>>>    6.28 6.36 		|		 -0.08000000000000007
[Mar 29, 22:22:58] 48 6.716251085785891
True
				 0.3581825792789459 5.266636848449707
#>>>    5.5 5.5 		|		 0.0
[Mar 29, 22:22:59] 49 6.715159653978822
True
				 0.41816022992134094 5.5147271156311035
#>>>    5.67 5.87 		|		 -0.20000000000000018
[Mar 29, 22:23:00] 50 6.714377381879012
True
				 0.29313695430755615 5.272212505340576
#>>>    5.79 5.84 		|		 -0.04999999999999982
[Mar 29, 22:23:01] 51 6.71322835407599
True
				 0.2976657748222351 5.113101005554199
#>>>    5.81 5.85 		|		 -0.040000000000000036
[Mar 29, 22:23:01] 52 6.711925892323476
True
				 0.33858636021614075 5.240077018737793
#>>>    6.01 5.8 		|		 0.20999999999999996
[Mar 29, 22:23:02] 53 6.710792629780304
True
				 0.20039208233356476 5.103429317474365
#>>>    6.47 6.38 		|		 0.08999999999999986
[Mar 29, 22:23:03] 54 6.709385658714244
True
				 0.1961272656917572 4.954348087310791
#>>>    5.98 5.78 		|		 0.20000000000000018
[Mar 29, 22:23:04] 55 6.707826748557544
True
				 0.25445759296417236 5.08391809463501
#>>>    5.94 5.85 		|		 0.09000000000000075
[Mar 29, 22:23:04] 56 6.706457297377376
True
				 0.1780400574207306 5.052433013916016
#>>>    6.44 6.32 		|		 0.1200000000000001
[Mar 29, 22:23:05] 57 6.704981313121533
True
				 0.24438133835792542 5.173551559448242
#>>>    5.87 5.87 		|		 0.0
[Mar 29, 22:23:06] 58 6.703694264795625
True
				 0.19734719395637512 5.1212897300720215
#>>>    5.82 5.97 		|		 -0.14999999999999947
[Mar 29, 22:23:06] 59 6.702309207425055
True
				 0.2781710624694824 5.181453227996826
#>>>    6.21 6.36 		|		 -0.15000000000000036
[Mar 29, 22:23:07] 60 6.701066522508097
True
				 0.30879777669906616 5.273547649383545
#>>>    5.74 5.76 		|		 -0.019999999999999574
[Mar 29, 22:23:08] 61 6.699947801471277
True
				 0.2867026925086975 5.1750969886779785
#>>>    5.58 5.64 		|		 -0.05999999999999961
[Mar 29, 22:23:09] 62 6.698709653291387
True
				 0.2247365564107895 5.01465368270874
#>>>    6.25 6.04 		|		 0.20999999999999996
[Mar 29, 22:23:09] 63 6.697250334011326
True
				 0.23249569535255432 5.116519451141357
#>>>    6.21 5.97 		|		 0.2400000000000002
[Mar 29, 22:23:10] 64 6.695902098913216
True
				 0.2813414931297302 5.3869123458862305
#>>>    6.01 6.4 		|		 -0.39000000000000057
[Mar 29, 22:23:11] 65 6.6948744507129225
True
				 0.20454907417297363 5.106451034545898
#>>>    5.74 5.77 		|		 -0.02999999999999936
[Mar 29, 22:23:12] 66 6.693490576132509
True
				 0.17804425954818726 4.845065116882324
#>>>    6.13 5.92 		|		 0.20999999999999996
[Mar 29, 22:23:12] 67 6.691820194992411
True
				 0.21587830781936646 5.109586715698242
#>>>    5.87 5.98 		|		 -0.11000000000000032
[Mar 29, 22:23:13] 68 6.69045383999975
True
				 0.22434571385383606 5.000101566314697
#>>>    6.43 6.43 		|		 0.0
[Mar 29, 22:23:14] 69 6.688987833410117
True
				 0.16402354836463928 4.82855749130249
#>>>    6.35 6.26 		|		 0.08999999999999986
[Mar 29, 22:23:15] 70 6.687291426467362
True
				 0.2340424358844757 5.1222991943359375
#>>>    5.97 6.07 		|		 -0.10000000000000053
[Mar 29, 22:23:15] 71 6.685960476879731
True
				 0.15422660112380981 4.946996212005615
#>>>    5.79 5.78 		|		 0.009999999999999787
[Mar 29, 22:23:16] 72 6.6843757393947945
True
				 0.16191086173057556 4.821556568145752
#>>>    6.35 6.13 		|		 0.21999999999999975
[Mar 29, 22:23:17] 73 6.682674831234287
True
				 0.18940061330795288 4.941652774810791
#>>>    5.82 5.89 		|		 -0.0699999999999994
[Mar 29, 22:23:18] 74 6.681123209850776
True
				 0.18565687537193298 5.085786819458008
#>>>    5.58 5.74 		|		 -0.16000000000000014
[Mar 29, 22:23:18] 75 6.679713530484767
True
				 0.14690956473350525 4.896029472351074
#>>>    6.25 6.17 		|		 0.08000000000000007
[Mar 29, 22:23:19] 76 6.678076756140379
True
				 0.17591452598571777 4.924280643463135
#>>>    5.9 5.78 		|		 0.1200000000000001
[Mar 29, 22:23:20] 77 6.676498874315269
True
				 0.22986915707588196 5.1538190841674805
#>>>    6.05 6.26 		|		 -0.20999999999999996
[Mar 29, 22:23:20] 78 6.675206063890814
True
				 0.1495206654071808 4.988240718841553
#>>>    6.09 6.15 		|		 -0.0600000000000005
[Mar 29, 22:23:21] 79 6.673668619419788
True
				 0.19572007656097412 4.955101490020752
#>>>    5.81 5.64 		|		 0.16999999999999993
[Mar 29, 22:23:22] 80 6.672145772486159
True
				 0.19340446591377258 5.057744979858398
#>>>    5.68 5.67 		|		 0.009999999999999787
[Mar 29, 22:23:23] 81 6.670724776368061
True
				 0.17850995063781738 5.0218825340271
#>>>    5.36 5.25 		|		 0.11000000000000032
[Mar 29, 22:23:23] 82 6.6692544443147765
True
				 0.17821484804153442 4.9990129470825195
#>>>    5.76 5.72 		|		 0.040000000000000036
[Mar 29, 22:23:24] 83 6.6677624178444
True
				 0.230825275182724 5.160176753997803
#>>>    5.8 6.13 		|		 -0.33000000000000007
[Mar 29, 22:23:25] 84 6.666485657604747
True
				 0.19909891486167908 4.9106035232543945
#>>>    5.92 5.63 		|		 0.29000000000000004
[Mar 29, 22:23:26] 85 6.6649288745342705
True
				 0.13255181908607483 4.869147777557373
#>>>    5.64 5.61 		|		 0.02999999999999936
[Mar 29, 22:23:26] 86 6.6632656451073675
True
				 0.1767154484987259 4.996563911437988
#>>>    5.64 5.71 		|		 -0.07000000000000028
[Mar 29, 22:23:27] 87 6.6617756587476915
True
				 0.16436824202537537 4.9244208335876465
#>>>    5.36 5.34 		|		 0.020000000000000462
[Mar 29, 22:23:28] 88 6.66020267207515
True
				 0.20629383623600006 5.084290504455566
#>>>    5.59 5.68 		|		 -0.08999999999999986
[Mar 29, 22:23:29] 89 6.658833053967284
True
				 0.1441572904586792 4.870594024658203
#>>>    5.77 5.7 		|		 0.0699999999999994
[Mar 29, 22:23:29] 90 6.657188972347644
True
				 0.16961774230003357 4.951879978179932
#>>>    5.41 5.43 		|		 -0.019999999999999574
[Mar 29, 22:23:30] 91 6.655653281006369
True
				 0.1341801881790161 4.8358049392700195
#>>>    5.29 5.15 		|		 0.13999999999999968
[Mar 29, 22:23:31] 92 6.653967612733602
True
				 0.17990854382514954 5.049161911010742
#>>>    5.51 5.61 		|		 -0.10000000000000053
[Mar 29, 22:23:32] 93 6.65254271578432
True
				 0.20397764444351196 5.101781845092773
#>>>    5.32 5.38 		|		 -0.05999999999999961
[Mar 29, 22:23:32] 94 6.651195932498467
True
				 0.21248409152030945 4.969843864440918
#>>>    5.62 5.76 		|		 -0.13999999999999968
[Mar 29, 22:23:33] 95 6.649727064313314
True
				 0.1433030068874359 4.852267265319824
#>>>    5.37 5.19 		|		 0.17999999999999972
[Mar 29, 22:23:34] 96 6.648072907431802
True
				 0.2189418375492096 5.02259635925293
#>>>    5.75 5.95 		|		 -0.20000000000000018
[Mar 29, 22:23:34] 97 6.64666637257216
True
				 0.175856351852417 5.0300493240356445
#>>>    5.83 6.02 		|		 -0.1899999999999995
[Mar 29, 22:23:35] 98 6.645225612113895
True
				 0.17879033088684082 4.963761806488037
#>>>    5.83 5.92 		|		 -0.08999999999999986
[Mar 29, 22:23:36] 99 6.643722938877574
True
				 0.1274249255657196 4.783027648925781
#>>>    5.65 5.5 		|		 0.15000000000000036
[Mar 29, 22:23:37] 100 6.641989668304572
True
				 0.16658300161361694 4.845170974731445
#>>>    5.73 5.71 		|		 0.020000000000000462
[Mar 29, 22:23:37] 101 6.640359432672217
True
				 0.13321354985237122 4.862443923950195
#>>>    5.37 5.25 		|		 0.1200000000000001
[Mar 29, 22:23:38] 102 6.638714730683546
True
				 0.13881993293762207 4.9323835372924805
#>>>    5.63 5.69 		|		 -0.0600000000000005
[Mar 29, 22:23:39] 103 6.6371472191846745
True
				 0.13901254534721375 4.830230712890625
#>>>    5.71 5.6 		|		 0.11000000000000032
[Mar 29, 22:23:40] 104 6.635479315015111
True
				 0.14855685830116272 4.9332194328308105
#>>>    5.8 5.86 		|		 -0.0600000000000005
[Mar 29, 22:23:40] 105 6.633925611842216
True
				 0.16592326760292053 4.927670001983643
#>>>    5.52 5.77 		|		 -0.25
[Mar 29, 22:23:41] 106 6.632385279350949
True
				 0.18971484899520874 4.9784040451049805
#>>>    5.65 5.62 		|		 0.03000000000000025
[Mar 29, 22:23:42] 107 6.6309210130253025
True
				 0.1392333209514618 4.886455059051514
#>>>    5.54 5.48 		|		 0.05999999999999961
[Mar 29, 22:23:42] 108 6.6293157801836635
True
				 0.13911744952201843 4.775942325592041
#>>>    5.77 5.52 		|		 0.25
[Mar 29, 22:23:43] 109 6.627601523969978
True
				 0.13704247772693634 4.839280128479004
#>>>    5.74 5.56 		|		 0.1800000000000006
[Mar 29, 22:23:44] 110 6.625950245096917
True
				 0.16800355911254883 4.9050750732421875
#>>>    6.38 6.43 		|		 -0.04999999999999982
[Mar 29, 22:23:45] 111 6.624397373484176
True
				 0.1101972907781601 4.7142181396484375
#>>>    5.79 5.65 		|		 0.13999999999999968
[Mar 29, 22:23:45] 112 6.622597391317601
True
				 0.1673639565706253 4.872615337371826
#>>>    5.76 5.86 		|		 -0.10000000000000053
[Mar 29, 22:23:46] 113 6.621014773384139
True
				 0.14053212106227875 4.864645957946777
#>>>    5.76 5.79 		|		 -0.03000000000000025
[Mar 29, 22:23:47] 114 6.619398936585456
True
				 0.1471281349658966 4.843867778778076
#>>>    5.96 5.91 		|		 0.04999999999999982
[Mar 29, 22:23:48] 115 6.617770533532812
True
				 0.14989352226257324 4.921018600463867
#>>>    5.61 5.74 		|		 -0.1299999999999999
[Mar 29, 22:23:48] 116 6.616223675360424
True
				 0.16562049090862274 4.766625881195068
#>>>    6.14 5.77 		|		 0.3700000000000001
[Mar 29, 22:23:49] 117 6.614539697893255
True
				 0.13647937774658203 4.765944957733154
#>>>    5.87 5.6 		|		 0.27000000000000046
[Mar 29, 22:23:50] 118 6.612827582530842
True
				 0.11236100643873215 4.809225559234619
#>>>    5.65 5.6 		|		 0.05000000000000071
[Mar 29, 22:23:51] 119 6.61113634146183
True
				 0.14453570544719696 4.796757698059082
#>>>    5.79 5.68 		|		 0.11000000000000032
[Mar 29, 22:23:51] 120 6.609466498359961
True
				 0.12445219606161118 4.697322845458984
#>>>    6.05 5.96 		|		 0.08999999999999986
[Mar 29, 22:23:52] 121 6.6076788068211645
True
				 0.12190183997154236 4.812076568603516
#>>>    6.18 6.08 		|		 0.09999999999999964
[Mar 29, 22:23:53] 122 6.60600510657193
True
				 0.18699707090854645 4.9479522705078125
#>>>    5.67 5.92 		|		 -0.25
[Mar 29, 22:23:54] 123 6.6045340506726635
True
				 0.14154542982578278 4.747279167175293
#>>>    6.09 6.05 		|		 0.040000000000000036
[Mar 29, 22:23:54] 124 6.602818341084882
True
				 0.1601812243461609 4.72706937789917
#>>>    6.12 6.1 		|		 0.020000000000000462
[Mar 29, 22:23:55] 125 6.601102773167229
True
				 0.11034877598285675 4.764637470245361
#>>>    5.9 5.81 		|		 0.09000000000000075
[Mar 29, 22:23:56] 126 6.599376656565783
True
				 0.13518142700195312 5.003122806549072
#>>>    5.81 6.07 		|		 -0.2600000000000007
[Mar 29, 22:23:56] 127 6.597915584142768
True
				 0.1295105218887329 4.780351638793945
#>>>    5.93 5.88 		|		 0.04999999999999982
[Mar 29, 22:23:57] 128 6.596227530600099
True
				 0.08638589084148407 4.71022367477417
#>>>    5.68 5.66 		|		 0.019999999999999574
[Mar 29, 22:23:58] 129 6.594427912471202
True
				 0.0839725211262703 4.677041530609131
#>>>    6.11 6.07 		|		 0.040000000000000036
[Mar 29, 22:23:59] 130 6.592594498543411
True
				 0.13808757066726685 4.794318199157715
#>>>    5.64 5.65 		|		 -0.010000000000000675
[Mar 29, 22:24:00] 131 6.590934309993507
True
				 0.1377245932817459 4.762397289276123
#>>>    5.4 5.33 		|		 0.07000000000000028
[Mar 29, 22:24:00] 132 6.589243497372356
True
				 0.09765033423900604 4.664610862731934
#>>>    6.02 6.0 		|		 0.019999999999999574
[Mar 29, 22:24:01] 133 6.58741651526567
True
				 0.10484479367733002 4.680144786834717
#>>>    5.52 5.62 		|		 -0.10000000000000053
[Mar 29, 22:24:02] 134 6.585614088107399
True
				 0.10971009731292725 4.595691680908203
#>>>    5.71 5.52 		|		 0.1900000000000004
[Mar 29, 22:24:02] 135 6.583733875916722
True
				 0.09372720122337341 4.682652473449707
#>>>    5.78 5.91 		|		 -0.1299999999999999
[Mar 29, 22:24:03] 136 6.581926521626071
True
				 0.14567935466766357 4.645252227783203
#>>>    6.1 5.86 		|		 0.23999999999999932
[Mar 29, 22:24:04] 137 6.580135526806106
True
				 0.13389912247657776 4.6291184425354
#>>>    5.62 5.48 		|		 0.13999999999999968
[Mar 29, 22:24:05] 138 6.578318408933718
True
				 0.14191420376300812 4.625678539276123
#>>>    5.63 5.75 		|		 -0.1200000000000001
[Mar 29, 22:24:05] 139 6.576507683431736
True
				 0.10234839469194412 4.569373607635498
#>>>    5.81 5.69 		|		 0.11999999999999922
[Mar 29, 22:24:06] 140 6.574602897683577
True
				 0.1664070039987564 4.732483863830566
#>>>    5.64 5.77 		|		 -0.1299999999999999
[Mar 29, 22:24:07] 141 6.572927185758031
True
				 0.13572987914085388 4.687497615814209
#>>>    5.74 5.82 		|		 -0.08000000000000007
[Mar 29, 22:24:08] 142 6.571177485977821
True
				 0.13707473874092102 4.5956926345825195
#>>>    6.07 5.98 		|		 0.08999999999999986
[Mar 29, 22:24:08] 143 6.569339076073783
True
				 0.14275643229484558 4.6663689613342285
#>>>    5.83 5.87 		|		 -0.040000000000000036
[Mar 29, 22:24:09] 144 6.567578862421141
True
				 0.14858217537403107 4.5990400314331055
#>>>    6.46 6.45 		|		 0.009999999999999787
[Mar 29, 22:24:10] 145 6.565758905571811
True
				 0.11009670794010162 4.617105484008789
#>>>    5.89 5.9 		|		 -0.010000000000000675
[Mar 29, 22:24:11] 146 6.563920349081706
True
				 0.13508334755897522 4.652919292449951
#>>>    6.09 6.07 		|		 0.019999999999999574
[Mar 29, 22:24:11] 147 6.562144431223621
True
				 0.1280055046081543 4.661188125610352
#>>>    5.5 5.44 		|		 0.05999999999999961
[Mar 29, 22:24:12] 148 6.560371480422615
True
				 0.19636812806129456 4.944946765899658
#>>>    5.41 5.68 		|		 -0.2699999999999996
[Mar 29, 22:24:13] 149 6.558952423925561
True
				 0.09490684419870377 4.481449127197266
#>>>    5.52 5.45 		|		 0.0699999999999994
[Mar 29, 22:24:14] 150 6.556969827435778
True
				 0.1676628291606903 4.646449565887451
#>>>    5.48 5.8 		|		 -0.3199999999999994
[Mar 29, 22:24:14] 151 6.5552269697947745
True
				 0.15079449117183685 4.7333292961120605
#>>>    5.02 5.04 		|		 -0.020000000000000462
[Mar 29, 22:24:15] 152 6.553555866627165
True
				 0.16531513631343842 4.534283638000488
#>>>    5.29 5.23 		|		 0.05999999999999961
[Mar 29, 22:24:16] 153 6.551701909549753
True
				 0.11402635276317596 4.694209575653076
#>>>    5.16 5.16 		|		 0.0
[Mar 29, 22:24:17] 154 6.549958443762335
True
				 0.13101819157600403 4.486877918243408
#>>>    5.64 5.56 		|		 0.08000000000000007
[Mar 29, 22:24:17] 155 6.548026381398589
True
				 0.15592151880264282 4.498630046844482
#>>>    5.54 5.58 		|		 -0.040000000000000036
[Mar 29, 22:24:18] 156 6.5461329065232325
True
				 0.12320318818092346 4.65684175491333
#>>>    5.38 5.33 		|		 0.04999999999999982
[Mar 29, 22:24:19] 157 6.544366818649211
True
				 0.1423802673816681 4.499850273132324
#>>>    5.14 5.04 		|		 0.09999999999999964
[Mar 29, 22:24:19] 158 6.542464682341273
True
				 0.14799584448337555 4.457262992858887
#>>>    5.46 5.61 		|		 -0.15000000000000036
[Mar 29, 22:24:20] 159 6.540527476600582
True
				 0.2239784151315689 4.602711200714111
#>>>    5.71 5.81 		|		 -0.09999999999999964
[Mar 29, 22:24:21] 160 6.538813638844135
True
				 0.13160446286201477 4.457494735717773
#>>>    5.14 4.93 		|		 0.20999999999999996
[Mar 29, 22:24:22] 161 6.536863924612487
True
				 0.13533295691013336 4.466257095336914
#>>>    5.79 5.6 		|		 0.1900000000000004
[Mar 29, 22:24:22] 162 6.53492865084443
True
				 0.16618236899375916 4.502146244049072
#>>>    5.83 5.83 		|		 0.0
[Mar 29, 22:24:23] 163 6.53306205095564
True
				 0.12249774485826492 4.31832218170166
#>>>    5.99 5.98 		|		 0.009999999999999787
[Mar 29, 22:24:24] 164 6.530969808644979
True
				 0.13145098090171814 4.477834701538086
#>>>    5.66 5.56 		|		 0.10000000000000053
[Mar 29, 22:24:25] 165 6.529048124667786
True
				 0.19399499893188477 4.290530681610107
#>>>    6.16 5.96 		|		 0.20000000000000018
[Mar 29, 22:24:25] 166 6.527003602223661
True
				 0.1549367904663086 4.470646858215332
#>>>    6.15 6.01 		|		 0.14000000000000057
[Mar 29, 22:24:26] 167 6.5251021822701185
True
				 0.15001678466796875 4.319222450256348
#>>>    6.03 5.94 		|		 0.08999999999999986
[Mar 29, 22:24:27] 168 6.523046319322773
True
				 0.16854694485664368 4.30373477935791
#>>>    6.33 6.13 		|		 0.20000000000000018
[Mar 29, 22:24:27] 169 6.52099555493628
True
				 0.17306651175022125 4.510719299316406
#>>>    5.87 5.82 		|		 0.04999999999999982
[Mar 29, 22:24:28] 170 6.519158345296718
True
				 0.1424574851989746 4.297883033752441
#>>>    6.22 6.11 		|		 0.10999999999999943
[Mar 29, 22:24:29] 171 6.517079527470373
True
				 0.156942680478096 4.50820779800415
#>>>    5.9 5.82 		|		 0.08000000000000007
[Mar 29, 22:24:30] 172 6.515227598585297
True
				 0.180000901222229 4.6090989112854
#>>>    6.41 6.21 		|		 0.20000000000000018
[Mar 29, 22:24:30] 173 6.51350147068001
True
				 0.14007745683193207 4.457442760467529
#>>>    5.94 5.93 		|		 0.010000000000000675
[Mar 29, 22:24:31] 174 6.51158548956074
True
				 0.17437492311000824 4.548233509063721
#>>>    5.94 5.96 		|		 -0.019999999999999574
[Mar 29, 22:24:32] 175 6.509796512637464
True
				 0.18894600868225098 4.370311737060547
#>>>    5.72 5.74 		|		 -0.020000000000000462
[Mar 29, 22:24:33] 176 6.507845973632151
True
				 0.13346774876117706 4.355101108551025
#>>>    5.83 5.71 		|		 0.1200000000000001
[Mar 29, 22:24:33] 177 6.505826696441324
True
				 0.12185311317443848 4.272669792175293
#>>>    6.11 5.77 		|		 0.34000000000000075
[Mar 29, 22:24:34] 178 6.503715392411814
True
				 0.1914103925228119 4.364887237548828
#>>>    6.16 6.29 		|		 -0.1299999999999999
[Mar 29, 22:24:35] 179 6.501767974798486
True
				 0.13544690608978271 4.326428413391113
#>>>    5.83 5.71 		|		 0.1200000000000001
[Mar 29, 22:24:36] 180 6.4997280822623775
True
				 0.1315462291240692 4.484097003936768
#>>>    5.92 6.0 		|		 -0.08000000000000007
[Mar 29, 22:24:36] 181 6.497843997204559
True
				 0.1978195309638977 4.514012813568115
#>>>    6.07 6.28 		|		 -0.20999999999999996
[Mar 29, 22:24:37] 182 6.4960579857307
True
				 0.1239621490240097 4.283961296081543
#>>>    6.0 5.82 		|		 0.17999999999999972
[Mar 29, 22:24:38] 183 6.493969850966558
True
				 0.1619679033756256 4.363856315612793
#>>>    6.2 6.05 		|		 0.15000000000000036
[Mar 29, 22:24:39] 184 6.492001705185569
True
				 0.20353873074054718 4.190988540649414
#>>>    6.57 6.56 		|		 0.010000000000000675
[Mar 29, 22:24:39] 185 6.489904230915686
True
				 0.17395859956741333 4.308289051055908
#>>>    6.74 6.7 		|		 0.040000000000000036
[Mar 29, 22:24:40] 186 6.487896574514207
True
				 0.13897493481636047 4.321732044219971
#>>>    6.63 6.44 		|		 0.1899999999999995
[Mar 29, 22:24:41] 187 6.485869385127345
True
				 0.1815965622663498 4.262211322784424
#>>>    6.72 6.64 		|		 0.08000000000000007
[Mar 29, 22:24:41] 188 6.483827323820984
True
				 0.21281816065311432 4.2967705726623535
#>>>    6.88 6.86 		|		 0.019999999999999574
[Mar 29, 22:24:42] 189 6.481853085215577
True
				 0.22039225697517395 4.574512481689453
#>>>    6.92 6.93 		|		 -0.009999999999999787
[Mar 29, 22:24:43] 190 6.480166136839223
True
				 0.1744937002658844 4.407630920410156
#>>>    6.82 6.7 		|		 0.1200000000000001
[Mar 29, 22:24:44] 191 6.478268095412467
True
				 0.16954511404037476 4.40580415725708
#>>>    7.14 7.26 		|		 -0.1200000000000001
[Mar 29, 22:24:44] 192 6.476365176647957
True
				 0.14204974472522736 4.1129150390625
#>>>    7.47 7.25 		|		 0.21999999999999975
[Mar 29, 22:24:45] 193 6.4741437762998
True
				 0.15941834449768066 4.301802635192871
#>>>    6.65 6.69 		|		 -0.040000000000000036
[Mar 29, 22:24:46] 194 6.4721308532647726
True
				 0.17849543690681458 4.089995384216309
#>>>    7.52 7.19 		|		 0.3299999999999992
[Mar 29, 22:24:47] 195 6.469927213202829
True
				 0.18727988004684448 4.121720790863037
#>>>    6.73 6.84 		|		 -0.10999999999999943
[Mar 29, 22:24:47] 196 6.467766286481722
True
				 0.1521824598312378 4.136965751647949
#>>>    6.74 6.56 		|		 0.1800000000000006
[Mar 29, 22:24:48] 197 6.465587668525928
True
				 0.20472308993339539 4.064016819000244
#>>>    7.55 7.48 		|		 0.0699999999999994
[Mar 29, 22:24:49] 198 6.46339082055772
True
				 0.18883422017097473 4.1703338623046875
#>>>    7.26 7.33 		|		 -0.07000000000000028
[Mar 29, 22:24:50] 199 6.461286597789836
True
				 0.1988852322101593 4.324219703674316
#>>>    6.87 6.81 		|		 0.0600000000000005
[Mar 29, 22:24:50] 200 6.459348416336547
True
				 0.21398615837097168 4.258759021759033
#>>>    7.41 7.36 		|		 0.04999999999999982
[Mar 29, 22:24:51] 201 6.457361812861922
True
				 0.18692730367183685 4.133519172668457
#>>>    7.01 6.72 		|		 0.29000000000000004
[Mar 29, 22:24:52] 202 6.455224897540302
True
				 0.18363195657730103 4.089247226715088
#>>>    6.91 6.77 		|		 0.14000000000000057
[Mar 29, 22:24:52] 203 6.453042551766449
True
				 0.20746642351150513 4.227987766265869
#>>>    6.72 6.58 		|		 0.13999999999999968
[Mar 29, 22:24:53] 204 6.451024963583275
True
				 0.15180373191833496 3.967906951904297
#>>>    6.9 6.62 		|		 0.28000000000000025
[Mar 29, 22:24:54] 205 6.448693649541933
True
				 0.22884580492973328 4.325773239135742
#>>>    6.57 6.7 		|		 -0.1299999999999999
[Mar 29, 22:24:55] 206 6.44679957472784
True
				 0.17444133758544922 4.052182674407959
#>>>    7.05 7.04 		|		 0.009999999999999787
[Mar 29, 22:24:55] 207 6.4445793991651055
True
				 0.1865772008895874 3.963698148727417
#>>>    7.02 6.96 		|		 0.05999999999999961
[Mar 29, 22:24:56] 208 6.442285094996348
True
				 0.13558214902877808 4.223919868469238
#>>>    6.58 6.42 		|		 0.16000000000000014
[Mar 29, 22:24:57] 209 6.440202311740036
True
				 0.12423928081989288 4.114240646362305
#>>>    6.6 6.42 		|		 0.17999999999999972
[Mar 29, 22:24:58] 210 6.43800058951939
True
				 0.160130575299263 4.223755359649658
#>>>    6.31 6.27 		|		 0.040000000000000036
[Mar 29, 22:24:58] 211 6.435946474790314
True
				 0.20346872508525848 3.9266111850738525
#>>>    6.97 6.93 		|		 0.040000000000000036
[Mar 29, 22:24:59] 212 6.433640608061769
True
				 0.2016061693429947 4.160489082336426
#>>>    6.8 6.82 		|		 -0.020000000000000462
[Mar 29, 22:25:00] 213 6.431569062809695
True
				 0.17060193419456482 4.058826446533203
#>>>    7.12 6.98 		|		 0.13999999999999968
[Mar 29, 22:25:01] 214 6.429366922038207
True
				 0.15539595484733582 3.9531238079071045
#>>>    7.32 7.08 		|		 0.2400000000000002
[Mar 29, 22:25:01] 215 6.427046074670306
True
				 0.16749699413776398 4.292471408843994
#>>>    6.56 6.63 		|		 -0.07000000000000028
[Mar 29, 22:25:02] 216 6.42507899716253
True
				 0.17628267407417297 4.031071662902832
#>>>    6.89 6.81 		|		 0.08000000000000007
[Mar 29, 22:25:03] 217 6.422861272710961
True
				 0.2454504370689392 4.290706634521484
#>>>    7.09 7.33 		|		 -0.2400000000000002
[Mar 29, 22:25:04] 218 6.420974568569445
True
				 0.2828789949417114 4.009048938751221
#>>>    6.98 6.99 		|		 -0.009999999999999787
[Mar 29, 22:25:04] 219 6.418845521815359
True
				 0.2254915088415146 4.025938987731934
#>>>    6.67 6.83 		|		 -0.16000000000000014
[Mar 29, 22:25:05] 220 6.416678106805018
True
				 0.1919841319322586 4.144192695617676
#>>>    6.67 6.54 		|		 0.1299999999999999
[Mar 29, 22:25:06] 221 6.414597605570466
True
				 0.1602843999862671 4.176652908325195
#>>>    6.77 6.74 		|		 0.02999999999999936
[Mar 29, 22:25:06] 222 6.412519945392416
True
				 0.12438824027776718 4.1268510818481445
#>>>    6.4 6.29 		|		 0.11000000000000032
[Mar 29, 22:25:07] 223 6.410358664746798
True
				 0.1861451268196106 4.196225166320801
#>>>    6.47 6.32 		|		 0.14999999999999947
[Mar 29, 22:25:08] 224 6.408330676554005
True
				 0.17778927087783813 3.9695417881011963
#>>>    7.3 7.08 		|		 0.21999999999999975
[Mar 29, 22:25:09] 225 6.406069677115244
True
				 0.18084502220153809 4.004528045654297
#>>>    6.84 6.55 		|		 0.29000000000000004
[Mar 29, 22:25:09] 226 6.403848980744404
True
				 0.1502929925918579 4.117822647094727
#>>>    6.39 6.37 		|		 0.019999999999999574
[Mar 29, 22:25:10] 227 6.401713247284137
True
				 0.17827993631362915 4.098179817199707
#>>>    6.92 6.97 		|		 -0.04999999999999982
[Mar 29, 22:25:11] 228 6.399587993730762
True
				 0.21854259073734283 3.9859724044799805
#>>>    7.24 6.96 		|		 0.28000000000000025
[Mar 29, 22:25:12] 229 6.397392920717347
True
				 0.19628725945949554 4.008935451507568
#>>>    7.34 7.25 		|		 0.08999999999999986
[Mar 29, 22:25:12] 230 6.395200750403289
True
				 0.24706760048866272 3.8532755374908447
#>>>    7.22 6.9 		|		 0.3199999999999994
[Mar 29, 22:25:13] 231 6.392905892880272
True
				 0.19344423711299896 4.098421573638916
#>>>    6.42 6.27 		|		 0.15000000000000036
[Mar 29, 22:25:14] 232 6.390804852813044
True
				 0.20306485891342163 3.9591023921966553
#>>>    7.22 7.16 		|		 0.05999999999999961
[Mar 29, 22:25:15] 233 6.388576215032527
True
				 0.200717493891716 3.8543763160705566
#>>>    7.28 7.15 		|		 0.1299999999999999
[Mar 29, 22:25:15] 234 6.386242732582754
True
				 0.24439316987991333 4.201781272888184
#>>>    7.25 7.2 		|		 0.04999999999999982
[Mar 29, 22:25:16] 235 6.384302664471753
True
				 0.2691262364387512 4.009605407714844
#>>>    7.42 7.43 		|		 -0.009999999999999787
[Mar 29, 22:25:17] 236 6.382197093630249
True
				 0.20076176524162292 3.8975446224212646
#>>>    7.11 6.91 		|		 0.20000000000000018
[Mar 29, 22:25:17] 237 6.379913202715665
True
				 0.3117213249206543 3.9283130168914795
#>>>    7.65 7.53 		|		 0.1200000000000001
[Mar 29, 22:25:18] 238 6.377773323616342
True
				 0.18368543684482574 4.06239652633667
#>>>    7.15 7.11 		|		 0.040000000000000036
[Mar 29, 22:25:19] 239 6.375641632121797
True
				 0.22427542507648468 3.701653242111206
#>>>    7.49 7.25 		|		 0.2400000000000002
[Mar 29, 22:25:20] 240 6.373191919082356
True
				 0.23757672309875488 3.8099544048309326
#>>>    7.61 7.24 		|		 0.3700000000000001
[Mar 29, 22:25:20] 241 6.370866258291204
True
				 0.20907628536224365 3.737335205078125
#>>>    7.43 7.37 		|		 0.05999999999999961
[Mar 29, 22:25:21] 242 6.368441803642562
True
				 0.20995421707630157 3.729017496109009
#>>>    7.3 6.89 		|		 0.41000000000000014
[Mar 29, 22:25:22] 243 6.366012333596808
True
				 0.2903786897659302 4.030311584472656
#>>>    7.41 7.53 		|		 -0.1200000000000001
[Mar 29, 22:25:23] 244 6.36396701141824
True
				 0.22886836528778076 4.0341033935546875
#>>>    7.46 7.24 		|		 0.21999999999999975
[Mar 29, 22:25:23] 245 6.361866016284874
True
				 0.18712987005710602 3.8429408073425293
#>>>    7.04 6.91 		|		 0.1299999999999999
[Mar 29, 22:25:24] 246 6.359534221050297
True
				 0.22294959425926208 3.9498839378356934
#>>>    6.76 6.58 		|		 0.17999999999999972
[Mar 29, 22:25:25] 247 6.357347520271935
True
				 0.2333451807498932 3.776718854904175
#>>>    6.99 6.88 		|		 0.11000000000000032
[Mar 29, 22:25:26] 248 6.355000236876724
True
				 0.16997231543064117 3.9328501224517822
#>>>    6.24 6.18 		|		 0.0600000000000005
[Mar 29, 22:25:26] 249 6.35274805894362
True
				 0.21344199776649475 3.933908224105835
#>>>    6.5 6.23 		|		 0.2699999999999996
[Mar 29, 22:25:27] 250 6.350542661195956
True
				 0.16993385553359985 4.181839942932129
#>>>    6.11 6.2 		|		 -0.08999999999999986
[Mar 29, 22:25:28] 251 6.348543892273621
True
				 0.22963351011276245 4.172334671020508
#>>>    6.36 6.32 		|		 0.040000000000000036
[Mar 29, 22:25:29] 252 6.346597316383667
True
				 0.24118024110794067 3.9470205307006836
#>>>    6.64 6.78 		|		 -0.14000000000000057
[Mar 29, 22:25:29] 253 6.344438920017906
True
				 0.20573559403419495 3.730868101119995
#>>>    7.28 7.33 		|		 -0.04999999999999982
[Mar 29, 22:25:30] 254 6.342031084882449
True
				 0.3054812252521515 3.550663948059082
#>>>    7.79 7.59 		|		 0.20000000000000018
[Mar 29, 22:25:31] 255 6.339545198941075
True
				 0.17065371572971344 3.7281360626220703
#>>>    7.16 7.04 		|		 0.1200000000000001
[Mar 29, 22:25:32] 256 6.337104443624795
True
				 0.2119070142507553 3.9416191577911377
#>>>    6.98 6.66 		|		 0.3200000000000003
[Mar 29, 22:25:32] 257 6.334920865487322
True
				 0.24818430840969086 3.9360291957855225
#>>>    7.05 6.95 		|		 0.09999999999999964
[Mar 29, 22:25:33] 258 6.33277015826014
True
				 0.2768794596195221 3.7245993614196777
#>>>    7.56 7.14 		|		 0.41999999999999993
[Mar 29, 22:25:34] 259 6.330438866773908
True
				 0.21777567267417908 3.897188901901245
#>>>    7.19 7.0 		|		 0.1900000000000004
[Mar 29, 22:25:35] 260 6.328223392392302
True
				 0.21209394931793213 3.8803324699401855
#>>>    7.37 7.26 		|		 0.11000000000000032
[Mar 29, 22:25:35] 261 6.325987595299958
True
				 0.18275223672389984 3.865356922149658
#>>>    7.48 7.25 		|		 0.23000000000000043
[Mar 29, 22:25:36] 262 6.3237097167592236
True
				 0.21268120408058167 3.8578109741210938
#>>>    7.47 7.15 		|		 0.3199999999999994
[Mar 29, 22:25:37] 263 6.321456499310073
True
				 0.16230499744415283 3.8694229125976562
#>>>    7.11 6.87 		|		 0.2400000000000002
[Mar 29, 22:25:38] 264 6.319166770601595
True
				 0.22603292763233185 3.9549686908721924
#>>>    7.0 6.71 		|		 0.29000000000000004
[Mar 29, 22:25:38] 265 6.317028605494202
True
				 0.21666042506694794 3.8387465476989746
#>>>    7.28 7.25 		|		 0.03000000000000025
[Mar 29, 22:25:39] 266 6.3147669839359795
True
				 0.28893211483955383 3.754049777984619
#>>>    7.54 7.32 		|		 0.21999999999999975
[Mar 29, 22:25:40] 267 6.312495199053484
True
				 0.26773548126220703 3.7420568466186523
#>>>    7.25 6.99 		|		 0.2599999999999998
[Mar 29, 22:25:41] 268 6.310192496182311
True
				 0.299479603767395 3.8636982440948486
#>>>    7.37 7.19 		|		 0.17999999999999972
[Mar 29, 22:25:41] 269 6.3080454816532
True
				 0.41426506638526917 3.925840377807617
#>>>    7.5 7.51 		|		 -0.009999999999999787
[Mar 29, 22:25:42] 270 6.306077541705147
True
				 0.2216109037399292 3.869847059249878
#>>>    6.98 6.68 		|		 0.3000000000000007
[Mar 29, 22:25:43] 271 6.303862922007222
True
				 0.2750319838523865 3.562310218811035
#>>>    7.68 7.16 		|		 0.5199999999999996
[Mar 29, 22:25:44] 272 6.301396401347483
True
				 0.3727250099182129 3.910623550415039
#>>>    7.34 7.19 		|		 0.14999999999999947
[Mar 29, 22:25:44] 273 6.2993783535064685
True
				 0.2582598328590393 3.650437116622925
#>>>    7.71 7.57 		|		 0.13999999999999968
[Mar 29, 22:25:45] 274 6.29698767204284
True
				 0.2599930763244629 3.7281346321105957
#>>>    7.58 7.44 		|		 0.13999999999999968
[Mar 29, 22:25:46] 275 6.2946788120792325
True
				 0.30619513988494873 3.586848258972168
#>>>    7.78 7.52 		|		 0.2600000000000007
[Mar 29, 22:25:46] 276 6.29227717678522
True
				 0.307679682970047 4.029310703277588
#>>>    7.6 7.21 		|		 0.3899999999999997
[Mar 29, 22:25:47] 277 6.29032188996488
True
				 0.3548760414123535 3.7863354682922363
#>>>    7.96 7.56 		|		 0.40000000000000036
[Mar 29, 22:25:48] 278 6.288172779584619
True
				 0.30888602137565613 3.8384592533111572
#>>>    7.6 7.6 		|		 0.0
[Mar 29, 22:25:49] 279 6.286031951871105
True
				 0.21429377794265747 3.6202988624572754
#>>>    7.82 7.33 		|		 0.4900000000000002
[Mar 29, 22:25:49] 280 6.28358051250003
True
				 0.3391534686088562 3.5529685020446777
#>>>    8.1 7.72 		|		 0.3799999999999999
[Mar 29, 22:25:50] 281 6.281189054017788
True
				 0.21050672233104706 3.6930243968963623
#>>>    7.37 7.11 		|		 0.2599999999999998
[Mar 29, 22:25:51] 282 6.278811396038294
True
				 0.2964716851711273 3.9151082038879395
#>>>    7.3 7.06 		|		 0.2400000000000002
[Mar 29, 22:25:52] 283 6.276744164441908
True
				 0.2549084424972534 3.7055795192718506
#>>>    6.97 6.53 		|		 0.4399999999999995
[Mar 29, 22:25:52] 284 6.274427908120026
True
				 0.2061733901500702 3.5937914848327637
#>>>    7.27 7.16 		|		 0.10999999999999943
[Mar 29, 22:25:53] 285 6.271953445116691
True
				 0.2665114104747772 3.6868410110473633
#>>>    7.45 7.28 		|		 0.16999999999999993
[Mar 29, 22:25:54] 286 6.269634844122899
True
				 0.2737564146518707 3.965456962585449
#>>>    7.75 7.67 		|		 0.08000000000000007
[Mar 29, 22:25:55] 287 6.26760442274542
True
				 0.20095202326774597 3.807223320007324
#>>>    6.93 6.92 		|		 0.009999999999999787
[Mar 29, 22:25:55] 288 6.265344993695753
True
				 0.3097313940525055 3.560105800628662
#>>>    7.6 7.23 		|		 0.3699999999999992
[Mar 29, 22:25:56] 289 6.262949485986145
True
				 0.29696065187454224 3.6536617279052734
#>>>    7.57 7.37 		|		 0.20000000000000018
[Mar 29, 22:25:57] 290 6.260637158820335
True
				 0.2530815005302429 3.6127781867980957
#>>>    7.11 6.89 		|		 0.22000000000000064
[Mar 29, 22:25:57] 291 6.258242381408447
True
				 0.2486116588115692 3.745406150817871
#>>>    6.92 6.54 		|		 0.3799999999999999
[Mar 29, 22:25:58] 292 6.255978156866471
True
				 0.2975735664367676 3.4289445877075195
#>>>    8.24 7.84 		|		 0.40000000000000036
[Mar 29, 22:25:59] 293 6.253448696863749
True
				 0.22420190274715424 3.705240488052368
#>>>    7.51 7.41 		|		 0.09999999999999964
[Mar 29, 22:26:00] 294 6.251124690572586
True
				 0.27839577198028564 3.629502773284912
#>>>    7.85 7.6 		|		 0.25
[Mar 29, 22:26:00] 295 6.2487814643080695
True
				 0.3077120780944824 3.3927273750305176
#>>>    8.37 8.35 		|		 0.019999999999999574
[Mar 29, 22:26:01] 296 6.2462331222968865
True
				 0.3397773504257202 3.8960118293762207
#>>>    7.82 7.89 		|		 -0.0699999999999994
[Mar 29, 22:26:02] 297 6.2442226784736015
True
				 0.2692389488220215 3.380993366241455
#>>>    7.71 7.61 		|		 0.09999999999999964
[Mar 29, 22:26:03] 298 6.2416286881101914
True
				 0.2881839871406555 3.920229911804199
#>>>    7.09 6.88 		|		 0.20999999999999996
[Mar 29, 22:26:03] 299 6.23959547349984
True
				 0.393324077129364 3.2258381843566895
#>>>    8.2 7.86 		|		 0.33999999999999897
[Mar 29, 22:26:04] 300 6.23697504034743
True
				 0.24439755082130432 3.526013135910034
#>>>    7.8 7.57 		|		 0.22999999999999954
[Mar 29, 22:26:05] 301 6.234508476083222
True
				 0.31107771396636963 3.4694299697875977
#>>>    7.71 7.37 		|		 0.33999999999999986
[Mar 29, 22:26:06] 302 6.232054475171683
True
				 0.37928417325019836 3.592588424682617
#>>>    8.35 7.98 		|		 0.3699999999999992
[Mar 29, 22:26:06] 303 6.229794293264642
True
				 0.1810016632080078 3.8784074783325195
#>>>    7.45 7.19 		|		 0.2599999999999998
[Mar 29, 22:26:07] 304 6.2276239081129185
True
				 0.27956581115722656 3.4836525917053223
#>>>    7.54 7.3 		|		 0.2400000000000002
[Mar 29, 22:26:08] 305 6.225159502607668
True
				 0.2848777174949646 3.4642155170440674
#>>>    7.55 7.44 		|		 0.10999999999999943
[Mar 29, 22:26:09] 306 6.222683436399205
True
				 0.3171297311782837 3.5955634117126465
#>>>    7.44 7.47 		|		 -0.02999999999999936
[Mar 29, 22:26:09] 307 6.220373445986487
True
				 0.189376562833786 3.646543264389038
#>>>    7.01 6.93 		|		 0.08000000000000007
[Mar 29, 22:26:10] 308 6.217988992397525
True
				 0.29600265622138977 3.5318119525909424
#>>>    7.65 7.17 		|		 0.4800000000000004
[Mar 29, 22:26:11] 309 6.215598817984137
True
				 0.2880985736846924 3.1986582279205322
#>>>    7.66 7.55 		|		 0.11000000000000032
[Mar 29, 22:26:12] 310 6.212869975967759
True
				 0.36351141333580017 3.20450758934021
#>>>    8.32 7.62 		|		 0.7000000000000002
[Mar 29, 22:26:12] 311 6.21022512490506
True
				 0.3163261115550995 3.634829044342041
#>>>    7.16 7.15 		|		 0.009999999999999787
[Mar 29, 22:26:13] 312 6.207966054965855
True
				 0.3910520672798157 3.344487428665161
#>>>    8.35 7.9 		|		 0.4499999999999993
[Mar 29, 22:26:14] 313 6.20549362834723
True
				 0.26587387919425964 3.5894417762756348
#>>>    7.42 7.17 		|		 0.25
[Mar 29, 22:26:14] 314 6.203143450404155
True
				 0.3028665781021118 3.29699969291687
#>>>    8.14 7.68 		|		 0.46000000000000085
[Mar 29, 22:26:15] 315 6.200540173343979
True
				 0.36577558517456055 3.3352651596069336
#>>>    7.91 7.65 		|		 0.2599999999999998
[Mar 29, 22:26:16] 316 6.198040673915417
True
				 0.33487600088119507 3.794046401977539
#>>>    7.15 7.03 		|		 0.1200000000000001
[Mar 29, 22:26:17] 317 6.195971555703965
True
				 0.316786527633667 3.503645181655884
#>>>    7.58 7.46 		|		 0.1200000000000001
[Mar 29, 22:26:17] 318 6.19359601585755
True
				 0.24786412715911865 3.769465446472168
#>>>    7.39 7.28 		|		 0.10999999999999943
[Mar 29, 22:26:18] 319 6.191419749534533
True
				 0.31281083822250366 3.5506412982940674
#>>>    8.05 7.9 		|		 0.15000000000000036
[Mar 29, 22:26:19] 320 6.189091781981119
True
				 0.2888242304325104 3.584608554840088
#>>>    7.39 7.12 		|		 0.2699999999999996
[Mar 29, 22:26:20] 321 6.186776123073818
True
				 0.31252577900886536 3.6698153018951416
#>>>    7.25 6.95 		|		 0.2999999999999998
[Mar 29, 22:26:20] 322 6.184571688001846
True
				 0.3079276382923126 3.6463165283203125
#>>>    7.39 7.48 		|		 -0.09000000000000075
[Mar 29, 22:26:21] 323 6.182341360450654
True
				 0.31240415573120117 3.736208200454712
#>>>    7.9 7.84 		|		 0.0600000000000005
[Mar 29, 22:26:22] 324 6.180207631684808
True
				 0.24620531499385834 3.3177595138549805
#>>>    7.69 7.44 		|		 0.25
[Mar 29, 22:26:23] 325 6.177591388896873
True
				 0.2882574200630188 3.5530319213867188
#>>>    7.63 7.3 		|		 0.33000000000000007
[Mar 29, 22:26:23] 326 6.1752550867898215
True
				 0.3260805904865265 3.523300886154175
#>>>    7.66 7.45 		|		 0.20999999999999996
[Mar 29, 22:26:24] 327 6.17292921314987
True
				 0.25364407896995544 3.7598490715026855
#>>>    7.09 7.04 		|		 0.04999999999999982
[Mar 29, 22:26:25] 328 6.170769776997785
True
				 0.28043198585510254 3.656087636947632
#>>>    7.9 7.83 		|		 0.07000000000000028
[Mar 29, 22:26:26] 329 6.16853552684359
True
				 0.31227779388427734 3.5145769119262695
#>>>    7.96 7.92 		|		 0.040000000000000036
[Mar 29, 22:26:26] 330 6.166193846022557
True
				 0.26652324199676514 3.4014971256256104
#>>>    8.01 7.63 		|		 0.3799999999999999
[Mar 29, 22:26:27] 331 6.163695672424947
True
				 0.27730584144592285 3.31294584274292
#>>>    8.47 8.12 		|		 0.3500000000000014
[Mar 29, 22:26:28] 332 6.161122228436711
True
				 0.3428857922554016 3.5074660778045654
#>>>    7.91 7.95 		|		 -0.040000000000000036
[Mar 29, 22:26:28] 333 6.15881145801873
True
				 0.3140638470649719 3.525339126586914
#>>>    7.86 7.29 		|		 0.5700000000000003
[Mar 29, 22:26:29] 334 6.156492049474758
True
				 0.3176453709602356 3.4753153324127197
#>>>    8.63 8.4 		|		 0.23000000000000043
[Mar 29, 22:26:30] 335 6.154128518069051
True
				 0.3095802068710327 3.467872142791748
#>>>    8.1 7.99 		|		 0.10999999999999943
[Mar 29, 22:26:31] 336 6.151751842019855
True
				 0.2744249105453491 3.47586989402771
#>>>    7.57 7.49 		|		 0.08000000000000007
[Mar 29, 22:26:31] 337 6.149350384863198
True
				 0.27129125595092773 3.2593159675598145
#>>>    8.32 8.09 		|		 0.23000000000000043
[Mar 29, 22:26:32] 338 6.146731641701846
True
				 0.3041646480560303 3.348750114440918
#>>>    8.45 8.21 		|		 0.23999999999999844
[Mar 29, 22:26:33] 339 6.144237824822641
True
				 0.2935265302658081 3.433001756668091
#>>>    8.3 8.08 		|		 0.22000000000000064
[Mar 29, 22:26:34] 340 6.141820115165543
True
				 0.3053440451622009 3.656296968460083
#>>>    8.08 7.91 		|		 0.16999999999999993
[Mar 29, 22:26:34] 341 6.139639936123604
True
				 0.41588979959487915 3.802987813949585
#>>>    8.32 8.3 		|		 0.019999999999999574
[Mar 29, 22:26:35] 342 6.137719173979839
True
				 0.3259633183479309 3.3315813541412354
#>>>    8.48 7.9 		|		 0.5800000000000001
[Mar 29, 22:26:36] 343 6.1352389994187435
True
				 0.29403430223464966 3.213221549987793
#>>>    8.89 8.34 		|		 0.5500000000000007
[Mar 29, 22:26:37] 344 6.132611016211943
True
				 0.40219464898109436 3.5805623531341553
#>>>    8.5 8.28 		|		 0.22000000000000064
[Mar 29, 22:26:37] 345 6.130461162287253
True
				 0.42239826917648315 3.7018368244171143
#>>>    8.09 7.89 		|		 0.20000000000000018
[Mar 29, 22:26:38] 346 6.128454936278164
True
				 0.3878614902496338 3.4914803504943848
#>>>    9.43 8.98 		|		 0.4499999999999993
[Mar 29, 22:26:39] 347 6.126205823182629
True
				 0.40274301171302795 3.3358325958251953
#>>>    8.8 8.59 		|		 0.21000000000000085
[Mar 29, 22:26:40] 348 6.123818193056392
True
				 0.31725263595581055 3.47452974319458
#>>>    8.72 8.36 		|		 0.3600000000000012
[Mar 29, 22:26:40] 349 6.121486157242487
True
				 0.38790565729141235 3.563389301300049
#>>>    8.51 8.27 		|		 0.2400000000000002
[Mar 29, 22:26:41] 350 6.119315965984231
True
				 0.38640737533569336 3.391873359680176
#>>>    8.71 8.42 		|		 0.2900000000000009
[Mar 29, 22:26:42] 351 6.116974930753263
True
				 0.2826290726661682 3.485903739929199
#>>>    8.42 8.08 		|		 0.33999999999999986
[Mar 29, 22:26:43] 352 6.1146264885755
True
				 0.4006745517253876 3.545389413833618
#>>>    8.24 8.25 		|		 -0.009999999999999787
[Mar 29, 22:26:43] 353 6.1124579260822856
True
				 0.2732951045036316 3.5524044036865234
#>>>    8.23 8.22 		|		 0.009999999999999787
[Mar 29, 22:26:44] 354 6.110171167723998
True
				 0.4476655423641205 3.265775203704834
#>>>    8.85 8.65 		|		 0.1999999999999993
[Mar 29, 22:26:45] 355 6.107774437212935
True
				 0.3745032250881195 3.439495086669922
#>>>    8.23 7.85 		|		 0.3800000000000008
[Mar 29, 22:26:46] 356 6.105480660998073
True
				 0.2888892590999603 3.4795432090759277
#>>>    8.14 8.07 		|		 0.07000000000000028
[Mar 29, 22:26:46] 357 6.1031436127158445
True
				 0.32742658257484436 3.1674273014068604
#>>>    8.7 8.29 		|		 0.41000000000000014
[Mar 29, 22:26:47] 358 6.100535323076517
True
				 0.4924876391887665 3.5247886180877686
#>>>    8.98 8.55 		|		 0.4299999999999997
[Mar 29, 22:26:48] 359 6.0984520640405195
True
				 0.41277605295181274 3.3037710189819336
#>>>    8.81 8.57 		|		 0.2400000000000002
[Mar 29, 22:26:48] 360 6.096070158988809
True
				 0.3938446640968323 3.513739824295044
#>>>    8.68 8.8 		|		 -0.120000000000001
[Mar 29, 22:26:49] 361 6.093881673258607
True
				 0.2529030442237854 3.5320961475372314
#>>>    8.11 7.99 		|		 0.11999999999999922
[Mar 29, 22:26:50] 362 6.091572790717504
True
				 0.2975226938724518 3.3109753131866455
#>>>    7.82 7.37 		|		 0.4500000000000002
[Mar 29, 22:26:51] 363 6.089089716023253
True
				 0.3039034605026245 3.404374837875366
#>>>    8.46 8.25 		|		 0.21000000000000085
[Mar 29, 22:26:51] 364 6.0867089044863985
True
				 0.26358574628829956 3.4182446002960205
#>>>    8.44 8.3 		|		 0.1399999999999988
[Mar 29, 22:26:52] 365 6.084304025988101
True
				 0.33310264348983765 3.165318012237549
#>>>    8.29 7.68 		|		 0.6099999999999994
[Mar 29, 22:26:53] 366 6.081718142677445
True
				 0.3172837197780609 3.3834967613220215
#>>>    8.13 7.84 		|		 0.2900000000000009
[Mar 29, 22:26:54] 367 6.0793372049264605
True
				 0.27334868907928467 3.4927501678466797
#>>>    8.2 8.13 		|		 0.06999999999999851
[Mar 29, 22:26:54] 368 6.077023966697669
True
				 0.2857569456100464 3.1577930450439453
#>>>    8.37 7.8 		|		 0.5699999999999994
[Mar 29, 22:26:55] 369 6.074390492840835
True
				 0.370686799287796 3.4370875358581543
#>>>    8.37 7.99 		|		 0.379999999999999
[Mar 29, 22:26:56] 370 6.072123876653338
True
				 0.36133623123168945 3.287708282470703
#>>>    8.51 8.09 		|		 0.41999999999999993
[Mar 29, 22:26:57] 371 6.069700797290387
True
				 0.3101609945297241 3.2524683475494385
#>>>    8.42 7.91 		|		 0.5099999999999998
[Mar 29, 22:26:57] 372 6.067193725715966
True
				 0.26518192887306213 3.071841239929199
#>>>    8.31 8.04 		|		 0.27000000000000135
[Mar 29, 22:26:58] 373 6.064463555248459
True
				 0.3377745747566223 3.165095090866089
#>>>    8.59 8.25 		|		 0.33999999999999986
[Mar 29, 22:26:59] 374 6.061901961299228
True
				 0.36029332876205444 3.3645670413970947
#>>>    8.14 7.92 		|		 0.22000000000000064
[Mar 29, 22:27:00] 375 6.059564919767693
True
				 0.4010794758796692 3.1273698806762695
#>>>    8.75 8.49 		|		 0.2599999999999998
[Mar 29, 22:27:00] 376 6.057033804144877
True
				 0.3022587299346924 3.5146477222442627
#>>>    7.71 7.73 		|		 -0.020000000000000462
[Mar 29, 22:27:01] 377 6.054793676792911
True
				 0.3754589855670929 2.847047805786133
#>>>    8.51 7.91 		|		 0.5999999999999996
[Mar 29, 22:27:02] 378 6.051961389877669
True
				 0.287137895822525 3.280064582824707
#>>>    8.1 7.88 		|		 0.21999999999999975
[Mar 29, 22:27:02] 379 6.049476631055846
True
				 0.4061340391635895 3.1132471561431885
#>>>    8.74 8.2 		|		 0.5400000000000009
[Mar 29, 22:27:03] 380 6.0469465357095045
True
				 0.4158686399459839 3.2044923305511475
#>>>    8.31 8.03 		|		 0.28000000000000114
[Mar 29, 22:27:04] 381 6.044519950025083
True
				 0.3775249719619751 3.326584577560425
#>>>    7.97 7.69 		|		 0.27999999999999936
[Mar 29, 22:27:05] 382 6.042179539743789
True
				 0.2919228672981262 3.3627800941467285
#>>>    7.95 7.7 		|		 0.25
[Mar 29, 22:27:05] 383 6.039792063105885
True
				 0.4336298108100891 3.3172035217285156
#>>>    8.58 8.47 		|		 0.10999999999999943
[Mar 29, 22:27:06] 384 6.0375031043157135
True
				 0.3961838483810425 3.01812481880188
#>>>    8.22 7.7 		|		 0.5200000000000005
[Mar 29, 22:27:07] 385 6.034879909759371
True
				 0.3315620422363281 2.780332565307617
#>>>    8.76 8.06 		|		 0.6999999999999993
[Mar 29, 22:27:08] 386 6.031956924457155
True
				 0.40539076924324036 3.095172166824341
#>>>    9.32 8.75 		|		 0.5700000000000003
[Mar 29, 22:27:08] 387 6.029425530438964
True
				 0.4553627371788025 2.846040725708008
#>>>    9.54 9.24 		|		 0.29999999999999893
[Mar 29, 22:27:09] 388 6.026697508431016
True
				 0.42196953296661377 3.398345947265625
#>>>    8.25 7.89 		|		 0.3600000000000003
[Mar 29, 22:27:10] 389 6.024491126283608
True
				 0.5245658159255981 3.365612268447876
#>>>    8.8 8.81 		|		 -0.009999999999999787
[Mar 29, 22:27:11] 390 6.022356813360907
True
				 0.4424590468406677 3.2169783115386963
#>>>    8.9 8.65 		|		 0.25
[Mar 29, 22:27:11] 391 6.01999389396553
True
				 0.38048720359802246 3.186112403869629
#>>>    8.8 8.64 		|		 0.16000000000000014
[Mar 29, 22:27:12] 392 6.017540499679033
True
				 0.3904261291027069 3.121988296508789
#>>>    8.71 8.32 		|		 0.39000000000000057
[Mar 29, 22:27:13] 393 6.015035373634768
True
				 0.41125571727752686 3.2158279418945312
#>>>    8.53 8.52 		|		 0.009999999999999787
[Mar 29, 22:27:14] 394 6.012647422039515
True
				 0.45197391510009766 3.3177762031555176
#>>>    7.94 7.73 		|		 0.20999999999999996
[Mar 29, 22:27:14] 395 6.010404524735731
True
				 0.4520968794822693 3.194617748260498
#>>>    8.4 7.95 		|		 0.4500000000000002
[Mar 29, 22:27:15] 396 6.008040834898343
True
				 0.34596115350723267 3.1104226112365723
#>>>    8.7 8.31 		|		 0.3899999999999988
[Mar 29, 22:27:16] 397 6.005489177768584
True
				 0.47149306535720825 3.071483612060547
#>>>    8.53 8.48 		|		 0.049999999999998934
[Mar 29, 22:27:17] 398 6.003026665208628
True
				 0.3695868253707886 3.1738688945770264
#>>>    7.99 7.63 		|		 0.3600000000000003
[Mar 29, 22:27:17] 399 6.000567094144158
True
				 0.3446526825428009 3.326775074005127
#>>>    7.97 7.51 		|		 0.45999999999999996
[Mar 29, 22:27:18] 400 5.998237954776759
True
				 0.3695923388004303 3.0139293670654297
#>>>    9.39 9.02 		|		 0.370000000000001
[Mar 29, 22:27:19] 401 5.995623238617255
True
				 0.32136136293411255 3.0410215854644775
#>>>    8.39 8.2 		|		 0.19000000000000128
[Mar 29, 22:27:20] 402 5.992989998267431
True
				 0.3071838617324829 3.1520233154296875
#>>>    8.5 8.04 		|		 0.46000000000000085
[Mar 29, 22:27:20] 403 5.990456215327116
True
				 0.3613704442977905 3.230349540710449
#>>>    8.33 8.22 		|		 0.10999999999999943
[Mar 29, 22:27:21] 404 5.988057479216006
True
				 0.40696972608566284 3.419593334197998
#>>>    8.43 8.09 		|		 0.33999999999999986
[Mar 29, 22:27:22] 405 5.985895984856678
True
				 0.3600407838821411 3.3490610122680664
#>>>    9.03 8.6 		|		 0.4299999999999997
[Mar 29, 22:27:22] 406 5.983619190548763
True
				 0.36284399032592773 3.072873830795288
#>>>    8.75 8.45 		|		 0.3000000000000007
[Mar 29, 22:27:23] 407 5.981071289179335
True
				 0.4665415287017822 3.2208025455474854
#>>>    8.27 8.23 		|		 0.03999999999999915
[Mar 29, 22:27:24] 408 5.978777561964405
True
				 0.434698224067688 2.9212353229522705
#>>>    8.77 8.23 		|		 0.5399999999999991
[Mar 29, 22:27:25] 409 5.9761547180686705
True
				 0.39449262619018555 3.4791512489318848
#>>>    7.99 7.73 		|		 0.2599999999999998
[Mar 29, 22:27:26] 410 5.974052207225723
True
				 0.4694668650627136 3.2048306465148926
#>>>    9.03 8.4 		|		 0.629999999999999
[Mar 29, 22:27:26] 411 5.97175245258968
True
				 0.45719072222709656 3.2745280265808105
#>>>    8.56 8.44 		|		 0.120000000000001
[Mar 29, 22:27:27] 412 5.9695124189157
True
				 0.49231624603271484 2.9742672443389893
#>>>    8.59 8.15 		|		 0.4399999999999995
[Mar 29, 22:27:28] 413 5.967009489987157
True
				 0.3574334383010864 2.806640863418579
#>>>    8.97 8.53 		|		 0.4400000000000013
[Mar 29, 22:27:28] 414 5.964206554918098
True
				 0.36472034454345703 3.420069694519043
#>>>    8.29 8.01 		|		 0.27999999999999936
[Mar 29, 22:27:29] 415 5.9620271384022425
True
				 0.4053295850753784 3.1000356674194336
#>>>    9.19 9.02 		|		 0.16999999999999993
[Mar 29, 22:27:30] 416 5.959570476635545
True
				 0.3573845624923706 3.237032413482666
#>>>    8.7 8.53 		|		 0.16999999999999993
[Mar 29, 22:27:31] 417 5.957205323254094
True
				 0.4748915731906891 3.0775671005249023
#>>>    8.76 8.86 		|		 -0.09999999999999964
[Mar 29, 22:27:31] 418 5.9548005766939625
True
				 0.42573824524879456 3.376983880996704
#>>>    8.74 8.38 		|		 0.35999999999999943
[Mar 29, 22:27:32] 419 5.952648498332921
True
				 0.48750853538513184 3.0471420288085938
#>>>    9.26 8.77 		|		 0.4900000000000002
[Mar 29, 22:27:33] 420 5.950230500398781
True
				 0.47782206535339355 3.276043176651001
#>>>    8.27 8.04 		|		 0.23000000000000043
[Mar 29, 22:27:34] 421 5.948034135140388
True
				 0.3581336736679077 3.056901454925537
#>>>    8.8 8.3 		|		 0.5
[Mar 29, 22:27:34] 422 5.94550113625305
True
				 0.496307373046875 2.8782920837402344
#>>>    9.11 8.62 		|		 0.4900000000000002
[Mar 29, 22:27:35] 423 5.942930234573584
True
				 0.3912610411643982 3.2509467601776123
#>>>    8.36 8.11 		|		 0.25
[Mar 29, 22:27:36] 424 5.940629512199957
True
				 0.3177093267440796 3.219123601913452
#>>>    8.52 8.29 		|		 0.23000000000000043
[Mar 29, 22:27:37] 425 5.938225715497206
True
				 0.40696942806243896 3.0582473278045654
#>>>    8.39 8.14 		|		 0.25
[Mar 29, 22:27:37] 426 5.9357527064183655
True
				 0.3056979775428772 3.1178441047668457
#>>>    8.63 8.3 		|		 0.33000000000000007
[Mar 29, 22:27:38] 427 5.933240495734652
True
				 0.43925172090530396 3.012650489807129
#>>>    8.45 8.23 		|		 0.21999999999999886
[Mar 29, 22:27:39] 428 5.930759157390025
True
				 0.22638869285583496 3.22507381439209
#>>>    8.2 7.82 		|		 0.379999999999999
[Mar 29, 22:27:40] 429 5.928279860739883
True
				 0.4015887677669525 3.11064076423645
#>>>    8.48 8.21 		|		 0.2699999999999996
[Mar 29, 22:27:40] 430 5.925863810321739
True
				 0.2936543822288513 3.201198101043701
#>>>    8.4 8.27 		|		 0.13000000000000078
[Mar 29, 22:27:41] 431 5.923432799054295
True
				 0.35180819034576416 3.180459976196289
#>>>    8.29 7.94 		|		 0.34999999999999876
[Mar 29, 22:27:42] 432 5.921041634302573
True
				 0.3762032091617584 3.0164315700531006
#>>>    8.51 8.26 		|		 0.25
[Mar 29, 22:27:43] 433 5.9185132275368915
True
				 0.4776291847229004 3.4178271293640137
#>>>    8.09 8.23 		|		 -0.14000000000000057
[Mar 29, 22:27:43] 434 5.916490170623441
True
				 0.34509193897247314 3.1729423999786377
#>>>    8.21 7.79 		|		 0.4200000000000008
[Mar 29, 22:27:44] 435 5.914091714910978
True
				 0.44901910424232483 2.9602839946746826
#>>>    9.02 8.89 		|		 0.129999999999999
[Mar 29, 22:27:45] 436 5.911586926384391
True
				 0.44523265957832336 3.252394199371338
#>>>    8.93 8.6 		|		 0.33000000000000007
[Mar 29, 22:27:46] 437 5.909372966287155
True
				 0.5066573619842529 3.049008846282959
#>>>    9.41 8.94 		|		 0.47000000000000064
[Mar 29, 22:27:46] 438 5.907019259529135
True
				 0.3811834752559662 3.2958011627197266
#>>>    8.39 8.11 		|		 0.28000000000000114
[Mar 29, 22:27:47] 439 5.904789224818175
True
				 0.4998612403869629 2.8994357585906982
#>>>    9.3 8.37 		|		 0.9300000000000015
[Mar 29, 22:27:48] 440 5.902283732592334
True
				 0.4090173542499542 2.8011562824249268
#>>>    9.24 8.71 		|		 0.5299999999999994
[Mar 29, 22:27:48] 441 5.899591622466614
True
				 0.44065484404563904 3.0550920963287354
#>>>    8.87 8.41 		|		 0.4599999999999991
[Mar 29, 22:27:49] 442 5.897187777695115
True
				 0.4635196328163147 3.3408544063568115
#>>>    8.35 8.24 		|		 0.10999999999999943
[Mar 29, 22:27:50] 443 5.895094963896989
True
				 0.31899338960647583 3.3505024909973145
#>>>    7.97 7.46 		|		 0.5099999999999998
[Mar 29, 22:27:51] 444 5.892869364754091
True
				 0.4277336597442627 3.039027690887451
#>>>    9.11 8.74 		|		 0.3699999999999992
[Mar 29, 22:27:51] 445 5.890443256739969
True
				 0.4666554927825928 2.8100199699401855
#>>>    9.12 8.42 		|		 0.6999999999999993
[Mar 29, 22:27:52] 446 5.887829488945952
True
				 0.4280771017074585 2.886481285095215
#>>>    8.83 8.52 		|		 0.3100000000000005
[Mar 29, 22:27:53] 447 5.8852562179630175
True
				 0.4369797706604004 2.8759031295776367
#>>>    9.08 8.73 		|		 0.34999999999999964
[Mar 29, 22:27:54] 448 5.8826838446452925
True
				 0.4637758135795593 2.7983076572418213
#>>>    9.15 8.9 		|		 0.25
[Mar 29, 22:27:54] 449 5.880063244331073
True
				 0.3322274386882782 3.0419998168945312
#>>>    8.19 7.76 		|		 0.4299999999999997
[Mar 29, 22:27:55] 450 5.877557408372128
True
				 0.4067211151123047 2.9642226696014404
#>>>    8.99 8.45 		|		 0.5400000000000009
[Mar 29, 22:27:56] 451 5.87505079474847
True
				 0.33345910906791687 3.1974666118621826
#>>>    8.66 8.15 		|		 0.5099999999999998
[Mar 29, 22:27:57] 452 5.872706669704454
True
				 0.4961884319782257 2.8295907974243164
#>>>    9.14 8.46 		|		 0.6799999999999997
[Mar 29, 22:27:57] 453 5.87015974223435
True
				 0.42764872312545776 2.844223976135254
#>>>    8.34 7.99 		|		 0.34999999999999964
[Mar 29, 22:27:58] 454 5.86756145525098
True
				 0.623062014579773 2.8818702697753906
#>>>    9.62 9.15 		|		 0.46999999999999886
[Mar 29, 22:27:59] 455 5.865198826199294
True
				 0.38729265332221985 2.8488004207611084
#>>>    8.96 8.46 		|		 0.5
[Mar 29, 22:28:00] 456 5.862569720417376
True
				 0.4525132477283478 2.9418575763702393
#>>>    9.14 8.93 		|		 0.21000000000000085
[Mar 29, 22:28:00] 457 5.860101521491255
True
				 0.4106139540672302 3.0893688201904297
#>>>    9.12 8.52 		|		 0.5999999999999996
[Mar 29, 22:28:01] 458 5.857741402803626
True
				 0.38476043939590454 3.1147103309631348
#>>>    8.66 8.23 		|		 0.4299999999999997
[Mar 29, 22:28:02] 459 5.855383132111577
True
				 0.3532905578613281 2.9092936515808105
#>>>    8.85 8.23 		|		 0.6199999999999992
[Mar 29, 22:28:03] 460 5.852790333188907
True
				 0.46820396184921265 3.4395134449005127
#>>>    8.9 8.81 		|		 0.08999999999999986
[Mar 29, 22:28:03] 461 5.850845260322073
True
				 0.48795560002326965 3.0289812088012695
#>>>    8.89 8.6 		|		 0.2900000000000009
[Mar 29, 22:28:04] 462 5.848511351840774
True
				 0.4843314290046692 2.8573241233825684
#>>>    9.15 8.9 		|		 0.25
[Mar 29, 22:28:05] 463 5.846004495981715
True
				 0.3528197407722473 3.1975884437561035
#>>>    7.98 7.54 		|		 0.4400000000000004
[Mar 29, 22:28:05] 464 5.843708899610657
True
				 0.4241352677345276 3.507513999938965
#>>>    8.21 7.72 		|		 0.4900000000000011
[Mar 29, 22:28:06] 465 5.841796839919116
True
				 0.33690398931503296 2.8663063049316406
#>>>    8.19 7.57 		|		 0.6199999999999992
[Mar 29, 22:28:07] 466 5.839158253433049
True
				 0.46546316146850586 3.6728687286376953
#>>>    8.26 7.97 		|		 0.29000000000000004
[Mar 29, 22:28:08] 467 5.8374574270697215
True
				 0.42478078603744507 3.1518256664276123
#>>>    8.12 7.88 		|		 0.23999999999999932
[Mar 29, 22:28:08] 468 5.835196576154721
True
				 0.44624242186546326 2.904339551925659
#>>>    8.58 8.31 		|		 0.2699999999999996
[Mar 29, 22:28:09] 469 5.832711961462951
True
				 0.4604976773262024 3.0516088008880615
#>>>    8.35 7.78 		|		 0.5699999999999994
[Mar 29, 22:28:10] 470 5.8303913559200975
True
				 0.4207068383693695 3.049773693084717
#>>>    8.21 8.04 		|		 0.1700000000000017
[Mar 29, 22:28:11] 471 5.828031445006225
True
				 0.38321158289909363 3.010988235473633
#>>>    8.43 7.9 		|		 0.5299999999999994
[Mar 29, 22:28:11] 472 5.8255976134093945
True
				 0.4052160978317261 3.1966845989227295
#>>>    8.39 8.42 		|		 -0.02999999999999936
[Mar 29, 22:28:12] 473 5.82337391637353
True
				 0.41331684589385986 2.819504499435425
#>>>    9.08 8.7 		|		 0.3800000000000008
[Mar 29, 22:28:13] 474 5.820783363921695
True
				 0.45695334672927856 2.852252721786499
#>>>    8.95 8.39 		|		 0.5599999999999987
[Mar 29, 22:28:14] 475 5.818271786566684
True
				 0.5877696871757507 2.584186553955078
#>>>    9.8 9.13 		|		 0.6699999999999999
[Mar 29, 22:28:14] 476 5.815625471080852
True
				 0.4694904088973999 2.947136640548706
#>>>    8.91 8.24 		|		 0.6699999999999999
[Mar 29, 22:28:15] 477 5.813226472540008
True
				 0.4700424075126648 2.959948778152466
#>>>    8.78 8.41 		|		 0.3699999999999992
[Mar 29, 22:28:16] 478 5.810843237312738
True
				 0.44773754477500916 2.9684431552886963
#>>>    8.94 8.68 		|		 0.2599999999999998
[Mar 29, 22:28:17] 479 5.808448574686081
True
				 0.5002110004425049 2.8663456439971924
#>>>    9.07 8.34 		|		 0.7300000000000004
[Mar 29, 22:28:17] 480 5.806006682755835
True
				 0.4382067322731018 3.0450148582458496
#>>>    8.89 8.26 		|		 0.6300000000000008
[Mar 29, 22:28:18] 481 5.803683897603994
True
				 0.552550196647644 3.3674559593200684
#>>>    8.91 8.99 		|		 -0.08000000000000007
[Mar 29, 22:28:19] 482 5.801800219981567
True
				 0.40889644622802734 3.0505549907684326
#>>>    8.63 7.96 		|		 0.6700000000000008
[Mar 29, 22:28:20] 483 5.799457871198582
True
				 0.43274933099746704 2.9945106506347656
#>>>    9.08 8.28 		|		 0.8000000000000007
[Mar 29, 22:28:20] 484 5.797085673249411
True
				 0.40321415662765503 2.752066135406494
#>>>    8.84 8.39 		|		 0.4499999999999993
[Mar 29, 22:28:21] 485 5.7944438679278
True
				 0.37854719161987305 2.9304287433624268
#>>>    9.14 8.75 		|		 0.39000000000000057
[Mar 29, 22:28:22] 486 5.791958399994854
True
				 0.5252740979194641 2.91013503074646
#>>>    8.7 8.41 		|		 0.28999999999999915
[Mar 29, 22:28:23] 487 5.78960185066392
True
				 0.4449138939380646 2.7740397453308105
#>>>    8.94 8.65 		|		 0.28999999999999915
[Mar 29, 22:28:23] 488 5.787031202422723
True
				 0.5042092204093933 2.533830404281616
#>>>    9.72 9.21 		|		 0.5099999999999998
[Mar 29, 22:28:24] 489 5.784282210904596
True
				 0.3788297474384308 3.0030155181884766
#>>>    8.59 8.08 		|		 0.5099999999999998
[Mar 29, 22:28:25] 490 5.781879773929516
True
				 0.47497621178627014 2.8066060543060303
#>>>    8.95 8.53 		|		 0.41999999999999993
[Mar 29, 22:28:25] 491 5.779379476511086
True
				 0.4617232084274292 2.8805081844329834
#>>>    8.64 8.29 		|		 0.3500000000000014
[Mar 29, 22:28:26] 492 5.776942328308226
True
				 0.36763033270835876 3.109747886657715
#>>>    8.34 7.62 		|		 0.7199999999999998
[Mar 29, 22:28:27] 493 5.774642764109878
True
				 0.4442855417728424 3.2824039459228516
#>>>    8.12 7.66 		|		 0.4599999999999991
[Mar 29, 22:28:28] 494 5.77259481092287
True
				 0.40257132053375244 3.0310192108154297
#>>>    9.17 8.65 		|		 0.5199999999999996
[Mar 29, 22:28:28] 495 5.770255806524087
True
				 0.3986049294471741 2.900104284286499
#>>>    8.7 8.44 		|		 0.2599999999999998
[Mar 29, 22:28:29] 496 5.767784259871692
True
				 0.5243985652923584 2.884546995162964
#>>>    8.82 8.26 		|		 0.5600000000000005
[Mar 29, 22:28:30] 497 5.765425421172275
True
				 0.4440072178840637 2.6601874828338623
#>>>    8.73 8.45 		|		 0.28000000000000114
[Mar 29, 22:28:31] 498 5.762764190392216
True
				 0.43483713269233704 2.747943878173828
#>>>    9.17 8.41 		|		 0.7599999999999998
[Mar 29, 22:28:31] 499 5.7601842071828875
True
				 0.4980265498161316 2.7904326915740967
#>>>    8.69 8.42 		|		 0.2699999999999996
[Mar 29, 22:28:32] 500 5.757712482276699
True
				 0.35979005694389343 3.256882667541504
#>>>    8.36 8.1 		|		 0.2599999999999998
[Mar 29, 22:28:33] 501 5.75557144254871
True
				 0.45229461789131165 2.6034762859344482
#>>>    8.87 8.28 		|		 0.5899999999999999
[Mar 29, 22:28:34] 502 5.752871641980184
True
				 0.4127092957496643 2.7053375244140625
#>>>    9.47 8.65 		|		 0.8200000000000003
[Mar 29, 22:28:34] 503 5.750236817098763
True
				 0.48661625385284424 3.0491373538970947
#>>>    8.79 8.51 		|		 0.27999999999999936
[Mar 29, 22:28:35] 504 5.748022334008623
True
				 0.5059399604797363 2.7877564430236816
#>>>    8.83 8.63 		|		 0.1999999999999993
[Mar 29, 22:28:36] 505 5.745568008078117
True
				 0.48324424028396606 2.5619664192199707
#>>>    9.0 8.64 		|		 0.35999999999999943
[Mar 29, 22:28:37] 506 5.742867650669939
True
				 0.3983299136161804 2.6857666969299316
#>>>    8.68 8.33 		|		 0.34999999999999964
[Mar 29, 22:28:37] 507 5.740208879689419
True
				 0.46527862548828125 2.548626184463501
#>>>    9.07 8.63 		|		 0.4399999999999995
[Mar 29, 22:28:38] 508 5.737482575619681
True
				 0.5473411679267883 3.2416532039642334
#>>>    9.45 9.48 		|		 -0.030000000000001137
[Mar 29, 22:28:39] 509 5.735534087356347
True
				 0.4995805621147156 2.617661237716675
#>>>    8.63 8.08 		|		 0.5500000000000007
[Mar 29, 22:28:39] 510 5.732915795128427
True
				 0.4806380867958069 2.8694450855255127
#>>>    8.61 8.19 		|		 0.41999999999999993
[Mar 29, 22:28:40] 511 5.7305329624460155
True
				 0.5134533643722534 2.745089530944824
#>>>    8.87 8.53 		|		 0.33999999999999986
[Mar 29, 22:28:41] 512 5.7280609724980955
True
				 0.40142694115638733 2.976069450378418
#>>>    8.14 7.62 		|		 0.5200000000000005
[Mar 29, 22:28:42] 513 5.72571040800654
True
				 0.3847702741622925 3.5745255947113037
#>>>    7.68 7.68 		|		 0.0
[Mar 29, 22:28:42] 514 5.723943993348198
True
				 0.419170081615448 2.9315123558044434
#>>>    9.0 8.55 		|		 0.4499999999999993
[Mar 29, 22:28:43] 515 5.721570731851874
True
				 0.3795745074748993 2.8222105503082275
#>>>    8.72 8.19 		|		 0.5300000000000011
[Mar 29, 22:28:44] 516 5.719050946207608
True
				 0.5020207166671753 2.879539966583252
#>>>    8.4 8.16 		|		 0.2400000000000002
[Mar 29, 22:28:45] 517 5.71671345606386
True
				 0.5303943157196045 2.706249952316284
#>>>    8.86 8.46 		|		 0.3999999999999986
[Mar 29, 22:28:45] 518 5.714233386875832
True
				 0.41321927309036255 2.813530445098877
#>>>    8.53 8.07 		|		 0.4599999999999991
[Mar 29, 22:28:46] 519 5.71174590314754
True
				 0.3658086359500885 2.9254372119903564
#>>>    8.66 8.19 		|		 0.47000000000000064
[Mar 29, 22:28:47] 520 5.70932540318174
True
				 0.33347779512405396 3.06510853767395
#>>>    8.41 8.12 		|		 0.2900000000000009
[Mar 29, 22:28:48] 521 5.707014664051751
True
				 0.5634968280792236 3.118692398071289
#>>>    8.96 8.68 		|		 0.28000000000000114
[Mar 29, 22:28:48] 522 5.704989838613851
True
				 0.42289331555366516 2.8995437622070312
#>>>    9.01 8.74 		|		 0.2699999999999996
[Mar 29, 22:28:49] 523 5.702607285823196
True
				 0.500100314617157 2.5118961334228516
#>>>    9.6 8.85 		|		 0.75
[Mar 29, 22:28:50] 524 5.699916675045017
True
				 0.5322928428649902 2.5197975635528564
#>>>    9.93 9.35 		|		 0.5800000000000001
[Mar 29, 22:28:51] 525 5.69726884877639
True
				 0.4056844115257263 2.8373799324035645
#>>>    8.97 8.49 		|		 0.4800000000000004
[Mar 29, 22:28:51] 526 5.694814644331147
True
				 0.5015435218811035 2.851365566253662
#>>>    9.14 9.15 		|		 -0.009999999999999787
[Mar 29, 22:28:52] 527 5.692472738774951
True
				 0.4950239062309265 2.8550524711608887
#>>>    9.44 9.15 		|		 0.28999999999999915
[Mar 29, 22:28:53] 528 5.690130342473172
True
				 0.6155093908309937 2.8833038806915283
#>>>    9.42 9.28 		|		 0.14000000000000057
[Mar 29, 22:28:54] 529 5.687939025283012
True
				 0.504027783870697 2.6969058513641357
#>>>    9.67 9.13 		|		 0.5399999999999991
[Mar 29, 22:28:54] 530 5.685452019952568
True
				 0.48370349407196045 2.443211555480957
#>>>    9.7 8.89 		|		 0.8099999999999987
[Mar 29, 22:28:55] 531 5.682693483101378
True
				 0.5145301818847656 2.7858188152313232
#>>>    9.49 8.75 		|		 0.7400000000000002
[Mar 29, 22:28:56] 532 5.680311138615393
True
				 0.44638878107070923 2.851274013519287
#>>>    9.48 8.96 		|		 0.5199999999999996
[Mar 29, 22:28:56] 533 5.677928490211762
True
				 0.500004768371582 2.458386182785034
#>>>    10.0 9.7 		|		 0.3000000000000007
[Mar 29, 22:28:57] 534 5.6752089526727065
True
				 0.44018781185150146 2.676082134246826
#>>>    9.49 8.95 		|		 0.5400000000000009
[Mar 29, 22:28:58] 535 5.672650013785341
True
				 0.479817658662796 2.6424686908721924
#>>>    10.1 9.49 		|		 0.6099999999999994
[Mar 29, 22:28:59] 536 5.670099650091288
True
				 0.4930631220340729 2.619877576828003
#>>>    9.97 9.57 		|		 0.40000000000000036
[Mar 29, 22:28:59] 537 5.667542491229466
True
				 0.4478785991668701 2.548900604248047
#>>>    9.47 9.43 		|		 0.040000000000000924
[Mar 29, 22:29:00] 538 5.664871727941652
True
				 0.4679023027420044 2.893451452255249
#>>>    8.95 8.37 		|		 0.5800000000000001
[Mar 29, 22:29:01] 539 5.662568210087916
True
				 0.5748468041419983 2.7591404914855957
#>>>    9.44 9.06 		|		 0.379999999999999
[Mar 29, 22:29:02] 540 5.6602396291138515
True
				 0.3988340497016907 2.786203384399414
#>>>    8.96 8.46 		|		 0.5
[Mar 29, 22:29:02] 541 5.657764426859234
True
				 0.463684618473053 2.99359130859375
#>>>    9.61 9.33 		|		 0.27999999999999936
[Mar 29, 22:29:03] 542 5.655563938299838
True
				 0.61137855052948 2.3736116886138916
#>>>    9.56 9.01 		|		 0.5500000000000007
[Mar 29, 22:29:04] 543 5.652893364481472
True
				 0.4468749761581421 2.7837746143341064
#>>>    9.44 8.66 		|		 0.7799999999999994
[Mar 29, 22:29:05] 544 5.650471120588274
True
				 0.3449609875679016 2.9630813598632812
#>>>    8.37 8.29 		|		 0.08000000000000007
[Mar 29, 22:29:05] 545 5.648128691755512
True
				 0.5015047788619995 2.719862937927246
#>>>    9.78 9.43 		|		 0.34999999999999964
[Mar 29, 22:29:06] 546 5.645701930899755
True
				 0.41898787021636963 3.0115089416503906
#>>>    8.57 8.47 		|		 0.09999999999999964
[Mar 29, 22:29:07] 547 5.643486725661513
True
				 0.4467483162879944 2.7302374839782715
#>>>    8.52 7.93 		|		 0.5899999999999999
[Mar 29, 22:29:08] 548 5.641020224676513
True
				 0.4897134304046631 3.0215461254119873
#>>>    8.72 8.71 		|		 0.009999999999999787
[Mar 29, 22:29:08] 549 5.638890464007653
True
				 0.5808330774307251 2.747343063354492
#>>>    9.5 8.89 		|		 0.6099999999999994
[Mar 29, 22:29:09] 550 5.636579749565221
True
				 0.5574628114700317 2.6932036876678467
#>>>    8.62 8.08 		|		 0.5399999999999991
[Mar 29, 22:29:10] 551 5.634193836434003
True
				 0.49310800433158875 2.4739551544189453
#>>>    9.22 8.76 		|		 0.46000000000000085
[Mar 29, 22:29:11] 552 5.631526705786122
True
				 0.46338117122650146 2.8839259147644043
#>>>    8.7 8.53 		|		 0.16999999999999993
[Mar 29, 22:29:11] 553 5.629242486285537
True
				 0.5736930966377258 2.600461483001709
#>>>    9.14 8.69 		|		 0.45000000000000107
[Mar 29, 22:29:12] 554 5.626787398319286
True
				 0.49782389402389526 2.748363494873047
#>>>    8.99 8.56 		|		 0.4299999999999997
[Mar 29, 22:29:13] 555 5.624406798369469
True
				 0.4639304280281067 2.50889253616333
#>>>    8.76 8.28 		|		 0.4800000000000004
[Mar 29, 22:29:14] 556 5.621755214475686
True
				 0.43235892057418823 2.7256386280059814
#>>>    8.76 8.33 		|		 0.4299999999999997
[Mar 29, 22:29:14] 557 5.619291456869396
True
				 0.41779980063438416 2.7766380310058594
#>>>    9.04 8.81 		|		 0.22999999999999865
[Mar 29, 22:29:15] 558 5.61686660315476
True
				 0.5198986530303955 2.5889430046081543
#>>>    9.45 9.17 		|		 0.27999999999999936
[Mar 29, 22:29:16] 559 5.614358578209244
True
				 0.44799867272377014 2.846141815185547
#>>>    8.7 8.47 		|		 0.22999999999999865
[Mar 29, 22:29:16] 560 5.612038360208351
True
				 0.528501570224762 2.6078763008117676
#>>>    9.18 8.32 		|		 0.8599999999999994
[Mar 29, 22:29:17] 561 5.609562699659574
True
				 0.47615742683410645 2.5403401851654053
#>>>    9.69 9.33 		|		 0.35999999999999943
[Mar 29, 22:29:18] 562 5.6069696345719136
True
				 0.4693717658519745 2.8220691680908203
#>>>    8.63 8.21 		|		 0.41999999999999993
[Mar 29, 22:29:19] 563 5.604654105901087
True
				 0.5601069927215576 2.5271928310394287
#>>>    9.21 8.85 		|		 0.3600000000000012
[Mar 29, 22:29:19] 564 5.602136751618947
True
				 0.46541696786880493 2.458085775375366
#>>>    9.6 9.07 		|		 0.5299999999999994
[Mar 29, 22:29:20] 565 5.599458117550968
True
				 0.36611735820770264 2.8231863975524902
#>>>    8.77 8.22 		|		 0.5499999999999989
[Mar 29, 22:29:21] 566 5.597047963308387
True
				 0.6383296251296997 3.005298137664795
#>>>    9.04 8.64 		|		 0.3999999999999986
[Mar 29, 22:29:22] 567 5.595094542988663
True
				 0.4923601746559143 2.7018001079559326
#>>>    9.83 9.65 		|		 0.17999999999999972
[Mar 29, 22:29:22] 568 5.592693608668681
True
				 0.5312484502792358 2.2576632499694824
#>>>    9.6 9.22 		|		 0.379999999999999
[Mar 29, 22:29:23] 569 5.589889826879471
True
				 0.5616058707237244 2.7512454986572266
#>>>    9.83 9.56 		|		 0.2699999999999996
[Mar 29, 22:29:24] 570 5.587612788481577
True
				 0.4759564995765686 2.8442790508270264
#>>>    9.57 9.32 		|		 0.25
[Mar 29, 22:29:25] 571 5.585345411183894
True
				 0.4103787839412689 2.735410213470459
#>>>    9.1 8.62 		|		 0.4800000000000004
[Mar 29, 22:29:25] 572 5.582905854680715
True
				 0.5625185966491699 2.9979476928710938
#>>>    9.09 8.71 		|		 0.379999999999999
[Mar 29, 22:29:26] 573 5.580883415115554
True
				 0.5067826509475708 2.3482561111450195
#>>>    9.69 9.12 		|		 0.5700000000000003
[Mar 29, 22:29:27] 574 5.578157570343322
True
				 0.4915510416030884 2.733602285385132
#>>>    9.08 8.64 		|		 0.4399999999999995
[Mar 29, 22:29:28] 575 5.575804566219176
True
				 0.486005574464798 2.677004098892212
#>>>    9.78 9.34 		|		 0.4399999999999995
[Mar 29, 22:29:28] 576 5.573391771296512
True
				 0.511099100112915 2.210867404937744
#>>>    9.73 9.13 		|		 0.5999999999999996
[Mar 29, 22:29:29] 577 5.570540346030266
True
				 0.4524136781692505 2.5222644805908203
#>>>    8.47 8.1 		|		 0.370000000000001
[Mar 29, 22:29:30] 578 5.567944483723786
True
				 0.4592354893684387 2.7954158782958984
#>>>    8.72 8.56 		|		 0.16000000000000014
[Mar 29, 22:29:31] 579 5.565631190548122
True
				 0.5644946098327637 2.8090555667877197
#>>>    9.17 8.67 		|		 0.5
[Mar 29, 22:29:31] 580 5.563439109534194
True
				 0.6011199951171875 2.831024408340454
#>>>    9.59 9.26 		|		 0.33000000000000007
[Mar 29, 22:29:32] 581 5.561307814828117
True
				 0.428230345249176 2.7207767963409424
#>>>    8.8 8.71 		|		 0.08999999999999986
[Mar 29, 22:29:33] 582 5.5588955140952745
True
				 0.443374902009964 2.547654151916504
#>>>    9.36 8.78 		|		 0.5800000000000001
[Mar 29, 22:29:34] 583 5.556327647605303
True
				 0.566809892654419 2.584700584411621
#>>>    9.35 9.07 		|		 0.27999999999999936
[Mar 29, 22:29:34] 584 5.553922830434764
True
				 0.5277875661849976 2.4613349437713623
#>>>    9.68 9.22 		|		 0.4599999999999991
[Mar 29, 22:29:35] 585 5.551358029995075
True
				 0.35505759716033936 2.7166402339935303
#>>>    9.13 8.71 		|		 0.41999999999999993
[Mar 29, 22:29:36] 586 5.548878369677024
True
				 0.5231454968452454 2.5602447986602783
#>>>    9.62 8.7 		|		 0.9199999999999999
[Mar 29, 22:29:36] 587 5.546412881543248
True
				 0.5672142505645752 2.4777307510375977
#>>>    9.71 9.16 		|		 0.5500000000000007
[Mar 29, 22:29:37] 588 5.543911413663308
True
				 0.5542725324630737 2.3860931396484375
#>>>    9.5 9.05 		|		 0.4499999999999993
[Mar 29, 22:29:38] 589 5.541307868040965
True
				 0.5443586111068726 2.509673833847046
#>>>    8.98 8.52 		|		 0.46000000000000085
[Mar 29, 22:29:39] 590 5.538820592498668
True
				 0.4250994622707367 2.5842843055725098
#>>>    9.3 8.66 		|		 0.6400000000000006
[Mar 29, 22:29:39] 591 5.536291155584606
True
				 0.4755482077598572 2.8678157329559326
#>>>    8.73 8.62 		|		 0.11000000000000121
[Mar 29, 22:29:40] 592 5.534098228429342
True
				 0.45097386837005615 2.4213664531707764
#>>>    9.23 8.54 		|		 0.6900000000000013
[Mar 29, 22:29:41] 593 5.531436470403244
True
				 0.581128716468811 2.506951332092285
#>>>    9.19 8.79 		|		 0.40000000000000036
[Mar 29, 22:29:42] 594 5.528993113862192
True
				 0.5733950138092041 2.640029191970825
#>>>    9.44 9.01 		|		 0.4299999999999997
[Mar 29, 22:29:42] 595 5.526677544954111
True
				 0.5092637538909912 2.2561659812927246
#>>>    9.06 8.34 		|		 0.7200000000000006
[Mar 29, 22:29:43] 596 5.52391629714434
True
				 0.5843753814697266 2.7178940773010254
#>>>    9.07 8.61 		|		 0.46000000000000085
[Mar 29, 22:29:44] 597 5.5216946503059665
True
				 0.5822494029998779 2.7623677253723145
#>>>    9.07 8.88 		|		 0.1899999999999995
[Mar 29, 22:29:45] 598 5.519517572784032
True
				 0.5047051906585693 2.595837116241455
#>>>    8.83 8.59 		|		 0.2400000000000002
[Mar 29, 22:29:45] 599 5.517098597518148
True
				 0.4773815870285034 2.699251174926758
#>>>    8.9 8.52 		|		 0.3800000000000008
[Mar 29, 22:29:46] 600 5.514758131801794
True
				 0.4155813455581665 2.987994432449341
#>>>    8.45 8.04 		|		 0.41000000000000014
[Mar 29, 22:29:47] 601 5.512646949567209
True
				 0.5142395496368408 2.313718795776367
#>>>    9.49 8.84 		|		 0.6500000000000004
[Mar 29, 22:29:48] 602 5.509962260963055
True
				 0.5437703728675842 2.9397640228271484
#>>>    8.6 8.34 		|		 0.2599999999999998
[Mar 29, 22:29:48] 603 5.507935833038182
True
				 0.3977353274822235 2.5205154418945312
#>>>    9.05 8.51 		|		 0.5400000000000009
[Mar 29, 22:29:49] 604 5.505346148004323
True
				 0.4324462413787842 2.8735249042510986
#>>>    9.36 9.31 		|		 0.049999999999998934
[Mar 29, 22:29:50] 605 5.503146773001949
True
				 0.48214054107666016 2.68536639213562
#>>>    9.06 8.98 		|		 0.08000000000000007
[Mar 29, 22:29:51] 606 5.500811133162159
True
				 0.5327821373939514 2.523160219192505
#>>>    9.95 9.69 		|		 0.2599999999999998
[Mar 29, 22:29:51] 607 5.498366264325979
True
				 0.5330390334129333 2.269958972930908
#>>>    9.92 9.33 		|		 0.5899999999999999
[Mar 29, 22:29:52] 608 5.495670896127601
True
				 0.5932639837265015 2.4558749198913574
#>>>    9.86 9.45 		|		 0.41000000000000014
[Mar 29, 22:29:53] 609 5.4932243642543
True
				 0.5530369281768799 2.5418219566345215
#>>>    9.43 8.77 		|		 0.6600000000000001
[Mar 29, 22:29:53] 610 5.490825998774857
True
				 0.5790917873382568 2.309163808822632
#>>>    10.21 9.89 		|		 0.3200000000000003
[Mar 29, 22:29:54] 611 5.488223428372242
True
				 0.5771209001541138 2.3022830486297607
#>>>    9.83 9.19 		|		 0.6400000000000006
[Mar 29, 22:29:55] 612 5.485614609011863
True
				 0.60332190990448 2.7324018478393555
#>>>    9.66 9.02 		|		 0.6400000000000006
[Mar 29, 22:29:56] 613 5.483464718279804
True
				 0.5770450830459595 2.5776357650756836
#>>>    9.79 9.58 		|		 0.20999999999999908
[Mar 29, 22:29:56] 614 5.481135934290437
True
				 0.4817711412906647 2.5725812911987305
#>>>    9.11 8.73 		|		 0.379999999999999
[Mar 29, 22:29:57] 615 5.478709150878044
True
				 0.4624527096748352 2.59673810005188
#>>>    9.38 8.77 		|		 0.6100000000000012
[Mar 29, 22:29:58] 616 5.476289632477288
True
				 0.5764825940132141 2.48633074760437
#>>>    9.73 9.07 		|		 0.6600000000000001
[Mar 29, 22:29:59] 617 5.473876156126824
True
				 0.44830650091171265 2.3952009677886963
#>>>    9.27 8.66 		|		 0.6099999999999994
[Mar 29, 22:29:59] 618 5.471245787499003
True
				 0.60069739818573 2.5139546394348145
#>>>    9.44 9.03 		|		 0.41000000000000014
[Mar 29, 22:30:00] 619 5.468889193868334
True
				 0.4808207154273987 2.5579001903533936
#>>>    9.48 9.02 		|		 0.46000000000000085
[Mar 29, 22:30:01] 620 5.466459025520641
True
				 0.44288259744644165 3.072141647338867
#>>>    8.73 8.58 		|		 0.15000000000000036
[Mar 29, 22:30:02] 621 5.4645075906803005
True
				 0.5134187936782837 2.7121007442474365
#>>>    9.37 8.93 		|		 0.4399999999999995
[Mar 29, 22:30:02] 622 5.462268602746755
True
				 0.4469107985496521 2.7279112339019775
#>>>    8.98 8.54 		|		 0.4400000000000013
[Mar 29, 22:30:03] 623 5.459981156236064
True
				 0.510138750076294 2.4724154472351074
#>>>    9.49 9.25 		|		 0.2400000000000002
[Mar 29, 22:30:04] 624 5.457503729277139
True
				 0.5804908275604248 2.2032883167266846
#>>>    10.35 9.86 		|		 0.4900000000000002
[Mar 29, 22:30:05] 625 5.454830004692149
True
				 0.5531714558601379 2.440486431121826
#>>>    9.38 8.93 		|		 0.45000000000000107
[Mar 29, 22:30:05] 626 5.452368832514835
True
				 0.7248328328132629 2.209439277648926
#>>>    9.72 9.03 		|		 0.6900000000000013
[Mar 29, 22:30:06] 627 5.449850735733177
True
				 0.4858902096748352 2.630556344985962
#>>>    9.14 8.47 		|		 0.6699999999999999
[Mar 29, 22:30:07] 628 5.4475173314925005
True
				 0.48571157455444336 2.935516595840454
#>>>    9.14 9.04 		|		 0.10000000000000142
[Mar 29, 22:30:08] 629 5.445491042331403
True
				 0.5396068096160889 2.356689691543579
#>>>    9.69 8.94 		|		 0.75
[Mar 29, 22:30:08] 630 5.442941847790231
True
				 0.6411786079406738 2.1260311603546143
#>>>    9.88 8.82 		|		 1.0600000000000005
[Mar 29, 22:30:09] 631 5.440266115710736
True
				 0.6241390705108643 2.520880937576294
#>>>    8.91 8.59 		|		 0.3200000000000003
[Mar 29, 22:30:10] 632 5.437970869603113
True
				 0.6386381387710571 2.325131893157959
#>>>    9.47 9.08 		|		 0.39000000000000057
[Mar 29, 22:30:10] 633 5.43549666864623
True
				 0.46003711223602295 2.5511324405670166
#>>>    9.59 9.08 		|		 0.5099999999999998
[Mar 29, 22:30:11] 634 5.433072341411178
True
				 0.4922192096710205 2.478591203689575
#>>>    9.48 9.01 		|		 0.47000000000000064
[Mar 29, 22:30:12] 635 5.430610079483127
True
				 0.6897721290588379 2.634803295135498
#>>>    9.77 9.49 		|		 0.27999999999999936
[Mar 29, 22:30:13] 636 5.4285040448278385
True
				 0.46483808755874634 2.2333803176879883
#>>>    9.57 8.96 		|		 0.6099999999999994
[Mar 29, 22:30:13] 637 5.425773759128653
True
				 0.5919443368911743 2.2926788330078125
#>>>    10.0 9.34 		|		 0.6600000000000001
[Mar 29, 22:30:14] 638 5.423232608420214
True
				 0.4868354797363281 2.4223690032958984
#>>>    9.16 8.34 		|		 0.8200000000000003
[Mar 29, 22:30:15] 639 5.420718580294826
True
				 0.44787856936454773 2.375587224960327
#>>>    9.44 8.99 		|		 0.4499999999999993
[Mar 29, 22:30:16] 640 5.418121327538659
True
				 0.4583743214607239 2.6116456985473633
#>>>    8.88 7.73 		|		 1.1500000000000004
[Mar 29, 22:30:16] 641 5.415773226171523
True
				 0.6577306985855103 2.612104892730713
#>>>    9.2 8.78 		|		 0.41999999999999993
[Mar 29, 22:30:17] 642 5.413627288417459
True
				 0.4325229823589325 2.465219020843506
#>>>    8.92 8.77 		|		 0.15000000000000036
[Mar 29, 22:30:18] 643 5.411111403162046
True
				 0.5223077535629272 2.4310338497161865
#>>>    9.31 8.73 		|		 0.5800000000000001
[Mar 29, 22:30:19] 644 5.408653633242954
True
				 0.5784881114959717 2.1207659244537354
#>>>    9.86 9.4 		|		 0.4599999999999991
[Mar 29, 22:30:19] 645 5.405944233645661
True
				 0.620174765586853 2.437497854232788
#>>>    10.11 9.54 		|		 0.5700000000000003
[Mar 29, 22:30:20] 646 5.403595961912625
True
				 0.4860724210739136 2.5152318477630615
#>>>    8.91 8.34 		|		 0.5700000000000003
[Mar 29, 22:30:21] 647 5.40119367010034
True
				 0.5727759599685669 2.30066180229187
#>>>    9.47 9.02 		|		 0.45000000000000107
[Mar 29, 22:30:22] 648 5.398665914311709
True
				 0.5184231400489807 2.5643301010131836
#>>>    9.16 8.72 		|		 0.4399999999999995
[Mar 29, 22:30:22] 649 5.396350001578855
True
				 0.5051307678222656 2.2774829864501953
#>>>    9.62 9.09 		|		 0.5299999999999994
[Mar 29, 22:30:23] 650 5.393736265331548
True
				 0.617402195930481 2.3769640922546387
#>>>    9.21 8.67 		|		 0.5400000000000009
[Mar 29, 22:30:24] 651 5.391336895235193
True
				 0.5894505977630615 2.3851373195648193
#>>>    10.0 9.59 		|		 0.41000000000000014
[Mar 29, 22:30:25] 652 5.388920146257286
True
				 0.6130749583244324 2.3839285373687744
#>>>    9.24 8.69 		|		 0.5500000000000007
[Mar 29, 22:30:25] 653 5.386528229666327
True
				 0.5021829009056091 2.79471755027771
#>>>    8.93 8.37 		|		 0.5600000000000005
[Mar 29, 22:30:26] 654 5.3844386019474495
True
				 0.5322710275650024 2.254525899887085
#>>>    9.68 9.33 		|		 0.34999999999999964
[Mar 29, 22:30:27] 655 5.3818409603921635
True
				 0.5252602696418762 2.3408565521240234
#>>>    9.23 8.59 		|		 0.6400000000000006
[Mar 29, 22:30:28] 656 5.3793252361939325
True
				 0.6208013296127319 2.1849489212036133
#>>>    9.87 9.14 		|		 0.7299999999999986
[Mar 29, 22:30:28] 657 5.376751661327765
True
				 0.5817314386367798 2.4707813262939453
#>>>    9.24 8.75 		|		 0.4900000000000002
[Mar 29, 22:30:29] 658 5.374427422312158
True
				 0.5561801791191101 2.2150495052337646
#>>>    9.76 9.41 		|		 0.34999999999999964
[Mar 29, 22:30:30] 659 5.371824224633803
True
				 0.591713011264801 2.444671154022217
#>>>    9.7 9.36 		|		 0.33999999999999986
[Mar 29, 22:30:30] 660 5.369488784514852
True
				 0.6185897588729858 2.212553024291992
#>>>    9.86 9.02 		|		 0.8399999999999999
[Mar 29, 22:30:31] 661 5.366950438632711
True
				 0.5496518611907959 2.2573659420013428
#>>>    9.45 8.73 		|		 0.7199999999999989
[Mar 29, 22:30:32] 662 5.36439050599727
True
				 0.519099771976471 2.3647682666778564
#>>>    9.1 8.62 		|		 0.4800000000000004
[Mar 29, 22:30:33] 663 5.361909983470322
True
				 0.5792933702468872 2.394566535949707
#>>>    9.21 8.6 		|		 0.6100000000000012
[Mar 29, 22:30:33] 664 5.359521933273839
True
				 0.6533747911453247 2.25618839263916
#>>>    9.31 8.59 		|		 0.7200000000000006
[Mar 29, 22:30:34] 665 5.35707197440514
True
				 0.524408221244812 2.3005902767181396
#>>>    9.23 8.86 		|		 0.370000000000001
[Mar 29, 22:30:35] 666 5.354539900809488
True
				 0.5727326273918152 2.43210506439209
#>>>    9.02 8.22 		|		 0.7999999999999989
[Mar 29, 22:30:36] 667 5.352190198660067
True
				 0.6512728333473206 2.7610247135162354
#>>>    9.43 8.99 		|		 0.4399999999999995
[Mar 29, 22:30:36] 668 5.350250305948666
True
				 0.4553777575492859 2.845952033996582
#>>>    8.97 8.62 		|		 0.3500000000000014
[Mar 29, 22:30:37] 669 5.348201385493868
True
				 0.7231569290161133 2.2684953212738037
#>>>    10.19 9.49 		|		 0.6999999999999993
[Mar 29, 22:30:38] 670 5.345844836358665
True
				 0.5683938264846802 2.5143558979034424
#>>>    9.6 9.11 		|		 0.4900000000000002
[Mar 29, 22:30:39] 671 5.343581741365903
True
				 0.43468528985977173 2.6177945137023926
#>>>    9.39 8.81 		|		 0.5800000000000001
[Mar 29, 22:30:39] 672 5.341290639368495
True
				 0.5324467420578003 2.234683036804199
#>>>    9.58 9.09 		|		 0.4900000000000002
[Mar 29, 22:30:40] 673 5.338716478627198
True
				 0.5841981768608093 2.425503969192505
#>>>    9.65 9.46 		|		 0.1899999999999995
[Mar 29, 22:30:41] 674 5.336387464354228
True
				 0.6268035769462585 2.7658843994140625
#>>>    9.53 9.48 		|		 0.049999999999998934
[Mar 29, 22:30:42] 675 5.3344437649258385
True
				 0.5913553237915039 2.2276201248168945
#>>>    9.8 9.36 		|		 0.4400000000000013
[Mar 29, 22:30:42] 676 5.331928296609521
True
				 0.47610732913017273 2.3401737213134766
#>>>    9.33 8.84 		|		 0.4900000000000002
[Mar 29, 22:30:43] 677 5.329412649393158
True
				 0.6060901880264282 2.068307876586914
#>>>    10.21 9.68 		|		 0.5300000000000011
[Mar 29, 22:30:44] 678 5.326757634689169
True
				 0.592185378074646 2.243692398071289
#>>>    9.66 8.96 		|		 0.6999999999999993
[Mar 29, 22:30:44] 679 5.324266754949836
True
				 0.6547449827194214 2.102266788482666
#>>>    9.95 9.26 		|		 0.6899999999999995
[Mar 29, 22:30:45] 680 5.321699500085297
True
				 0.5519760251045227 2.3355772495269775
#>>>    9.79 9.41 		|		 0.379999999999999
[Mar 29, 22:30:46] 681 5.3192653538002395
True
				 0.3940203785896301 2.5533370971679688
#>>>    8.68 8.07 		|		 0.6099999999999994
[Mar 29, 22:30:47] 682 5.3168934458625925
True
				 0.4986189305782318 2.2787528038024902
#>>>    9.4 8.85 		|		 0.5500000000000007
[Mar 29, 22:30:47] 683 5.314353924061703
True
				 0.5460410118103027 2.1445982456207275
#>>>    9.57 9.03 		|		 0.5400000000000009
[Mar 29, 22:30:48] 684 5.311730209395073
True
				 0.704222559928894 2.596499443054199
#>>>    9.65 9.07 		|		 0.5800000000000001
[Mar 29, 22:30:49] 685 5.30971920130787
True
				 0.4993060827255249 2.481635093688965
#>>>    8.94 8.42 		|		 0.5199999999999996
[Mar 29, 22:30:50] 686 5.307390423402186
True
				 0.5508189797401428 2.677985668182373
#>>>    9.57 9.0 		|		 0.5700000000000003
[Mar 29, 22:30:50] 687 5.305311837567102
True
				 0.5266862511634827 2.3987720012664795
#>>>    9.77 9.48 		|		 0.28999999999999915
[Mar 29, 22:30:51] 688 5.30293198392236
True
				 0.6130766868591309 2.225006341934204
#>>>    9.74 8.52 		|		 1.2200000000000006
[Mar 29, 22:30:52] 689 5.3004671349672305
True
				 0.4854240417480469 2.3477070331573486
#>>>    9.75 9.1 		|		 0.6500000000000004
[Mar 29, 22:30:53] 690 5.297999798907169
True
				 0.6050820350646973 2.6597073078155518
#>>>    8.97 8.73 		|		 0.2400000000000002
[Mar 29, 22:30:53] 691 5.295966588451142
True
				 0.46666428446769714 2.3727922439575195
#>>>    9.57 8.91 		|		 0.6600000000000001
[Mar 29, 22:30:54] 692 5.293510078420918
True
				 0.4491405189037323 2.1087887287139893
#>>>    9.92 9.33 		|		 0.5899999999999999
[Mar 29, 22:30:55] 693 5.290774497619917
True
				 0.3630262017250061 2.488399028778076
#>>>    9.29 8.41 		|		 0.879999999999999
[Mar 29, 22:30:56] 694 5.288335148293195
True
				 0.5888689160346985 2.460592269897461
#>>>    9.74 9.59 		|		 0.15000000000000036
[Mar 29, 22:30:56] 695 5.2860962742712285
True
				 0.5400089025497437 2.6808624267578125
#>>>    9.74 9.7 		|		 0.040000000000000924
[Mar 29, 22:30:57] 696 5.284031049445474
True
				 0.5793923139572144 2.367309093475342
#>>>    9.6 9.07 		|		 0.5299999999999994
[Mar 29, 22:30:58] 697 5.281693719922671
True
				 0.57581627368927 2.3251967430114746
#>>>    9.9 9.43 		|		 0.47000000000000064
[Mar 29, 22:30:59] 698 5.27931303910024
True
				 0.5966300964355469 2.5776724815368652
#>>>    9.13 9.05 		|		 0.08000000000000007
[Mar 29, 22:30:59] 699 5.277208028639111
True
				 0.7099961638450623 2.2113006114959717
#>>>    10.7 10.35 		|		 0.34999999999999964
[Mar 29, 22:31:00] 700 5.274852117445418
True
				 0.7444548010826111 2.4000141620635986
#>>>    10.41 10.22 		|		 0.1899999999999995
[Mar 29, 22:31:01] 701 5.272721734350724
True
				 0.5785599946975708 2.3610126972198486
#>>>    10.13 9.6 		|		 0.5300000000000011
[Mar 29, 22:31:02] 702 5.2703885854275
True
				 0.5477018356323242 2.408834934234619
#>>>    10.07 9.4 		|		 0.6699999999999999
[Mar 29, 22:31:02] 703 5.26807473361194
True
				 0.57003253698349 2.580125570297241
#>>>    9.76 9.34 		|		 0.41999999999999993
[Mar 29, 22:31:03] 704 5.265956817045213
True
				 0.5657931566238403 2.1062326431274414
#>>>    10.09 9.72 		|		 0.3699999999999992
[Mar 29, 22:31:04] 705 5.26336288590871
True
				 0.5734513998031616 2.2372095584869385
#>>>    9.69 9.3 		|		 0.3899999999999988
[Mar 29, 22:31:05] 706 5.260910183861881
True
				 0.7685573101043701 2.5029234886169434
#>>>    9.81 9.45 		|		 0.3600000000000012
[Mar 29, 22:31:05] 707 5.2589207544767405
True
				 0.6153697371482849 2.1362011432647705
#>>>    9.76 8.88 		|		 0.879999999999999
[Mar 29, 22:31:06] 708 5.256413404662282
True
				 0.4352114200592041 2.4813380241394043
#>>>    9.34 8.92 		|		 0.41999999999999993
[Mar 29, 22:31:07] 709 5.2540735407018175
True
				 0.5789855718612671 2.676762342453003
#>>>    9.45 9.27 		|		 0.17999999999999972
[Mar 29, 22:31:07] 710 5.252075214956221
True
				 0.6241484880447388 2.446842670440674
#>>>    9.45 9.04 		|		 0.41000000000000014
[Mar 29, 22:31:08] 711 5.249894130780541
True
				 0.49262797832489014 2.4968478679656982
#>>>    9.26 8.69 		|		 0.5700000000000003
[Mar 29, 22:31:09] 712 5.247633712376842
True
				 0.622929573059082 2.321718215942383
#>>>    9.34 8.92 		|		 0.41999999999999993
[Mar 29, 22:31:10] 713 5.245330726453467
True
				 0.6314477920532227 2.52207350730896
#>>>    9.33 9.02 		|		 0.3100000000000005
[Mar 29, 22:31:10] 714 5.243238917026376
True
				 0.5663812160491943 2.1553969383239746
#>>>    9.57 9.04 		|		 0.5300000000000011
[Mar 29, 22:31:11] 715 5.240717456263722
True
				 0.5138006210327148 2.5661914348602295
#>>>    9.16 8.71 		|		 0.4499999999999993
[Mar 29, 22:31:12] 716 5.238556730863351
True
				 0.5370458364486694 2.336634874343872
#>>>    8.98 8.43 		|		 0.5500000000000007
[Mar 29, 22:31:13] 717 5.236191854724071
True
				 0.4785550832748413 2.8994102478027344
#>>>    8.77 8.41 		|		 0.35999999999999943
[Mar 29, 22:31:13] 718 5.234333628319634
True
				 0.5790491104125977 2.290120840072632
#>>>    9.8 9.17 		|		 0.6300000000000008
[Mar 29, 22:31:14] 719 5.2319684646418
True
				 0.5976716876029968 2.3481054306030273
#>>>    9.66 8.98 		|		 0.6799999999999997
[Mar 29, 22:31:15] 720 5.229682273354968
True
				 0.5659078359603882 2.4160068035125732
#>>>    9.69 9.23 		|		 0.4599999999999991
[Mar 29, 22:31:16] 721 5.227434505601877
True
				 0.49406304955482483 2.626175880432129
#>>>    9.76 8.84 		|		 0.9199999999999999
[Mar 29, 22:31:16] 722 5.225327310115669
True
				 0.5292246341705322 2.3763976097106934
#>>>    9.12 8.73 		|		 0.3899999999999988
[Mar 29, 22:31:17] 723 5.223007605049435
True
				 0.5273035168647766 2.1652801036834717
#>>>    9.69 9.09 		|		 0.5999999999999996
[Mar 29, 22:31:18] 724 5.22047718100533
True
				 0.6379694938659668 1.951582670211792
#>>>    10.49 9.63 		|		 0.8599999999999994
[Mar 29, 22:31:19] 725 5.217846255988402
True
				 0.549759030342102 2.1555306911468506
#>>>    9.48 8.85 		|		 0.6300000000000008
[Mar 29, 22:31:19] 726 5.215333699573112
True
				 0.5548164248466492 2.4321744441986084
#>>>    9.13 8.94 		|		 0.19000000000000128
[Mar 29, 22:31:20] 727 5.213105356802188
True
				 0.6975786089897156 2.1571598052978516
#>>>    10.23 9.64 		|		 0.5899999999999999
[Mar 29, 22:31:21] 728 5.210746989919278
True
				 0.63632732629776 2.5401527881622314
#>>>    9.98 9.77 		|		 0.21000000000000085
[Mar 29, 22:31:22] 729 5.208712722984214
True
				 0.5555522441864014 2.203368902206421
#>>>    9.79 9.12 		|		 0.6699999999999999
[Mar 29, 22:31:22] 730 5.206262931407623
True
				 0.5661807060241699 2.47747540473938
#>>>    9.38 9.23 		|		 0.15000000000000036
[Mar 29, 22:31:23] 731 5.204100324586979
True
				 0.6661521196365356 2.2047858238220215
#>>>    9.8 8.95 		|		 0.8500000000000014
[Mar 29, 22:31:24] 732 5.201767162086641
True
				 0.578666090965271 1.9976838827133179
#>>>    9.95 8.92 		|		 1.0299999999999994
[Mar 29, 22:31:25] 733 5.199141744898234
True
				 0.6263048052787781 2.5688490867614746
#>>>    9.53 9.4 		|		 0.129999999999999
[Mar 29, 22:31:25] 734 5.19713775710498
True
				 0.6340188980102539 2.3163528442382812
#>>>    9.68 9.21 		|		 0.46999999999999886
[Mar 29, 22:31:26] 735 5.194890991090124
True
				 0.6772204041481018 2.3389928340911865
#>>>    9.65 9.2 		|		 0.45000000000000107
[Mar 29, 22:31:27] 736 5.192712313277668
True
				 0.5137298107147217 2.4604671001434326
#>>>    9.7 9.09 		|		 0.6099999999999994
[Mar 29, 22:31:28] 737 5.190493797875249
True
				 0.6550056338310242 2.5624990463256836
#>>>    9.56 9.2 		|		 0.3600000000000012
[Mar 29, 22:31:28] 738 5.188520808817135
True
				 0.5272845029830933 2.222574234008789
#>>>    9.41 9.04 		|		 0.370000000000001
[Mar 29, 22:31:29] 739 5.186082146864519
True
				 0.5677680373191833 2.5307884216308594
#>>>    9.75 9.58 		|		 0.16999999999999993
[Mar 29, 22:31:30] 740 5.1839946212362085
True
				 0.5780247449874878 2.3082566261291504
#>>>    9.75 9.15 		|		 0.5999999999999996
[Mar 29, 22:31:30] 741 5.181696908105298
True
				 0.618738055229187 2.7738091945648193
#>>>    9.08 8.83 		|		 0.25
[Mar 29, 22:31:31] 742 5.179907758327778
True
				 0.5449484586715698 2.328763484954834
#>>>    9.72 9.04 		|		 0.6800000000000015
[Mar 29, 22:31:32] 743 5.177601562632286
True
				 0.5318108797073364 2.104327917098999
#>>>    9.98 9.13 		|		 0.8499999999999996
[Mar 29, 22:31:33] 744 5.175060099985669
True
				 0.6311818957328796 2.6440865993499756
#>>>    9.88 9.79 		|		 0.09000000000000163
[Mar 29, 22:31:33] 745 5.17316030844037
True
				 0.6756117343902588 2.4544224739074707
#>>>    10.12 9.02 		|		 1.0999999999999996
[Mar 29, 22:31:34] 746 5.171117182340228
True
				 0.6097395420074463 2.0553996562957764
#>>>    10.29 9.68 		|		 0.6099999999999994
[Mar 29, 22:31:35] 747 5.168611204356191
True
				 0.640962541103363 2.7718019485473633
#>>>    10.09 9.7 		|		 0.39000000000000057
[Mar 29, 22:31:36] 748 5.16685535770109
True
				 0.5887541770935059 2.5694022178649902
#>>>    9.88 9.32 		|		 0.5600000000000005
[Mar 29, 22:31:36] 749 5.164846658738347
True
				 0.6572614908218384 2.074051856994629
#>>>    10.44 9.73 		|		 0.7099999999999991
[Mar 29, 22:31:37] 750 5.162413125308216
True
				 0.5975877642631531 2.0749120712280273
#>>>    10.39 9.45 		|		 0.9400000000000013
[Mar 29, 22:31:38] 751 5.159923212078003
True
				 0.5795168876647949 2.159355640411377
#>>>    10.24 9.72 		|		 0.5199999999999996
[Mar 29, 22:31:39] 752 5.157502161394001
True
				 0.5503249764442444 2.275419235229492
#>>>    9.95 9.63 		|		 0.3199999999999985
[Mar 29, 22:31:39] 753 5.155170403384677
True
				 0.5629427433013916 2.4142045974731445
#>>>    10.25 9.96 		|		 0.28999999999999915
[Mar 29, 22:31:40] 754 5.1529923803220665
True
				 0.6169863939285278 2.4005918502807617
#>>>    9.93 9.4 		|		 0.5299999999999994
[Mar 29, 22:31:41] 755 5.150856966066745
True
				 0.6727728843688965 2.2532639503479004
#>>>    10.1 9.39 		|		 0.7099999999999991
[Mar 29, 22:31:42] 756 5.148632145935395
True
				 0.4574393332004547 2.5498270988464355
#>>>    9.27 8.78 		|		 0.4900000000000002
[Mar 29, 22:31:42] 757 5.146490780310914
True
				 0.5860182046890259 2.474302291870117
#>>>    9.05 8.61 		|		 0.4400000000000013
[Mar 29, 22:31:43] 758 5.144404609907953
True
				 0.4509935975074768 3.0071239471435547
#>>>    8.78 8.8 		|		 -0.02000000000000135
[Mar 29, 22:31:44] 759 5.142718322783092
True
				 0.5599063038825989 2.1857988834381104
#>>>    9.6 9.23 		|		 0.3699999999999992
[Mar 29, 22:31:45] 760 5.140321309588026
True
				 0.6077408194541931 2.009969472885132
#>>>    10.28 9.73 		|		 0.5499999999999989
[Mar 29, 22:31:45] 761 5.137798698630382
True
				 0.745259165763855 1.978208303451538
#>>>    10.82 9.98 		|		 0.8399999999999999
[Mar 29, 22:31:46] 762 5.135384367281758
True
				 0.5729975700378418 2.4511032104492188
#>>>    9.39 8.98 		|		 0.41000000000000014
[Mar 29, 22:31:47] 763 5.133273083694963
True
				 0.5264754295349121 2.3422415256500244
#>>>    9.85 9.33 		|		 0.5199999999999996
[Mar 29, 22:31:48] 764 5.131008527566453
True
				 0.5552657842636108 2.4514801502227783
#>>>    10.01 9.79 		|		 0.22000000000000064
[Mar 29, 22:31:48] 765 5.128884264854164
True
				 0.5446577668190002 1.9996025562286377
#>>>    9.69 9.01 		|		 0.6799999999999997
[Mar 29, 22:31:49] 766 5.126299640852753
True
				 0.7145837545394897 2.241661787033081
#>>>    10.65 10.0 		|		 0.6500000000000004
[Mar 29, 22:31:50] 767 5.124129586634264
True
				 0.5737571716308594 2.545229196548462
#>>>    10.13 9.38 		|		 0.75
[Mar 29, 22:31:50] 768 5.122124443415809
True
				 0.6419214010238647 2.124432325363159
#>>>    10.04 9.48 		|		 0.5599999999999987
[Mar 29, 22:31:51] 769 5.119768672579571
True
				 0.5246177315711975 2.322577714920044
#>>>    9.66 9.1 		|		 0.5600000000000005
[Mar 29, 22:31:52] 770 5.117496099293878
True
				 0.6230367422103882 2.195953607559204
#>>>    10.14 9.59 		|		 0.5500000000000007
[Mar 29, 22:31:53] 771 5.115197593425145
True
				 0.49185070395469666 2.4561550617218018
#>>>    9.4 8.86 		|		 0.5400000000000009
[Mar 29, 22:31:53] 772 5.113030401507989
True
				 0.7344277501106262 2.336287260055542
#>>>    9.77 9.39 		|		 0.379999999999999
[Mar 29, 22:31:54] 773 5.110988086057042
True
				 0.5334647297859192 2.3571674823760986
#>>>    9.7 8.87 		|		 0.8300000000000001
[Mar 29, 22:31:55] 774 5.108767730123543
True
				 0.5655102729797363 2.2648675441741943
#>>>    9.87 9.17 		|		 0.6999999999999993
[Mar 29, 22:31:56] 775 5.106489340210573
True
				 0.5173241496086121 2.5514349937438965
#>>>    9.81 9.69 		|		 0.120000000000001
[Mar 29, 22:31:56] 776 5.10445161007332
True
				 0.6524385809898376 2.0379300117492676
#>>>    9.74 9.18 		|		 0.5600000000000005
[Mar 29, 22:31:57] 777 5.10203752711559
True
				 0.5727008581161499 2.2574164867401123
#>>>    9.58 8.91 		|		 0.6699999999999999
[Mar 29, 22:31:58] 778 5.099765606814122
True
				 0.5941848754882812 2.0300023555755615
#>>>    9.91 9.03 		|		 0.8800000000000008
[Mar 29, 22:31:59] 779 5.097290028438372
True
				 0.584373414516449 2.4540674686431885
#>>>    9.38 8.77 		|		 0.6100000000000012
[Mar 29, 22:31:59] 780 5.095231179352697
True
				 0.7381730079650879 2.1390607357025146
#>>>    9.99 9.58 		|		 0.41000000000000014
[Mar 29, 22:32:00] 781 5.093013181917012
True
				 0.47359970211982727 2.3291070461273193
#>>>    9.5 8.88 		|		 0.6199999999999992
[Mar 29, 22:32:01] 782 5.090722875453539
True
				 0.5891040563583374 2.212559700012207
#>>>    9.91 9.26 		|		 0.6500000000000004
[Mar 29, 22:32:02] 783 5.088433816453666
True
				 0.5257478952407837 2.2959842681884766
#>>>    9.61 9.21 		|		 0.3999999999999986
[Mar 29, 22:32:02] 784 5.086167114681432
True
				 0.6215344667434692 2.278733015060425
#>>>    9.58 8.96 		|		 0.6199999999999992
[Mar 29, 22:32:03] 785 5.083981215167763
True
				 0.637117862701416 2.262923240661621
#>>>    10.6 10.16 		|		 0.4399999999999995
[Mar 29, 22:32:04] 786 5.081797275055958
True
				 0.6192839741706848 2.2307159900665283
#>>>    9.94 9.54 		|		 0.40000000000000036
[Mar 29, 22:32:05] 787 5.079565477685534
True
				 0.7621002197265625 2.0915560722351074
#>>>    10.37 9.97 		|		 0.3999999999999986
[Mar 29, 22:32:05] 788 5.077339568499811
True
				 0.6022300124168396 2.4331231117248535
#>>>    9.65 9.39 		|		 0.2599999999999998
[Mar 29, 22:32:06] 789 5.075297582115057
True
				 0.6356826424598694 1.9727991819381714
#>>>    10.85 10.21 		|		 0.6399999999999988
[Mar 29, 22:32:07] 790 5.072830766416945
True
				 0.6882377862930298 2.0981695652008057
#>>>    10.56 9.72 		|		 0.8399999999999999
[Mar 29, 22:32:08] 791 5.070544343121231
True
				 0.5758033394813538 2.0822136402130127
#>>>    9.68 8.76 		|		 0.9199999999999999
[Mar 29, 22:32:08] 792 5.068131815698199
True
				 0.4847811162471771 2.1043953895568848
#>>>    9.8 9.36 		|		 0.4400000000000013
[Mar 29, 22:32:09] 793 5.065652860298898
True
				 0.4475986659526825 2.3995590209960938
#>>>    9.27 8.82 		|		 0.4499999999999993
[Mar 29, 22:32:10] 794 5.0634343651553495
True
				 0.550708532333374 2.1722850799560547
#>>>    9.3 8.83 		|		 0.47000000000000064
[Mar 29, 22:32:11] 795 5.061093924402484
True
				 0.6863596439361572 2.2694008350372314
#>>>    9.62 9.27 		|		 0.34999999999999964
[Mar 29, 22:32:11] 796 5.058988590957054
True
				 0.603015124797821 2.0142154693603516
#>>>    9.46 8.83 		|		 0.6300000000000008
[Mar 29, 22:32:12] 797 5.05654683301986
True
				 0.6465327739715576 2.2004640102386475
#>>>    9.99 9.49 		|		 0.5
[Mar 29, 22:32:13] 798 5.054337282971051
True
				 0.46065837144851685 2.366629123687744
#>>>    9.54 9.22 		|		 0.3199999999999985
[Mar 29, 22:32:13] 799 5.052110233123612
True
				 0.7663053274154663 2.0271191596984863
#>>>    10.02 9.25 		|		 0.7699999999999996
[Mar 29, 22:32:14] 800 5.049851547496811
True
				 0.5907690525054932 1.8275129795074463
#>>>    9.88 9.35 		|		 0.5300000000000011
[Mar 29, 22:32:15] 801 5.047219977981327
True
				 0.4619375467300415 2.2126946449279785
#>>>    9.48 8.83 		|		 0.6500000000000004
[Mar 29, 22:32:16] 802 5.044847390075795
True
				 0.5997224450111389 2.1411681175231934
#>>>    10.08 9.43 		|		 0.6500000000000004
[Mar 29, 22:32:16] 803 5.042543433188648
True
				 0.581925630569458 2.2126057147979736
#>>>    9.89 9.25 		|		 0.6400000000000006
[Mar 29, 22:32:17] 804 5.040295421100827
True
				 0.6057453155517578 2.1555964946746826
#>>>    10.18 9.66 		|		 0.5199999999999996
[Mar 29, 22:32:18] 805 5.038016467489952
True
				 0.7512958645820618 1.993593692779541
#>>>    10.16 9.51 		|		 0.6500000000000004
[Mar 29, 22:32:19] 806 5.035723340520219
True
				 0.6524065732955933 1.9354711771011353
#>>>    10.44 9.84 		|		 0.5999999999999996
[Mar 29, 22:32:19] 807 5.033275494930096
True
				 0.6219360828399658 2.113673448562622
#>>>    10.21 9.92 		|		 0.2900000000000009
[Mar 29, 22:32:20] 808 5.030977828966568
True
				 0.44143539667129517 2.1120800971984863
#>>>    9.86 9.49 		|		 0.3699999999999992
[Mar 29, 22:32:21] 809 5.028500366571866
True
				 0.6892735958099365 1.995329737663269
#>>>    10.11 9.07 		|		 1.0399999999999991
[Mar 29, 22:32:22] 810 5.026156469419559
True
				 0.5780905485153198 2.199049234390259
#>>>    10.14 9.87 		|		 0.27000000000000135
[Mar 29, 22:32:22] 811 5.023907452613836
True
				 0.5996671915054321 2.4744985103607178
#>>>    9.8 9.24 		|		 0.5600000000000005
[Mar 29, 22:32:23] 812 5.0219577109822975
True
				 0.6237770318984985 2.444892644882202
#>>>    10.1 9.76 		|		 0.33999999999999986
[Mar 29, 22:32:24] 813 5.020004423067305
True
				 0.6292527914047241 2.0132548809051514
#>>>    10.8 10.41 		|		 0.39000000000000057
[Mar 29, 22:32:25] 814 5.017626926197338
True
				 0.6536067724227905 2.046837568283081
#>>>    10.49 9.77 		|		 0.7200000000000006
[Mar 29, 22:32:25] 815 5.0153097434926375
True
				 0.6016931533813477 2.144301176071167
#>>>    10.19 9.55 		|		 0.6399999999999988
[Mar 29, 22:32:26] 816 5.013040428078598
True
				 0.7184678912162781 2.1256394386291504
#>>>    10.37 9.38 		|		 0.9899999999999984
[Mar 29, 22:32:27] 817 5.010871495039969
True
				 0.6041644811630249 2.47235107421875
#>>>    10.16 9.65 		|		 0.5099999999999998
[Mar 29, 22:32:28] 818 5.00893713921952
True
				 0.503709614276886 2.168048858642578
#>>>    9.91 9.13 		|		 0.7799999999999994
[Mar 29, 22:32:28] 819 5.006599960493615
True
				 0.5566864013671875 2.088446855545044
#>>>    10.13 9.6 		|		 0.5300000000000011
[Mar 29, 22:32:29] 820 5.004238493790034
True
				 0.5517275333404541 2.474064350128174
#>>>    9.71 9.27 		|		 0.4400000000000013
[Mar 29, 22:32:30] 821 5.002260047179712
True
				 0.5690615177154541 1.9190113544464111
#>>>    10.15 9.54 		|		 0.6100000000000012
[Mar 29, 22:32:30] 822 4.999745860004695
True
				 0.7882343530654907 2.023153305053711
#>>>    10.53 10.13 		|		 0.3999999999999986
[Mar 29, 22:32:31] 823 4.9975575016836
True
				 0.4421205222606659 2.3784584999084473
#>>>    9.42 8.83 		|		 0.5899999999999999
[Mar 29, 22:32:32] 824 4.995380523233888
True
				 0.6530587673187256 2.283364772796631
#>>>    10.32 10.06 		|		 0.2599999999999998
[Mar 29, 22:32:33] 825 4.99332156625077
True
				 0.5667716264724731 2.0288000106811523
#>>>    10.04 9.17 		|		 0.8699999999999992
[Mar 29, 22:32:33] 826 4.990923816202463
True
				 0.6055185794830322 2.491098165512085
#>>>    9.74 9.39 		|		 0.34999999999999964
[Mar 29, 22:32:34] 827 4.989029509131256
True
				 0.5385038256645203 2.3677823543548584
#>>>    9.54 8.93 		|		 0.6099999999999994
[Mar 29, 22:32:35] 828 4.986946765861749
True
				 0.5895641446113586 1.937305212020874
#>>>    10.19 9.52 		|		 0.6699999999999999
[Mar 29, 22:32:36] 829 4.984486688392915
True
				 0.7191329598426819 2.221574544906616
#>>>    10.11 9.74 		|		 0.3699999999999992
[Mar 29, 22:32:36] 830 4.9824429091496665
True
				 0.5824524164199829 2.184504270553589
#>>>    9.64 9.19 		|		 0.45000000000000107
[Mar 29, 22:32:37] 831 4.9802274230467
True
				 0.5328786373138428 2.165686845779419
#>>>    10.0 9.4 		|		 0.5999999999999996
[Mar 29, 22:32:38] 832 4.977945761106747
True
				 0.6738702654838562 2.14009165763855
#>>>    10.02 9.3 		|		 0.7199999999999989
[Mar 29, 22:32:39] 833 4.975781777328367
True
				 0.7345357537269592 2.348278045654297
#>>>    9.59 9.27 		|		 0.3200000000000003
[Mar 29, 22:32:39] 834 4.973888809290815
True
				 0.7088308334350586 1.8124605417251587
#>>>    10.82 10.16 		|		 0.6600000000000001
[Mar 29, 22:32:40] 835 4.971436211737475
True
				 0.5179351568222046 2.2435200214385986
#>>>    9.43 8.61 		|		 0.8200000000000003
[Mar 29, 22:32:41] 836 4.969226230584789
True
				 0.5619164109230042 2.3201305866241455
#>>>    9.39 8.69 		|		 0.7000000000000011
[Mar 29, 22:32:42] 837 4.967139051292148
True
				 0.6357454061508179 2.07140851020813
#>>>    9.81 8.97 		|		 0.8399999999999999
[Mar 29, 22:32:42] 838 4.964879066038005
True
				 0.6066291928291321 2.210397958755493
#>>>    10.0 9.71 		|		 0.28999999999999915
[Mar 29, 22:32:43] 839 4.962731214063947
True
				 0.6379044055938721 1.9744439125061035
#>>>    10.2 9.7 		|		 0.5
[Mar 29, 22:32:44] 840 4.960380831167982
True
				 0.6052933931350708 2.25801420211792
#>>>    9.78 9.0 		|		 0.7799999999999994
[Mar 29, 22:32:44] 841 4.958283757812858
True
				 0.5192074775695801 2.1299750804901123
#>>>    9.77 9.21 		|		 0.5599999999999987
[Mar 29, 22:32:45] 842 4.955974656613105
True
				 0.7026174664497375 1.990781307220459
#>>>    10.01 9.28 		|		 0.7300000000000004
[Mar 29, 22:32:46] 843 4.953712080670557
True
				 0.6464290618896484 1.9310636520385742
#>>>    10.06 9.24 		|		 0.8200000000000003
[Mar 29, 22:32:47] 844 4.951335861303814
True
				 0.5405445694923401 2.4181458950042725
#>>>    8.59 8.15 		|		 0.4399999999999995
[Mar 29, 22:32:47] 845 4.949343215847402
True
				 0.7024968862533569 1.7139215469360352
#>>>    10.61 9.54 		|		 1.0700000000000003
[Mar 29, 22:32:48] 846 4.946810291183953
True
				 0.7220120429992676 2.2079174518585205
#>>>    9.63 8.86 		|		 0.7700000000000014
[Mar 29, 22:32:49] 847 4.944793410387627
True
				 0.5578974485397339 2.1182732582092285
#>>>    9.8 9.3 		|		 0.5
[Mar 29, 22:32:50] 848 4.9425247878031975
True
				 0.6393719911575317 2.084744930267334
#>>>    10.16 9.1 		|		 1.0600000000000005
[Mar 29, 22:32:50] 849 4.94030637981761
True
				 0.7431904673576355 1.937787413597107
#>>>    10.39 9.74 		|		 0.6500000000000004
[Mar 29, 22:32:51] 850 4.938047051259142
True
				 0.575508713722229 2.31693696975708
#>>>    9.71 9.32 		|		 0.39000000000000057
[Mar 29, 22:32:52] 851 4.936001449772153
True
				 0.5541581511497498 2.033907413482666
#>>>    10.01 9.48 		|		 0.5299999999999994
[Mar 29, 22:32:53] 852 4.933653513946617
True
				 0.7113812565803528 2.0092649459838867
#>>>    9.76 9.3 		|		 0.4599999999999991
[Mar 29, 22:32:53] 853 4.931440506575631
True
				 0.5875732898712158 1.941662073135376
#>>>    10.36 10.05 		|		 0.3099999999999987
[Mar 29, 22:32:54] 854 4.929038301432062
True
				 0.670380711555481 1.9216337203979492
#>>>    10.06 9.29 		|		 0.7700000000000014
[Mar 29, 22:32:55] 855 4.926701277443374
True
				 0.5309194326400757 2.1721577644348145
#>>>    9.18 8.6 		|		 0.5800000000000001
[Mar 29, 22:32:56] 856 4.924477653482215
True
				 0.6736226677894592 2.1558754444122314
#>>>    10.07 9.44 		|		 0.6300000000000008
[Mar 29, 22:32:56] 857 4.922382673881329
True
				 0.6259040236473083 2.0940988063812256
#>>>    10.37 9.65 		|		 0.7199999999999989
[Mar 29, 22:32:57] 858 4.920180294097081
True
				 0.671234130859375 2.0440638065338135
#>>>    10.23 9.49 		|		 0.7400000000000002
[Mar 29, 22:32:58] 859 4.917975411740377
True
				 0.6368599534034729 2.329047203063965
#>>>    9.98 9.47 		|		 0.5099999999999998
[Mar 29, 22:32:59] 860 4.9160233434255
True
				 0.6007653474807739 2.3949623107910156
#>>>    10.1 9.57 		|		 0.5299999999999994
[Mar 29, 22:32:59] 861 4.914103047621136
True
				 0.5670197010040283 1.9036548137664795
#>>>    10.54 9.78 		|		 0.7599999999999998
[Mar 29, 22:33:00] 862 4.911659619088286
True
				 0.5287863612174988 1.953456997871399
#>>>    9.77 8.96 		|		 0.8099999999999987
[Mar 29, 22:33:01] 863 4.909230202768682
True
				 0.7171005010604858 2.0285918712615967
#>>>    9.5 8.76 		|		 0.7400000000000002
[Mar 29, 22:33:01] 864 4.907066664819026
True
				 0.676568865776062 1.8209114074707031
#>>>    10.28 9.41 		|		 0.8699999999999992
[Mar 29, 22:33:02] 865 4.904657078546664
True
				 0.5496994256973267 2.147388219833374
#>>>    9.7 9.24 		|		 0.4599999999999991
[Mar 29, 22:33:03] 866 4.902449509232857
True
				 0.6229656934738159 1.9484270811080933
#>>>    10.31 9.78 		|		 0.5300000000000011
[Mar 29, 22:33:04] 867 4.900118452498206
True
				 0.7072066068649292 2.0336365699768066
#>>>    9.95 8.66 		|		 1.2899999999999991
[Mar 29, 22:33:05] 868 4.897959177341758
True
				 0.7745131254196167 1.8979030847549438
#>>>    10.09 9.05 		|		 1.0399999999999991
[Mar 29, 22:33:05] 869 4.895733634374591
True
				 0.5308393836021423 2.014838218688965
#>>>    10.08 9.56 		|		 0.5199999999999996
[Mar 29, 22:33:06] 870 4.893383578402112
True
				 0.6183484792709351 2.021226167678833
#>>>    9.76 8.93 		|		 0.8300000000000001
[Mar 29, 22:33:07] 871 4.89112976935145
True
				 0.620063066482544 2.0810043811798096
#>>>    9.65 8.87 		|		 0.7800000000000011
[Mar 29, 22:33:07] 872 4.8889397070297615
True
				 0.5830283164978027 1.9310660362243652
#>>>    10.23 9.49 		|		 0.7400000000000002
[Mar 29, 22:33:08] 873 4.886564861675454
True
				 0.4712716341018677 2.003103017807007
#>>>    9.56 9.04 		|		 0.5200000000000014
[Mar 29, 22:33:09] 874 4.884152671584896
True
				 0.6901589632034302 2.027374744415283
#>>>    10.53 9.91 		|		 0.6199999999999992
[Mar 29, 22:33:10] 875 4.881986052501721
True
				 0.6529954671859741 2.0315868854522705
#>>>    10.14 9.26 		|		 0.8800000000000008
[Mar 29, 22:33:10] 876 4.879788648682648
True
				 0.5936461687088013 2.243318557739258
#>>>    9.85 9.53 		|		 0.3200000000000003
[Mar 29, 22:33:11] 877 4.877745824641204
True
				 0.5004280805587769 2.1264469623565674
#>>>    9.27 8.71 		|		 0.5599999999999987
[Mar 29, 22:33:12] 878 4.875494953740269
True
				 0.5351511240005493 2.2204134464263916
#>>>    9.75 9.18 		|		 0.5700000000000003
[Mar 29, 22:33:13] 879 4.873375023476164
True
				 0.5159592628479004 2.219437837600708
#>>>    9.7 9.07 		|		 0.629999999999999
[Mar 29, 22:33:13] 880 4.871237045553137
True
				 0.7963526844978333 2.2349696159362793
#>>>    10.24 9.76 		|		 0.4800000000000004
[Mar 29, 22:33:14] 881 4.869397130748413
True
				 0.6256418228149414 2.0787312984466553
#>>>    9.6 8.7 		|		 0.9000000000000004
[Mar 29, 22:33:15] 882 4.867232106738927
True
				 0.5810203552246094 2.281654119491577
#>>>    9.46 8.96 		|		 0.5
[Mar 29, 22:33:16] 883 4.865227549106904
True
				 0.5073733329772949 2.353987693786621
#>>>    9.5 8.84 		|		 0.6600000000000001
[Mar 29, 22:33:16] 884 4.863223682584561
True
				 0.6619592308998108 1.8833035230636597
#>>>    10.7 9.74 		|		 0.9599999999999991
[Mar 29, 22:33:17] 885 4.860905721715544
True
				 0.5984541177749634 2.2298288345336914
#>>>    9.75 9.29 		|		 0.46000000000000085
[Mar 29, 22:33:18] 886 4.858873098826928
True
				 0.6083535552024841 2.291936159133911
#>>>    9.64 8.66 		|		 0.9800000000000004
[Mar 29, 22:33:19] 887 4.856914515502043
True
				 0.7203493714332581 2.2444114685058594
#>>>    10.4 9.73 		|		 0.6699999999999999
[Mar 29, 22:33:19] 888 4.855022361766875
True
				 0.6655584573745728 2.1664228439331055
#>>>    9.99 9.5 		|		 0.4900000000000002
[Mar 29, 22:33:20] 889 4.852999320587207
True
				 0.6492791175842285 2.0975611209869385
#>>>    10.06 9.45 		|		 0.6100000000000012
[Mar 29, 22:33:21] 890 4.850893161505192
True
				 0.6589783430099487 1.896442174911499
#>>>    10.51 9.7 		|		 0.8100000000000005
[Mar 29, 22:33:22] 891 4.848597688742399
True
				 0.683700680732727 1.989203929901123
#>>>    10.39 9.42 		|		 0.9700000000000006
[Mar 29, 22:33:22] 892 4.846421995545081
True
				 0.5781058073043823 2.4461774826049805
#>>>    10.29 10.13 		|		 0.15999999999999837
[Mar 29, 22:33:23] 893 4.844599856958655
True
				 0.6085408926010132 2.135857582092285
#>>>    10.7 10.32 		|		 0.379999999999999
[Mar 29, 22:33:24] 894 4.842499655695598
True
				 0.5276467800140381 1.9836821556091309
#>>>    10.06 9.47 		|		 0.5899999999999999
[Mar 29, 22:33:25] 895 4.840168484975526
True
				 0.7877922654151917 2.104124069213867
#>>>    10.61 10.23 		|		 0.379999999999999
[Mar 29, 22:33:25] 896 4.838220232765575
True
				 0.6919212341308594 1.8091368675231934
#>>>    10.78 10.15 		|		 0.629999999999999
[Mar 29, 22:33:26] 897 4.835883070634463
True
				 0.6109289526939392 2.0929439067840576
#>>>    10.61 9.84 		|		 0.7699999999999996
[Mar 29, 22:33:27] 898 4.833751060482911
True
				 0.7106635570526123 1.9954825639724731
#>>>    10.49 9.83 		|		 0.6600000000000001
[Mar 29, 22:33:28] 899 4.831623455662662
True
				 0.6242269277572632 2.1527068614959717
#>>>    9.76 9.25 		|		 0.5099999999999998
[Mar 29, 22:33:28] 900 4.829568765877044
True
				 0.6720210313796997 1.7949552536010742
#>>>    10.52 10.11 		|		 0.41000000000000014
[Mar 29, 22:33:29] 901 4.827206173276938
True
				 0.6938026547431946 2.191804885864258
#>>>    9.72 8.74 		|		 0.9800000000000004
[Mar 29, 22:33:30] 902 4.825264574584663
True
				 0.6179904341697693 2.042243242263794
#>>>    10.19 9.64 		|		 0.5499999999999989
[Mar 29, 22:33:30] 903 4.823099543746117
True
				 0.6252174377441406 2.1249027252197266
#>>>    10.11 9.69 		|		 0.41999999999999993
[Mar 29, 22:33:31] 904 4.821026564365335
True
				 0.5357479453086853 2.0839669704437256
#>>>    9.85 9.62 		|		 0.23000000000000043
[Mar 29, 22:33:32] 905 4.8188252527763265
True
				 0.744780957698822 1.9833571910858154
#>>>    10.3 9.78 		|		 0.5200000000000014
[Mar 29, 22:33:33] 906 4.816734565731939
True
				 0.6019798517227173 2.0078258514404297
#>>>    10.07 9.33 		|		 0.7400000000000002
[Mar 29, 22:33:33] 907 4.814527636750161
True
				 0.6679784059524536 2.0400588512420654
#>>>    10.73 9.92 		|		 0.8100000000000005
[Mar 29, 22:33:34] 908 4.812421146489815
True
				 0.7536923289299011 2.2435081005096436
#>>>    10.72 10.02 		|		 0.7000000000000011
[Mar 29, 22:33:35] 909 4.81060592583237
True
				 0.5867489576339722 2.3557591438293457
#>>>    10.01 9.78 		|		 0.23000000000000043
[Mar 29, 22:33:36] 910 4.80873782812721
True
				 0.6900379657745361 1.920149803161621
#>>>    10.06 8.96 		|		 1.0999999999999996
[Mar 29, 22:33:36] 911 4.806539278068019
True
				 0.6647305488586426 1.9534456729888916
#>>>    10.33 9.6 		|		 0.7300000000000004
[Mar 29, 22:33:37] 912 4.804350915011799
True
				 0.5680747628211975 2.1131162643432617
#>>>    9.52 8.84 		|		 0.6799999999999997
[Mar 29, 22:33:38] 913 4.802227755064347
True
				 0.5662329792976379 2.0766117572784424
#>>>    9.66 8.88 		|		 0.7799999999999994
[Mar 29, 22:33:39] 914 4.800068371986255
True
				 0.590722382068634 1.9114285707473755
#>>>    10.0 9.68 		|		 0.3200000000000003
[Mar 29, 22:33:39] 915 4.797770454626689
True
				 0.5490513443946838 2.1941518783569336
#>>>    9.37 8.79 		|		 0.5800000000000001
[Mar 29, 22:33:40] 916 4.79571588733521
True
				 0.623842716217041 2.0982666015625
#>>>    9.86 9.05 		|		 0.8099999999999987
[Mar 29, 22:33:41] 917 4.7936422807656545
True
				 0.5523287057876587 2.1049695014953613
#>>>    9.84 9.16 		|		 0.6799999999999997
[Mar 29, 22:33:42] 918 4.791505936572962
True
				 0.5858112573623657 1.9841736555099487
#>>>    10.18 9.54 		|		 0.6400000000000006
[Mar 29, 22:33:42] 919 4.789284415549262
True
				 0.6469173431396484 2.115482807159424
#>>>    10.16 9.94 		|		 0.22000000000000064
[Mar 29, 22:33:43] 920 4.787257531284012
True
				 0.6300671100616455 1.9410237073898315
#>>>    10.11 9.88 		|		 0.22999999999999865
[Mar 29, 22:33:44] 921 4.78504136445097
True
				 0.6259775757789612 2.26715087890625
#>>>    10.22 9.72 		|		 0.5
[Mar 29, 22:33:45] 922 4.7831494514816
True
				 0.5456636548042297 2.0583646297454834
#>>>    9.7 9.12 		|		 0.5800000000000001
[Mar 29, 22:33:45] 923 4.780970330255064
True
				 0.6888636350631714 1.8616575002670288
#>>>    10.22 9.51 		|		 0.7100000000000009
[Mar 29, 22:33:46] 924 4.7787398810601385
True
				 0.7302426099777222 2.0138449668884277
#>>>    10.36 9.87 		|		 0.4900000000000002
[Mar 29, 22:33:47] 925 4.776705228875153
True
				 0.5518252849578857 2.131985664367676
#>>>    9.79 9.18 		|		 0.6099999999999994
[Mar 29, 22:33:47] 926 4.774612334595604
True
				 0.5932407379150391 2.040651321411133
#>>>    9.85 9.26 		|		 0.5899999999999999
[Mar 29, 22:33:48] 927 4.7724716143203345
True
				 0.6888077855110168 1.8796944618225098
#>>>    10.23 9.45 		|		 0.7800000000000011
[Mar 29, 22:33:49] 928 4.770267644893743
True
				 0.5673463344573975 2.1191601753234863
#>>>    9.73 8.83 		|		 0.9000000000000004
[Mar 29, 22:33:50] 929 4.76818388375863
True
				 0.8112539052963257 1.8778249025344849
#>>>    10.31 9.9 		|		 0.41000000000000014
[Mar 29, 22:33:50] 930 4.766104778682703
True
				 0.6007159352302551 2.078496217727661
#>>>    9.48 8.84 		|		 0.6400000000000006
[Mar 29, 22:33:51] 931 4.764017885997373
True
				 0.5809757709503174 2.2373552322387695
#>>>    9.37 8.72 		|		 0.6499999999999986
[Mar 29, 22:33:52] 932 4.762072199114565
True
				 0.7057034969329834 2.040464401245117
#>>>    9.79 9.19 		|		 0.5999999999999996
[Mar 29, 22:33:53] 933 4.760056294813628
True
				 0.6497573256492615 2.114593029022217
#>>>    9.89 9.47 		|		 0.41999999999999993
[Mar 29, 22:33:53] 934 4.758060588933091
True
				 0.6389451026916504 2.169781446456909
#>>>    9.52 9.0 		|		 0.5199999999999996
[Mar 29, 22:33:54] 935 4.756111254893307
True
				 0.7241266965866089 2.136563301086426
#>>>    10.36 9.78 		|		 0.5800000000000001
[Mar 29, 22:33:55] 936 4.754215833755295
True
				 0.7144187688827515 1.776031732559204
#>>>    10.53 9.68 		|		 0.8499999999999996
[Mar 29, 22:33:56] 937 4.751952068303773
True
				 0.680597722530365 2.3384697437286377
#>>>    9.66 9.31 		|		 0.34999999999999964
[Mar 29, 22:33:56] 938 4.750219183761332
True
				 0.710827648639679 1.7982193231582642
#>>>    10.04 9.44 		|		 0.5999999999999996
[Mar 29, 22:33:57] 939 4.747978011608973
True
				 0.5942567586898804 1.9902089834213257
#>>>    9.77 9.25 		|		 0.5199999999999996
[Mar 29, 22:33:58] 940 4.745814499339476
True
				 0.6505260467529297 2.036322593688965
#>>>    9.66 8.9 		|		 0.7599999999999998
[Mar 29, 22:33:59] 941 4.743755533480578
True
				 0.7356416583061218 1.8140404224395752
#>>>    10.24 9.73 		|		 0.5099999999999998
[Mar 29, 22:33:59] 942 4.741561460087448
True
				 0.5116126537322998 2.0971431732177734
#>>>    9.68 9.35 		|		 0.33000000000000007
[Mar 29, 22:34:00] 943 4.7394286544543105
True
				 0.6248198747634888 1.9061448574066162
#>>>    9.89 9.17 		|		 0.7200000000000006
[Mar 29, 22:34:01] 944 4.737220190651236
True
				 0.7046827077865601 1.7065929174423218
#>>>    10.31 10.11 		|		 0.20000000000000107
[Mar 29, 22:34:02] 945 4.734894246085814
True
				 0.6053786277770996 2.155364513397217
#>>>    9.9 9.53 		|		 0.370000000000001
[Mar 29, 22:34:02] 946 4.732920094980902
True
				 0.5759936571121216 2.134481430053711
#>>>    9.77 9.16 		|		 0.6099999999999994
[Mar 29, 22:34:03] 947 4.730897649853878
True
				 0.47250914573669434 1.9996211528778076
#>>>    9.71 8.69 		|		 1.0200000000000014
[Mar 29, 22:34:04] 948 4.728638882502639
True
				 0.5786774754524231 2.0162453651428223
#>>>    9.91 9.3 		|		 0.6099999999999994
[Mar 29, 22:34:05] 949 4.726505166401127
True
				 0.646085262298584 2.033590316772461
#>>>    10.43 9.51 		|		 0.9199999999999999
[Mar 29, 22:34:05] 950 4.724458336813798
True
				 0.6008509397506714 2.1195149421691895
#>>>    9.91 9.37 		|		 0.5400000000000009
[Mar 29, 22:34:06] 951 4.722454244478112
True
				 0.6975926756858826 2.131511688232422
#>>>    10.41 9.67 		|		 0.7400000000000002
[Mar 29, 22:34:07] 952 4.720560894657158
True
				 0.7075673341751099 1.9113966226577759
#>>>    10.3 9.57 		|		 0.7300000000000004
[Mar 29, 22:34:07] 953 4.718459297719334
True
				 0.6065641641616821 1.6206425428390503
#>>>    10.41 9.65 		|		 0.7599999999999998
[Mar 29, 22:34:08] 954 4.715968045128615
True
				 0.5891185998916626 2.2835211753845215
#>>>    9.78 9.1 		|		 0.6799999999999997
[Mar 29, 22:34:09] 955 4.714124716739553
True
				 0.5511070489883423 2.1579360961914062
#>>>    9.68 9.04 		|		 0.6400000000000006
[Mar 29, 22:34:10] 956 4.712119635048784
True
				 0.6506427526473999 2.1364450454711914
#>>>    9.78 8.99 		|		 0.7899999999999991
[Mar 29, 22:34:10] 957 4.710194603331063
True
				 0.5557091236114502 2.320786476135254
#>>>    9.66 9.15 		|		 0.5099999999999998
[Mar 29, 22:34:11] 958 4.708360904327479
True
				 0.7485241889953613 2.116223096847534
#>>>    9.92 9.3 		|		 0.6199999999999992
[Mar 29, 22:34:12] 959 4.706517290708994
True
				 0.6536051034927368 2.0988376140594482
#>>>    9.87 9.42 		|		 0.4499999999999993
[Mar 29, 22:34:13] 960 4.704563216255046
True
				 0.6905314922332764 2.290416955947876
#>>>    9.79 8.93 		|		 0.8599999999999994
[Mar 29, 22:34:13] 961 4.702839601486972
True
				 0.5987249612808228 2.0743134021759033
#>>>    9.84 9.29 		|		 0.5500000000000007
[Mar 29, 22:34:14] 962 4.700809800368151
True
				 0.6433665752410889 2.0118191242218018
#>>>    10.43 10.06 		|		 0.3699999999999992
[Mar 29, 22:34:15] 963 4.698764176267246
True
				 0.6118741035461426 2.3303606510162354
#>>>    10.4 10.05 		|		 0.34999999999999964
[Mar 29, 22:34:16] 964 4.697007646845541
True
				 0.6480058431625366 2.035437822341919
#>>>    10.43 9.86 		|		 0.5700000000000003
[Mar 29, 22:34:16] 965 4.694994082744991
True
				 0.6417568325996399 1.8997652530670166
#>>>    10.42 9.52 		|		 0.9000000000000004
[Mar 29, 22:34:17] 966 4.692840610688308
True
				 0.6867350339889526 2.2285804748535156
#>>>    10.68 10.23 		|		 0.4499999999999993
[Mar 29, 22:34:18] 967 4.691063085705672
True
				 0.7037227153778076 2.1392040252685547
#>>>    10.06 9.19 		|		 0.870000000000001
[Mar 29, 22:34:19] 968 4.689214949360612
True
				 0.654596209526062 1.8493247032165527
#>>>    10.6 10.27 		|		 0.33000000000000007
[Mar 29, 22:34:19] 969 4.687029655443204
True
				 0.6302270889282227 2.139824151992798
#>>>    9.9 9.14 		|		 0.7599999999999998
[Mar 29, 22:34:20] 970 4.685112677028681
True
				 0.758540153503418 2.2333788871765137
#>>>    10.62 10.15 		|		 0.46999999999999886
[Mar 29, 22:34:21] 971 4.683419483392332
True
				 0.7997226715087891 2.130300521850586
#>>>    10.66 10.09 		|		 0.5700000000000003
[Mar 29, 22:34:21] 972 4.6816660871022995
True
				 0.7362552285194397 1.7154055833816528
#>>>    10.76 10.14 		|		 0.6199999999999992
[Mar 29, 22:34:22] 973 4.679436081886703
True
				 0.8036214709281921 2.171250343322754
#>>>    10.2 9.35 		|		 0.8499999999999996
[Mar 29, 22:34:23] 974 4.677731517678672
True
				 0.7321338057518005 1.7934377193450928
#>>>    10.6 9.74 		|		 0.8599999999999994
[Mar 29, 22:34:24] 975 4.675579357745695
True
				 0.6630324721336365 2.1720848083496094
#>>>    10.44 9.94 		|		 0.5
[Mar 29, 22:34:25] 976 4.673738895728038
True
				 0.6707858443260193 2.323267698287964
#>>>    10.32 9.69 		|		 0.6300000000000008
[Mar 29, 22:34:25] 977 4.672059210434528
True
				 0.6778972744941711 1.7676302194595337
#>>>    10.26 9.8 		|		 0.4599999999999991
[Mar 29, 22:34:26] 978 4.669832678777652
True
				 0.6668503880500793 2.134550094604492
#>>>    10.15 9.4 		|		 0.75
[Mar 29, 22:34:27] 979 4.667964246521925
True
				 0.684138834476471 1.6767789125442505
#>>>    10.8 9.99 		|		 0.8100000000000005
[Mar 29, 22:34:28] 980 4.665657200082029
True
				 0.6131718754768372 1.7871472835540771
#>>>    10.26 9.25 		|		 1.0099999999999998
[Mar 29, 22:34:28] 981 4.663391861981373
True
				 0.7100620269775391 1.7759959697723389
#>>>    10.49 9.37 		|		 1.120000000000001
[Mar 29, 22:34:29] 982 4.661214528116142
True
				 0.6351293325424194 1.98995041847229
#>>>    10.19 9.62 		|		 0.5700000000000003
[Mar 29, 22:34:30] 983 4.659178393219832
True
				 0.6506191492080688 1.9901812076568604
#>>>    10.01 9.66 		|		 0.34999999999999964
[Mar 29, 22:34:30] 984 4.657160015302686
True
				 0.6153587698936462 2.2433292865753174
#>>>    10.44 9.67 		|		 0.7699999999999996
[Mar 29, 22:34:31] 985 4.655361543403457
True
				 0.6001700162887573 2.258603811264038
#>>>    9.74 9.07 		|		 0.6699999999999999
[Mar 29, 22:34:32] 986 4.653564955568397
True
				 0.7566134929656982 2.3030271530151367
#>>>    9.85 9.28 		|		 0.5700000000000003
[Mar 29, 22:34:33] 987 4.651971031258809
True
				 0.6480903625488281 2.150723457336426
#>>>    9.91 9.51 		|		 0.40000000000000036
[Mar 29, 22:34:33] 988 4.650117874047436
True
				 0.6494874954223633 1.89055335521698
#>>>    10.13 9.18 		|		 0.9500000000000011
[Mar 29, 22:34:34] 989 4.648007797143237
True
				 0.7604215145111084 1.6856426000595093
#>>>    10.24 9.34 		|		 0.9000000000000004
[Mar 29, 22:34:35] 990 4.6458058533414555
True
				 0.6922793984413147 1.9537262916564941
#>>>    10.37 9.57 		|		 0.7999999999999989
[Mar 29, 22:34:36] 991 4.643806053118607
True
				 0.5768120288848877 1.9842637777328491
#>>>    9.75 9.06 		|		 0.6899999999999995
[Mar 29, 22:34:36] 992 4.641723322752897
True
				 0.5936453342437744 2.1235721111297607
#>>>    9.51 9.35 		|		 0.16000000000000014
[Mar 29, 22:34:37] 993 4.639798816875517
True
				 0.5767757296562195 1.8581005334854126
#>>>    9.94 9.33 		|		 0.6099999999999994
[Mar 29, 22:34:38] 994 4.637593894262179
True
				 0.4983890652656555 1.8399217128753662
#>>>    9.82 9.09 		|		 0.7300000000000004
[Mar 29, 22:34:38] 995 4.635294611086453
True
				 0.8152798414230347 1.653032660484314
#>>>    10.11 9.28 		|		 0.8300000000000001
[Mar 29, 22:34:39] 996 4.633127628977274
True
				 0.627036452293396 2.042281150817871
#>>>    9.77 9.33 		|		 0.4399999999999995
[Mar 29, 22:34:40] 997 4.631163819070617
True
				 0.6489697098731995 1.7658677101135254
#>>>    9.94 9.16 		|		 0.7799999999999994
[Mar 29, 22:34:41] 998 4.628947492611927
True
				 0.6604853272438049 2.092789888381958
#>>>    9.54 8.87 		|		 0.6699999999999999
[Mar 29, 22:34:41] 999 4.6270718202753365
True
				 0.7616002559661865 1.9712615013122559
#>>>    9.82 9.14 		|		 0.6799999999999997
[Mar 29, 22:34:42] 1000 4.62517761021234
True
				 0.7622294425964355 1.8548731803894043
#>>>    10.01 9.51 		|		 0.5
[Mar 29, 22:34:43] 1001 4.623169535225113
True
				 0.6676779985427856 1.9897046089172363
#>>>    9.85 9.14 		|		 0.7099999999999991
[Mar 29, 22:34:44] 1002 4.6212037481781385
True
				 0.6796928644180298 1.8568826913833618
#>>>    9.91 9.17 		|		 0.7400000000000002
[Mar 29, 22:34:44] 1003 4.619119119985761
True
				 0.6505239605903625 1.9012706279754639
#>>>    9.72 9.13 		|		 0.5899999999999999
[Mar 29, 22:34:45] 1004 4.617051795394737
True
				 0.6318244934082031 2.2375805377960205
#>>>    9.31 8.99 		|		 0.3200000000000003
[Mar 29, 22:34:46] 1005 4.615304148630546
True
				 0.655876100063324 2.440049409866333
#>>>    9.72 9.36 		|		 0.3600000000000012
[Mar 29, 22:34:46] 1006 4.613784770051449
True
				 0.6420600414276123 1.874697208404541
#>>>    9.67 8.96 		|		 0.7099999999999991
[Mar 29, 22:34:47] 1007 4.61168774253123
True
				 0.620261549949646 1.9555124044418335
#>>>    10.7 10.22 		|		 0.47999999999999865
[Mar 29, 22:34:48] 1008 4.6096518287430905
True
				 0.5833655595779419 1.9773962497711182
#>>>    9.74 9.25 		|		 0.4900000000000002
[Mar 29, 22:34:49] 1009 4.607602938842906
True
				 0.6540713310241699 1.6889218091964722
#>>>    10.53 9.73 		|		 0.7999999999999989
[Mar 29, 22:34:49] 1010 4.605338329163493
True
				 0.5849100351333618 1.7870893478393555
#>>>    10.66 10.06 		|		 0.5999999999999996
[Mar 29, 22:34:50] 1011 4.6031049900980925
True
				 0.651703953742981 1.7391092777252197
#>>>    10.21 9.84 		|		 0.370000000000001
[Mar 29, 22:34:51] 1012 4.600892698458672
True
				 0.6196804046630859 1.7387913465499878
#>>>    10.29 9.72 		|		 0.5699999999999985
[Mar 29, 22:34:52] 1013 4.598650277630635
True
				 0.6526502370834351 2.2286455631256104
#>>>    9.43 8.85 		|		 0.5800000000000001
[Mar 29, 22:34:52] 1014 4.596932923034005
True
				 0.5966359376907349 2.0123488903045654
#>>>    9.66 9.04 		|		 0.620000000000001
[Mar 29, 22:34:53] 1015 4.594944975058175
True
				 0.6129740476608276 2.322283983230591
#>>>    9.14 8.69 		|		 0.45000000000000107
[Mar 29, 22:34:54] 1016 4.5932852879947985
[Mar 29, 22:34:54] #> Done with all triples!

Qwen/Qwen1.5-1.8B-Chat
{'instruction_model': 'Qwen/Qwen1.5-1.8B-Chat'}
#> LR will use 100 warmup steps and linear decay over 500000 steps.
True

#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: . what is the science of mapmaking called, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2003,  1996,  2671,  1997,  4949, 12614,  2170,
          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:1')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:1')

True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
True
#> Saving a checkpoint to /home/ubuntu/colbert/experiments/test/none/2024-03/29/22.22.09/checkpoints/colbert ..
#> Joined...
#> Joined...
Saved checkpoint to None...
